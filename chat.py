# ============================================
#  CHATBOT 4-B∆Ø·ªöC ‚Äì HI·ªÇU NGHƒ®A, KH√îNG B·ªäA
#  Router (LLM + Embedding) ‚Üí Rewrite (LLM)
#  ‚Üí Search (Embedding + LLM Rerank) ‚Üí Strict Answer (LLM)
#  Model LLM:  qwen2.5:3b  (ollama)
#  Model Emb:  BAAI/bge-large-en-v1.5
# ============================================

import sqlite3
import requests
import numpy as np
import os
from sentence_transformers import SentenceTransformer

FAQ_DB_PATH = "faq.db"
OLLAMA_URL = "http://127.0.0.1:11434"
MODEL = "qwen2.5:3b"
TIMEOUT = 20

FALLBACK_MSG = "Hi·ªán t·∫°i th∆∞ vi·ªán ch∆∞a c√≥ th√¥ng tin ch√≠nh x√°c cho c√¢u n√†y. B·∫°n m√¥ t·∫£ r√µ h∆°n gi√∫p m√¨nh nh√©."

# ============================================
#  EMBEDDING MODEL (Vietnamese SBERT)
# ============================================
print("ƒêang t·∫£i model embedding (l·∫ßn ƒë·∫ßu s·∫Ω h∆°i l√¢u)...")
try:
    # User suggested BAAI/bge-large-en-v1.5, but BAAI/bge-m3 is SOTA for multilingual/Vietnamese
    embed_model = SentenceTransformer("BAAI/bge-m3")
except Exception as e:
    print(f"‚ö† L·ªói load model embedding: {e}")
    print("ƒêang d√πng fallback model (keepitreal/vietnamese-sbert)...")
    embed_model = SentenceTransformer("keepitreal/vietnamese-sbert")


# ============================================
#  TEXT NORMALIZE ‚Äì NH·∫∏, KH√îNG PH√Å NGHƒ®A
# ============================================
def normalize(x: str) -> str:
    # ch·ªâ lower + trim, kh√¥ng ƒë·ª•ng t·ªõi d·∫•u
    return " ".join(x.lower().strip().split())


# ============================================
#  OLLAMA LLM CALL
# ============================================
def llm(prompt: str, temp: float = 0.15, n: int = 128) -> str:
    try:
        r = requests.post(
            f"{OLLAMA_URL}/api/generate",
            json={
                "model": MODEL,
                "prompt": prompt,
                "stream": False,
                "options": {"temperature": temp, "num_predict": n},
            },
            timeout=TIMEOUT,
        )
        if r.status_code == 200:
            return r.json().get("response", "").strip()
    except Exception:
        pass
    return ""


# ============================================
#  LOAD & EMBED DB
# ============================================
print("ƒêang t·∫£i d·ªØ li·ªáu t·ª´ faq.db...")

if not os.path.exists(FAQ_DB_PATH):
    print(f"‚ùå Kh√¥ng t√¨m th·∫•y file {FAQ_DB_PATH}. H√£y ch·∫°y sync_faq.py tr∆∞·ªõc!")
    # T·∫°o dummy ƒë·ªÉ kh√¥ng crash
    FAQ_TEXTS, BOOK_TEXTS, MAJOR_TEXTS = [], [], []
    FAQ_EMB = np.zeros((0, 768)) # vietnamese-sbert dim is 768
    BOOK_EMB = np.zeros((0, 768))
    MAJOR_EMB = np.zeros((0, 768))
    faq_rows, book_rows, major_rows = [], [], []
else:
    conn = sqlite3.connect(FAQ_DB_PATH)
    cur = conn.cursor()

    # FAQ
    cur.execute(
        "SELECT question, answer, category FROM faq WHERE approved = 1 OR approved IS NULL"
    )
    faq_rows = cur.fetchall()
    
    # UPDATE: Theo y√™u c·∫ßu "hi·ªÉu c√¢u tr·∫£ l·ªùi", ta s·∫Ω embed C√ÇU TR·∫¢ L·ªúI (Answer).
    # Tuy nhi√™n, ƒë·ªÉ AI hi·ªÉu ng·ªØ c·∫£nh t·ªët nh·∫•t, ta n√™n gh√©p c·∫£ Category v√†o (n·∫øu c√≥).
    # V√≠ d·ª•: "Gi·ªù m·ªü c·ª≠a: Th∆∞ vi·ªán m·ªü t·ª´ 7h..." s·∫Ω d·ªÖ t√¨m h∆°n l√† ch·ªâ "Th∆∞ vi·ªán m·ªü t·ª´ 7h..."
    FAQ_TEXTS = []
    for q, a, cat in faq_rows:
        # K·∫øt h·ª£p Category + Answer ƒë·ªÉ t·∫°o th√†nh m·ªôt "kh·ªëi ki·∫øn th·ª©c" (Knowledge Chunk)
        # N·∫øu Answer ƒë√£ ƒë·∫ßy ƒë·ªß √Ω nghƒ©a th√¨ r·∫•t t·ªët.
        content = f"{cat or ''}: {a or ''}" 
        FAQ_TEXTS.append(normalize(content))
    
    # BOOKS
    cur.execute(
        """
        SELECT b.name, b.author, b.year, b.quantity, b.status, m.name
        FROM books b LEFT JOIN majors m ON b.major_id = m.major_id
    """
    )
    book_rows = cur.fetchall()
    BOOK_TEXTS = [
        normalize(f"s√°ch {n}. t√°c gi·∫£ {a}. ng√†nh {m or ''}")
        for n, a, _, _, _, m in book_rows
    ]

    # MAJORS
    cur.execute("SELECT name, major_id, description FROM majors")
    major_rows = cur.fetchall()
    MAJOR_TEXTS = [
        normalize(f"ng√†nh {n}. m√£ {mid}. {desc or ''}")
        for n, mid, desc in major_rows
    ]

    conn.close()

    print("ƒêang t·∫°o embedding (l·∫ßn ƒë·∫ßu s·∫Ω h∆°i l√¢u)...")
    FAQ_EMB = (
        embed_model.encode(FAQ_TEXTS, normalize_embeddings=True)
        if FAQ_TEXTS
        else np.zeros((0, 768))
    )
    BOOK_EMB = (
        embed_model.encode(BOOK_TEXTS, normalize_embeddings=True)
        if BOOK_TEXTS
        else np.zeros((0, 768))
    )
    MAJOR_EMB = (
        embed_model.encode(MAJOR_TEXTS, normalize_embeddings=True)
        if MAJOR_TEXTS
        else np.zeros((0, 768))
    )

    print(f"‚úÖ ƒê√£ t·∫£i: FAQ={len(faq_rows)} | BOOKS={len(book_rows)} | MAJORS={len(major_rows)}")


# ============================================
#  ROUTER ‚Äì FALLBACK B·∫∞NG EMBEDDING
# ============================================
def auto_route_by_embedding(q_vec: np.ndarray) -> str:
    """
    N·∫øu LLM ph√¢n lo·∫°i linh tinh ‚Üí d√πng embedding ch·ªçn b·∫£ng n√†o g·∫ßn nh·∫•t.
    """
    best_type = "FAQ"
    best_score = -1.0

    if len(FAQ_EMB) > 0:
        s = float(np.max(np.dot(FAQ_EMB, q_vec)))
        best_type, best_score = "FAQ", s

    if len(BOOK_EMB) > 0:
        s = float(np.max(np.dot(BOOK_EMB, q_vec)))
        if s > best_score:
            best_type, best_score = "BOOKS", s

    if len(MAJOR_EMB) > 0:
        s = float(np.max(np.dot(MAJOR_EMB, q_vec)))
        if s > best_score:
            best_type, best_score = "MAJORS", s

    return best_type


# ============================================
#  LOAD TRAINED MODEL (ML Classification)
# ============================================
import torch
from model import NeuralNet
from nltk_utils import bag_of_words, tokenize

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

FILE = "data.pth"
try:
    data = torch.load(FILE, map_location=device)
    input_size = data["input_size"]
    hidden_size = data["hidden_size"]
    output_size = data["output_size"]
    all_words = data["all_words"]
    tags = data["tags"]
    model_state = data["model_state"]

    model = NeuralNet(input_size, hidden_size, output_size).to(device)
    model.load_state_dict(model_state)
    model.eval()
    print("‚úÖ ƒê√£ load model ph√¢n lo·∫°i (data.pth)")
except Exception as e:
    print(f"‚ö† Kh√¥ng load ƒë∆∞·ª£c model ph√¢n lo·∫°i: {e}")
    model = None

def predict_intent(sentence):
    if not model:
        return None
    
    sentence = tokenize(sentence)
    X = bag_of_words(sentence, all_words)
    X = X.reshape(1, X.shape[0])
    X = torch.from_numpy(X).to(device)

    output = model(X)
    _, predicted = torch.max(output, dim=1)
    tag = tags[predicted.item()]

    probs = torch.softmax(output, dim=1)
    prob = probs[0][predicted.item()]
    
    if prob.item() > 0.75:
        return tag
    return None

# ============================================
# 1) ROUTER ‚Äì HYBRID (ML + LLM)
# ============================================
def route_llm(question: str, q_vec: np.ndarray) -> str:
    # B1: D√πng model ƒë√£ train ƒë·ªÉ ph√¢n lo·∫°i Category (ML c∆° b·∫£n)
    # Model n√†y ƒë√£ ƒë∆∞·ª£c train tr√™n C√ÇU TR·∫¢ L·ªúI t·ª´ Notion
    intent = predict_intent(question)
    
    if intent:
        print(f"[ML Predict] Intent: {intent}")
        # N·∫øu l√† GREETING -> Tr·∫£ v·ªÅ lu√¥n
        if intent == "GREETING":
            return "GREETING"
        
        # N·∫øu ra c√°c Category c·ª• th·ªÉ (Gi·ªù m·ªü c·ª≠a, Li√™n h·ªá...) -> Tr·∫£ v·ªÅ ch√≠nh Category ƒë√≥
        # ƒê·ªÉ l√°t n·ªØa search_faq ch·ªâ t√¨m trong category n√†y th√¥i.
        return intent

    # B2: N·∫øu model kh√¥ng ch·∫Øc ch·∫Øn (ho·∫∑c l√† c√¢u h·ªèi v·ªÅ S√°ch/Ng√†nh m√† model ch∆∞a h·ªçc k·ªπ)
    # D√πng LLM ƒë·ªÉ ph√¢n lo·∫°i chung
    prompt = f"""
Ph√¢n lo·∫°i c√¢u h·ªèi c·ªßa sinh vi√™n v√†o 1 trong 3 nh√≥m sau:

1. FAQ: H·ªèi v·ªÅ quy ƒë·ªãnh, th·ªß t·ª•c, gi·ªù m·ªü c·ª≠a, li√™n h·ªá, m∆∞·ª£n tr·∫£ s√°ch, wifi, t√†i kho·∫£n...
2. BOOKS: H·ªèi t√¨m s√°ch, gi√°o tr√¨nh, t√†i li·ªáu, t√°c gi·∫£, ki·ªÉm tra s√°ch c√≤n kh√¥ng...
3. MAJORS: H·ªèi th√¥ng tin v·ªÅ c√°c ng√†nh h·ªçc, m√£ ng√†nh, ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o...

C√¢u h·ªèi: "{question}"

Ch·ªâ tr·∫£ v·ªÅ ƒë√∫ng 1 t·ª´: FAQ ho·∫∑c BOOKS ho·∫∑c MAJORS.
"""
    out = llm(prompt, temp=0.05, n=10).upper().strip()

    if out in ["FAQ", "BOOKS", "MAJORS"]:
        return out

    # fallback embedding
    return auto_route_by_embedding(q_vec)
# ============================================
# 2) REWRITE ‚Äì KH√îNG ƒê·ª§NG C√ÇU NG·∫ÆN
# ============================================
def rewrite_question(q: str) -> str:
    # C√¢u ng·∫Øn (‚â§ 5 t·ª´) ‚Üí gi·ªØ nguy√™n, tr√°nh LLM ph√° nghƒ©a.
    # UPDATE: V·ªõi y√™u c·∫ßu "hi·ªÉu nh∆∞ ng∆∞·ªùi", ta cho LLM s·ª≠a c·∫£ c√¢u ng·∫Øn n·∫øu n√≥ qu√° t·ªëi nghƒ©a.
    # Ch·ªâ b·ªè qua n·∫øu qu√° ng·∫Øn (< 2 t·ª´)
    if len(q.split()) < 2:
        return q

    prompt = f"""
B·∫°n l√† m·ªôt tr·ª£ l√Ω th√¥ng minh. H√£y ƒê·ªåC HI·ªÇU √Ω ƒë·ªãnh c·ªßa ng∆∞·ªùi d√πng v√† vi·∫øt l·∫°i c√¢u h·ªèi sao cho r√µ r√†ng, ƒë·∫ßy ƒë·ªß nghƒ©a nh·∫•t.
N·∫øu c√¢u h·ªèi qu√° ng·∫Øn, d√πng t·ª´ ƒëa nghƒ©a ho·∫∑c thi·∫øu ch·ªß ng·ªØ, h√£y di·ªÖn gi·∫£i l·∫°i theo c√°ch ng∆∞·ªùi b√¨nh th∆∞·ªùng s·∫Ω h·ªèi ƒë·∫ßy ƒë·ªß.
ƒê·∫∂C BI·ªÜT:
- N·∫øu h·ªèi v·ªÅ "s·ªë", "g·ªçi", "alo" -> Th√™m t·ª´ kh√≥a "s·ªë ƒëi·ªán tho·∫°i li√™n h·ªá hotline".
- N·∫øu h·ªèi v·ªÅ "·ªü ƒë√¢u", "ch·ªó n√†o" -> Th√™m t·ª´ kh√≥a "ƒë·ªãa ƒëi·ªÉm v·ªã tr√≠".

V√≠ d·ª•:
- "s·ªë n√†o" -> "s·ªë ƒëi·ªán tho·∫°i li√™n h·ªá hotline l√† g√¨"
- "m·ªü c·ª≠a ko" -> "gi·ªù m·ªü c·ª≠a ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o"
- "li√™n h·ªá sao" -> "c√°ch th·ª©c li√™n h·ªá v·ªõi th∆∞ vi·ªán"

C√¢u g·ªëc: "{q}"

C√¢u vi·∫øt l·∫°i (ch·ªâ vi·∫øt 1 c√¢u duy nh·∫•t):
"""
    out = llm(prompt, temp=0.1, n=64)
    return out.strip() if out else q


# ============================================
# 3A) SEMANTIC SEARCH CHO FAQ ‚Äì C√ì L·ªåC CATEGORY
# ============================================
def search_faq_candidates(q_vec: np.ndarray, top_k: int = 10, filter_category: str = None): 
    if len(FAQ_EMB) == 0:
        return []

    sims = np.dot(FAQ_EMB, q_vec)
    idx = np.argsort(-sims)[:top_k]

    candidates = []
    for i in idx:
        score = float(sims[i])
        # H·∫° ng∆∞·ª°ng xu·ªëng c·ª±c th·∫•p ƒë·ªÉ "l∆∞·ªõi" ƒë∆∞·ª£c h·∫øt c√°c c√¢u c√≥ √Ω nghƒ©a li√™n quan
        if score < 0.08: 
            continue
        
        q, a, cat = faq_rows[i]
        
        # L·ªåC: N·∫øu ƒë√£ bi·∫øt Category (do model train d·ª± ƒëo√°n), ch·ªâ l·∫•y ƒë√∫ng Category ƒë√≥
        if filter_category and filter_category not in ["FAQ", "BOOKS", "MAJORS", "GREETING"]:
            # So s√°nh t∆∞∆°ng ƒë·ªëi (v√¨ c√≥ th·ªÉ c√≥ s·ª± kh√°c bi·ªát nh·ªè v·ªÅ string)
            if cat != filter_category:
                continue

        candidates.append(
            {
                "score": score,
                "question": q or "",
                "answer": a or "",
                "category": cat or "",
                "id": i,
            }
        )
    return candidates


# ============================================
# 3B) SEMANTIC SEARCH CHO BOOKS / MAJORS
# ============================================
def search_nonfaq(table: str, q_vec: np.ndarray, top_k: int = 5):
    results = []

    if table == "BOOKS":
        if len(BOOK_EMB) == 0:
            return []
        sims = np.dot(BOOK_EMB, q_vec)
        rows = book_rows
        th = 0.20 # H·∫° ng∆∞·ª°ng s√°ch
        idx = np.argsort(-sims)[:top_k]
        for i in idx:
            score = float(sims[i])
            if score < th:
                continue
            n, a, y, qty, s, m = rows[i]
            results.append(
                f"- S√°ch: {n}\n  T√°c gi·∫£: {a}\n  NƒÉm: {y} | SL: {qty} | TT: {s}\n  Ng√†nh: {m or 'Chung'}"
            )
        return results

    # MAJORS
    if len(MAJOR_EMB) == 0:
        return []
    sims = np.dot(MAJOR_EMB, q_vec)
    rows = major_rows
    th = 0.25 # H·∫° ng∆∞·ª°ng ng√†nh
    idx = np.argsort(-sims)[:top_k]
    for i in idx:
        score = float(sims[i])
        if score < th:
            continue
        name, code, desc = rows[i]
        results.append(
            f"- Ng√†nh: {name} (M√£: {code})\n  M√¥ t·∫£: {desc or 'ƒêang c·∫≠p nh·∫≠t'}"
        )
    return results


# ============================================
# 3C) LLM RERANK CHO FAQ ‚Äì CH·ªñ ‚ÄúHI·ªÇU NGHƒ®A‚Äù
# ============================================
def rerank_with_llm(user_q: str, candidates: list):
    if not candidates:
        return None

    block = ""
    for i, c in enumerate(candidates, start=1):
        block += f"{i}. {c['answer']}\n"

    prompt = f"""
B·∫°n l√† chuy√™n gia t∆∞ v·∫•n th√¥ng minh.
Nhi·ªám v·ª•: T√¨m c√¢u tr·∫£ l·ªùi T·ªêT NH·∫§T cho c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng trong danh s√°ch b√™n d∆∞·ªõi.

C√¢u h·ªèi: "{user_q}"

Danh s√°ch ·ª©ng vi√™n:
{block}

H∆Ø·ªöNG D·∫™N T∆Ø DUY (QUAN TR·ªåNG):
1. **X·ª¨ L√ù C√ÇU H·ªéI LI·ªÜT K√ä (LIST ALL) - QUAN TR·ªåNG**:
   - N·∫øu h·ªèi "G·ªìm nh·ªØng g√¨?", "C√≥ nh·ªØng ph√≤ng n√†o?", "Li·ªát k√™...", "Chia th√†nh...".
   - -> B·∫ÆT BU·ªòC ch·ªçn c√¢u tr·∫£ l·ªùi c√≥ ch·ª©a DANH S√ÅCH (d·∫•u g·∫°ch ƒë·∫ßu d√≤ng "-") ho·∫∑c t·ª´ "g·ªìm", "bao g·ªìm".
   - V√≠ d·ª•: H·ªèi "Th∆∞ vi·ªán g·ªìm nh·ªØng ph√≤ng n√†o?" -> Ch·ªçn c√¢u "c√°c ph√≤ng th∆∞ vi·ªán: - Ph√≤ng A... - Ph√≤ng B...".

2. **X·ª¨ L√ù T√åM KI·∫æM C·ª§ TH·ªÇ (SPECIFIC LOOKUP)**:
   - N·∫øu h·ªèi tr√∫ng t√™n m·ªôt ph√≤ng c·ª• th·ªÉ (v√≠ d·ª•: "Ph√≤ng m∆∞·ª£n s√°ch").
   - -> H√£y t√¨m trong danh s√°ch xem c√≥ m·ª•c ƒë√≥ kh√¥ng. N·∫øu c√≥ -> CH·ªåN NGAY.

3. **SO KH·ªöP T·ª™ KH√ìA & NG·ªÆ NGHƒ®A**:
   - H·ªèi "·ªû ƒë√¢u", "Ch·ªó n√†o" -> T√¨m c√¢u ch·ª©a ƒë·ªãa ƒëi·ªÉm (Nh√†, Ph√≤ng, T·∫ßng, L·∫ßu, Khu, V·ªã tr√≠...).
   - H·ªèi "Bao nhi√™u", "S·ªë l∆∞·ª£ng" -> T√¨m c√¢u ch·ª©a con s·ªë ho·∫∑c t·ª´ ch·ªâ l∆∞·ª£ng (cu·ªën, b·∫£n, ƒë·∫ßu s√°ch...).
   - H·ªèi "Th·ªùi gian", "Bao l√¢u" -> T√¨m c√¢u ch·ª©a ng√†y, gi·ªù, th√°ng, nƒÉm.

4. **KI·ªÇM TRA ƒê·ªäNH D·∫†NG**:
   - H·ªèi "S·ªë ƒëi·ªán tho·∫°i" -> C√¢u tr·∫£ l·ªùi PH·∫¢I c√≥ d√£y s·ªë.
   - H·ªèi "Link/Facebook" -> C√¢u tr·∫£ l·ªùi PH·∫¢I c√≥ "http".

K·∫æT QU·∫¢:
- N·∫øu t√¨m th·∫•y c√¢u tr·∫£ l·ªùi ph√π h·ª£p: Tr·∫£ v·ªÅ S·ªê TH·ª® T·ª∞ (v√≠ d·ª•: 1, 2...).
- N·∫øu kh√¥ng c√≥ c√¢u n√†o kh·ªõp: Tr·∫£ v·ªÅ 0.

Ch·ªâ tr·∫£ v·ªÅ 1 con s·ªë duy nh·∫•t.
- N·∫øu kh√¥ng t√¨m th·∫•y c√¢u tr·∫£ l·ªùi ph√π h·ª£p, tr·∫£ v·ªÅ "0".
"""
    out = llm(prompt, temp=0.1, n=10).strip()
    
    # L·∫•y s·ªë ƒë·∫ßu ti√™n t√¨m th·∫•y
    import re
    match = re.search(r'\d+', out)
    if match:
        idx = int(match.group()) - 1
        if 0 <= idx < len(candidates):
            return candidates[idx]
            
    return None


# ============================================
# 4) STRICT ANSWER ‚Äì KH√îNG BAO GI·ªú B·ªäA
# ============================================
def strict_answer(question: str, knowledge: str) -> str:
    prompt = f"""
B·∫°n l√† tr·ª£ l√Ω ·∫£o c·ªßa th∆∞ vi·ªán. 
NHI·ªÜM V·ª§: Tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n th√¥ng tin cung c·∫•p b√™n d∆∞·ªõi.

TH√îNG TIN (KNOWLEDGE):
{knowledge}

C√ÇU H·ªéI (QUESTION): "{question}"

QUY T·∫ÆC B·∫ÆT BU·ªòC:
1. ‚ö†Ô∏è TUY·ªÜT ƒê·ªêI TR·∫¢ L·ªúI B·∫∞NG TI·∫æNG VI·ªÜT. (Kh√¥ng d√πng ti·∫øng Trung/Anh).
2. N·∫øu th√¥ng tin c√≥ v·∫ª li√™n quan, H√ÉY TR·∫¢ L·ªúI NGAY (ƒë·ª´ng s·ª£ sai).
3. N·∫øu th√¥ng tin l√† danh s√°ch, h√£y tr√≠ch xu·∫•t √Ω ch√≠nh.
4. N·∫øu c√¢u h·ªèi d√πng t·ª´ ƒë·ªìng nghƒ©a (v√≠ d·ª•: "r√°ch" = "h·ªèng"), h√£y t·ª± suy lu·∫≠n ƒë·ªÉ tr·∫£ l·ªùi.
5. N·∫øu c√≥ s·ªë li·ªáu/th·ªëng k√™, h√£y ƒë∆∞a ra con s·ªë ƒë√≥.
6. N·∫øu c√¢u h·ªèi v·ªÅ ƒë·ªëi t∆∞·ª£ng c·ª• th·ªÉ (v√≠ d·ª•: "s√°ch tham kh·∫£o") m√† th√¥ng tin ch·ªâ n√≥i chung chung (v√≠ d·ª•: "s√°ch"), H√ÉY D√ôNG TH√îNG TIN CHUNG ƒê√ì ƒë·ªÉ tr·∫£ l·ªùi.
7. N·∫øu th√¥ng tin l√† S·ªê ƒêI·ªÜN THO·∫†I, EMAIL, LINK -> H√£y tr·∫£ l·ªùi ngay (v√≠ d·ª•: "0987654321").
8. N·∫øu th√¥ng tin l√† QUY TR√åNH (Tr√¨nh th·∫ª, Qu√©t m√£...) -> H√£y tr·∫£ l·ªùi c√°c b∆∞·ªõc ƒë√≥.
9. Tuy·ªát ƒë·ªëi KH√îNG tr·∫£ l·ªùi "{FALLBACK_MSG}" n·∫øu b·∫°n t√¨m th·∫•y th√¥ng tin li√™n quan d√π ch·ªâ m·ªôt ch√∫t.

N·∫øu th√¥ng tin HO√ÄN TO√ÄN KH√îNG LI√äN QUAN th√¨ m·ªõi n√≥i: "{FALLBACK_MSG}"

V√≠ d·ª•:
- Info: "M·∫•t s√°ch ƒë·ªÅn g·∫•p ƒë√¥i" -> H·ªèi: "L√†m r√°ch b·ªã ph·∫°t ko?" -> Tr·∫£ l·ªùi: "C√≥, b·∫°n ph·∫£i ƒë·ªÅn g·∫•p ƒë√¥i."
- Info: "0262.3825180" -> H·ªèi: "S·ªë n√†o?" -> Tr·∫£ l·ªùi: "0262.3825180"
- Info: "Tr√¨nh th·∫ª v√† t√†i li·ªáu..." -> H·ªèi: "C√°ch tr·∫£ s√°ch?" -> Tr·∫£ l·ªùi: "B·∫°n c·∫ßn tr√¨nh th·∫ª v√† t√†i li·ªáu cho c√°n b·ªô."

C√¢u tr·∫£ l·ªùi c·ªßa b·∫°n (Ti·∫øng Vi·ªát):
"""
    # TƒÉng temp l√™n ƒë·ªÉ bot "d√°m" tr·∫£ l·ªùi h∆°n
    out = llm(prompt, temp=0.3, n=256) 
    if not out:
        return FALLBACK_MSG

    out = out.strip()
    
    # UPDATE: Ch·∫•p nh·∫≠n SƒêT (s·ªë) ho·∫∑c Email (@) ho·∫∑c Link (http)
    if any(c.isdigit() for c in out) or "@" in out or "http" in out:
        return out

    # B·ªè check "kh√¥ng c√≥ th√¥ng tin" qu√° g·∫Øt, ch·ªâ check n·∫øu output qu√° ng·∫Øn
    if "kh√¥ng c√≥ th√¥ng tin" in out.lower() and len(out) < 15: 
         return FALLBACK_MSG

    return out


# ============================================
#  MAIN PROCESS
# ============================================
def process_message(text: str) -> str:
    if not text.strip():
        return "Xin ch√†o üëã B·∫°n mu·ªën h·ªèi th√¥ng tin g√¨ trong th∆∞ vi·ªán?"

    # B0: vector cho router
    q_vec_route = embed_model.encode(normalize(text), normalize_embeddings=True)

    # B1: Router
    route = route_llm(text, q_vec_route)
    # print("[DEBUG ROUTE]", route)

    # B2: Rewrite
    rewritten = rewrite_question(text)
    q_vec = embed_model.encode(normalize(rewritten), normalize_embeddings=True)

    # B3 + B4
    # UPDATE: N·∫øu c√¢u h·ªèi d√†i (> 3 t·ª´) ho·∫∑c ch·ª©a t·ª´ kh√≥a h·ªèi (·ªü ƒë√¢u, s√°ch, ph√≤ng, bao nhi√™u...), 
    # th√¨ D√ô Router b·∫£o l√† GREETING c≈©ng K·ªÜ N√ì, c·ª© ƒëi t√¨m ki·∫øm cho ch·∫Øc.
    # Tr√°nh tr∆∞·ªùng h·ª£p model train b·ªã l·ªách, c·ª© th·∫•y l·∫° l√† ph√°n Greeting.
    is_real_question = len(text.split()) > 3 or any(w in text.lower() for w in ["·ªü ƒë√¢u", "s√°ch", "ph√≤ng", "bao nhi√™u", "khi n√†o", "m·∫•y gi·ªù", "l√† g√¨"])
    
    if route == "GREETING" and not is_real_question:
        return "Xin ch√†o! T√¥i l√† tr·ª£ l√Ω ·∫£o th∆∞ vi·ªán (ƒë√£ ƒë∆∞·ª£c train). B·∫°n c·∫ßn t√¨m s√°ch, h·ªèi quy ƒë·ªãnh hay th√¥ng tin ng√†nh h·ªçc?"

    # N·∫øu route l√† BOOKS ho·∫∑c MAJORS -> X·ª≠ l√Ω ri√™ng
    if route == "BOOKS":
        # ... (gi·ªØ nguy√™n logic BOOKS)
        pass 
    elif route == "MAJORS":
        # ... (gi·ªØ nguy√™n logic MAJORS)
        pass
    else:
        # Tr∆∞·ªùng h·ª£p c√≤n l·∫°i: FAQ ho·∫∑c C√ÅC CATEGORY C·ª§ TH·ªÇ (Gi·ªù m·ªü c·ª≠a, Li√™n h·ªá...)
        # N·∫øu route kh√¥ng ph·∫£i l√† "FAQ" chung chung, th√¨ n√≥ ch√≠nh l√† filter_category
        filter_cat = route if route != "FAQ" else None
        
        print(f"\n[DEBUG] Filter Category: {filter_cat}")

        # B∆Ø·ªöC 1: T√¨m TO√ÄN B·ªò FAQ (B·ªè l·ªçc Category ƒë·ªÉ tƒÉng Recall)
        # L√Ω do: Router ƒë√¥i khi ƒëo√°n sai (v√≠ d·ª•: "H∆∞·ªõng d·∫´n tr·∫£ s√°ch" -> ƒëo√°n l√† "Nhi·ªám v·ª•" thay v√¨ "Quy ƒë·ªãnh")
        # N·∫øu l·ªçc c·ª©ng s·∫Ω m·∫•t c√¢u tr·∫£ l·ªùi ƒë√∫ng.
        # Ta c·ª© l·∫•y Top 15 c√¢u li√™n quan nh·∫•t b·∫•t k·ªÉ ch·ªß ƒë·ªÅ, r·ªìi ƒë·ªÉ Rerank LLM ch·ªçn.
        candidates = search_faq_candidates(q_vec, top_k=20, filter_category=None)
            
        if not candidates:
            print("[DEBUG] ‚ùå Kh√¥ng t√¨m th·∫•y candidate n√†o (do ƒëi·ªÉm th·∫•p h∆°n ng∆∞·ª°ng).")
            return "Xin l·ªói, t√¥i ch∆∞a t√¨m th·∫•y th√¥ng tin ph√π h·ª£p trong c∆° s·ªü d·ªØ li·ªáu."

        print(f"[DEBUG] Found {len(candidates)} candidates:")
        for c in candidates:
            print(f"  - [{c['score']:.4f}] {c['answer'][:50]}... (Cat: {c['category']})")

        # Rerank
        best_cand = rerank_with_llm(rewritten, candidates)
        if not best_cand:
             print("[DEBUG] ‚ùå Rerank LLM t·ª´ ch·ªëi t·∫•t c·∫£ candidates.")
             # Fallback: l·∫•y top 1
             best_cand = candidates[0]
        else:
             print(f"[DEBUG] ‚úÖ Rerank ch·ªçn: {best_cand['answer'][:50]}...")

        # Strict Answer
        final_ans = strict_answer(rewritten, best_cand['answer'])
        return final_ans

    # Logic c≈© cho BOOKS v√† MAJORS (ƒë·ªÉ code kh√¥ng b·ªã l·ªói indentation, ta vi·∫øt l·∫°i ƒëo·∫°n n√†y)
    if route == "BOOKS":
        results = search_nonfaq("BOOKS", q_vec, top_k=5)
        if not results:
             return "Kh√¥ng t√¨m th·∫•y s√°ch n√†o ph√π h·ª£p."
        knowledge = "\n".join(results)
        return strict_answer(rewritten, knowledge)

    if route == "MAJORS":
        results = search_nonfaq("MAJORS", q_vec, top_k=5)
        if not results:
             return "Kh√¥ng t√¨m th·∫•y ng√†nh h·ªçc n√†o ph√π h·ª£p."
        knowledge = "\n".join(results)
        return strict_answer(rewritten, knowledge)
    
    return "Xin l·ªói, t√¥i kh√¥ng hi·ªÉu y√™u c·∫ßu."


# ============================================
#  CLI
# ============================================
if __name__ == "__main__":
    print("ü§ñ Chatbot 4-B∆Ø·ªöC (Router ‚Üí Rewrite ‚Üí Search+Rerank ‚Üí Strict Answer) ƒë√£ s·∫µn s√†ng!")
    while True:
        q = input("\nB·∫°n: ")
        if q.lower() in ["quit", "bye", "exit", "tho√°t"]:
            print("H·∫πn g·∫∑p l·∫°i b·∫°n ·ªü th∆∞ vi·ªán nh√©! üìö")
            break
        print("Bot:", process_message(q))
