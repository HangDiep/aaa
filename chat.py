# ============================================
#  CHATBOT 4-B∆Ø·ªöC ‚Äì HI·ªÇU NGHƒ®A, KH√îNG B·ªäA
#  Router (LLM + Embedding) ‚Üí Rewrite (LLM)
#  ‚Üí Search (Embedding + LLM Rerank) ‚Üí Strict Answer (LLM)
#  Model LLM:  qwen2.5:3b  (ollama)
#  Model Emb:  BAAI/bge-m3
# ============================================

import os
import re
import sqlite3
import requests
import numpy as np
from sentence_transformers import SentenceTransformer

FAQ_DB_PATH = "faq.db"
OLLAMA_URL = "http://127.0.0.1:11434"
MODEL = "qwen2.5:3b"
TIMEOUT = 20

FALLBACK_MSG = "Hi·ªán t·∫°i th∆∞ vi·ªán ch∆∞a c√≥ th√¥ng tin ch√≠nh x√°c cho c√¢u n√†y. B·∫°n m√¥ t·∫£ r√µ h∆°n gi√∫p m√¨nh nh√©."

# ============================================
#  EMBEDDING MODEL
# ============================================
print("ƒêang t·∫£i model embedding (l·∫ßn ƒë·∫ßu s·∫Ω h∆°i l√¢u)...")
try:
    embed_model = SentenceTransformer("BAAI/bge-m3")
except Exception as e:
    print(f"‚ö† L·ªói load model embedding: {e}")
    print("ƒêang d√πng fallback model (keepitreal/vietnamese-sbert)...")
    embed_model = SentenceTransformer("keepitreal/vietnamese-sbert")


# ============================================
#  TEXT NORMALIZE ‚Äì NH·∫∏, KH√îNG PH√Å NGHƒ®A
# ============================================
def normalize(x: str) -> str:
    # ch·ªâ lower + trim, kh√¥ng ƒë·ª•ng t·ªõi d·∫•u
    return " ".join(x.lower().strip().split())


# ============================================
#  OLLAMA LLM CALL
# ============================================
def llm(prompt: str, temp: float = 0.15, n: int = 128) -> str:
    try:
        r = requests.post(
            f"{OLLAMA_URL}/api/generate",
            json={
                "model": MODEL,
                "prompt": prompt,
                "stream": False,
                "options": {"temperature": temp, "num_predict": n},
            },
            timeout=TIMEOUT,
        )
        if r.status_code == 200:
            return r.json().get("response", "").strip()
    except Exception:
        pass
    return ""


# ============================================
#  LOAD & EMBED DB
# ============================================
print("ƒêang t·∫£i d·ªØ li·ªáu t·ª´ faq.db...")

if not os.path.exists(FAQ_DB_PATH):
    print(f"‚ùå Kh√¥ng t√¨m th·∫•y file {FAQ_DB_PATH}. H√£y ch·∫°y sync_all.py / sync_faq.py tr∆∞·ªõc!")
    # T·∫°o dummy ƒë·ªÉ kh√¥ng crash
    FAQ_TEXTS, BOOK_TEXTS, MAJOR_TEXTS = [], [], []
    FAQ_EMB = np.zeros((0, 768))
    BOOK_EMB = np.zeros((0, 768))
    MAJOR_EMB = np.zeros((0, 768))
    faq_rows, book_rows, major_rows = [], [], []
else:
    conn = sqlite3.connect(FAQ_DB_PATH)
    cur = conn.cursor()

    # FAQ
    cur.execute(
        "SELECT question, answer, category FROM faq WHERE approved = 1 OR approved IS NULL"
    )
    faq_rows = cur.fetchall()

    FAQ_TEXTS = []
    for q, a, cat in faq_rows:
        # Nh√∫ng Category + Answer ƒë·ªÉ t·∫°o chunk ki·∫øn th·ª©c r√µ nghƒ©a
        content = f"{cat or ''}: {a or ''}"
        FAQ_TEXTS.append(normalize(content))

    # BOOKS
    cur.execute(
        """
        SELECT b.name, b.author, b.year, b.quantity, b.status, m.name
        FROM books b LEFT JOIN majors m ON b.major_id = m.major_id
        """
    )
    book_rows = cur.fetchall()
    BOOK_TEXTS = [
        normalize(f"s√°ch {n}. t√°c gi·∫£ {a}. ng√†nh {m or ''}")
        for n, a, _, _, _, m in book_rows
    ]

    # MAJORS
    cur.execute("SELECT name, major_id, description FROM majors")
    major_rows = cur.fetchall()
    MAJOR_TEXTS = [
        normalize(f"ng√†nh {n}. m√£ {mid}. {desc or ''}")
        for n, mid, desc in major_rows
    ]

    conn.close()

    print("ƒêang t·∫°o embedding (l·∫ßn ƒë·∫ßu s·∫Ω h∆°i l√¢u)...")
    FAQ_EMB = (
        embed_model.encode(FAQ_TEXTS, normalize_embeddings=True)
        if FAQ_TEXTS
        else np.zeros((0, 768))
    )
    BOOK_EMB = (
        embed_model.encode(BOOK_TEXTS, normalize_embeddings=True)
        if BOOK_TEXTS
        else np.zeros((0, 768))
    )
    MAJOR_EMB = (
        embed_model.encode(MAJOR_TEXTS, normalize_embeddings=True)
        if MAJOR_TEXTS
        else np.zeros((0, 768))
    )

    print(f"‚úÖ ƒê√£ t·∫£i: FAQ={len(faq_rows)} | BOOKS={len(book_rows)} | MAJORS={len(major_rows)}")


# ============================================
#  ROUTER ‚Äì FALLBACK B·∫∞NG EMBEDDING (REAL DB)
# ============================================
def auto_route_by_embedding(q_vec: np.ndarray) -> str:
    """
    N·∫øu LLM ph√¢n lo·∫°i linh tinh ‚Üí d√πng embedding ch·ªçn b·∫£ng n√†o g·∫ßn nh·∫•t
    d·ª±a tr√™n d·ªØ li·ªáu th·∫≠t trong FAQ/BOOKS/MAJORS.
    """
    best_type = "FAQ"
    best_score = -1.0

    if len(FAQ_EMB) > 0:
        s = float(np.max(np.dot(FAQ_EMB, q_vec)))
        best_type, best_score = "FAQ", s

    if len(BOOK_EMB) > 0:
        s = float(np.max(np.dot(BOOK_EMB, q_vec)))
        if s > best_score:
            best_type, best_score = "BOOKS", s

    if len(MAJOR_EMB) > 0:
        s = float(np.max(np.dot(MAJOR_EMB, q_vec)))
        if s > best_score:
            best_type, best_score = "MAJORS", s

    return best_type


# ============================================
#  SIMPLE GREETING CHECK
# ============================================
def is_greeting(text: str) -> bool:
    t = text.lower().strip()
    greet_words = ["xin ch√†o", "ch√†o b·∫°n", "ch√†o ad", "hello", "hi", "alo"]
    return any(w in t for w in greet_words)


# ============================================
# 1) ROUTER ‚Äì 100% LLM + EMBEDDING (KH√îNG D√ôNG data.pth)
# ============================================
def route_llm(question: str, q_vec: np.ndarray) -> str:
    """
    HYBRID ROUTER:
    1. H·ªèi LLM (Reasoning): "C√¢u n√†y thu·ªôc nh√≥m n√†o?"
    2. N·∫øu LLM tr·∫£ ƒë√∫ng (BOOKS/MAJORS/FAQ) -> Tin n√≥.
    3. N·∫øu LLM tr·∫£ linh tinh -> D√πng auto_route_by_embedding (vector t·ª´ DB th·∫≠t).
    """
    # B0: Check Greeting nhanh
    if is_greeting(question) and len(question.split()) <= 4:
        print("[ROUTER] Detected GREETING")
        return "GREETING"

    # B1: D√πng LLM (Reasoning)
    prompt = f"""
Ph√¢n lo·∫°i c√¢u h·ªèi v√†o 1 trong 3 nh√≥m:
1. FAQ: Quy ƒë·ªãnh, th·ªß t·ª•c, gi·ªù m·ªü c·ª≠a, li√™n h·ªá, wifi, T·ªîNG S·ªê L∆Ø·ª¢NG t√†i li·ªáu, th·ªëng k√™, V·ªä TR√ç ph√≤ng ·ªëc, ƒë·ªãa ƒëi·ªÉm...
2. BOOKS: T√¨m s√°ch c·ª• th·ªÉ, gi√°o tr√¨nh, t√†i li·ªáu tham kh·∫£o, t√°c gi·∫£, ki·ªÉm tra s√°ch c√≤n kh√¥ng...
3. MAJORS: Ng√†nh h·ªçc, m√£ ng√†nh, ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o, khoa...

L∆ØU √ù: 
- H·ªèi v·ªÅ "T·ªïng s·ªë l∆∞·ª£ng" ho·∫∑c "Th·ªëng k√™" -> Ch·ªçn FAQ.
- H·ªèi v·ªÅ "·ªû ƒë√¢u", "Ph√≤ng n√†o", "T·∫ßng m·∫•y" -> Ch·ªçn FAQ.
- H·ªèi v·ªÅ "Quy tr√¨nh", "Th·ªß t·ª•c", "C√°ch m∆∞·ª£n/tr·∫£" -> Ch·ªçn FAQ (k·ªÉ c·∫£ c√≥ t·ª´ "s√°ch").

C√¢u h·ªèi: "{question}"

Ch·ªâ tr·∫£ v·ªÅ ƒë√∫ng 1 t·ª´: FAQ ho·∫∑c BOOKS ho·∫∑c MAJORS.
"""
    out = llm(prompt, temp=0.05, n=10)
    out_upper = (out or "").upper()
    print(f"[ROUTER LLM] Raw output: {out_upper!r}")

    if "FAQ" in out_upper:
        print("[ROUTER] ‚úÖ LLM ch·ªçn: FAQ")
        return "FAQ"
    if "BOOKS" in out_upper:
        print("[ROUTER] ‚úÖ LLM ch·ªçn: BOOKS")
        return "BOOKS"
    if "MAJORS" in out_upper:
        print("[ROUTER] ‚úÖ LLM ch·ªçn: MAJORS")
        return "MAJORS"

    # B2: Fallback = Vector theo DB th·∫≠t
    print("[ROUTER] ‚ö†Ô∏è LLM kh√¥ng ch·∫Øc ch·∫Øn -> D√πng auto_route_by_embedding (Real DB)...")
    fallback_route = auto_route_by_embedding(q_vec)
    print(f"[ROUTER] -> Vector (DB) ch·ªçn: {fallback_route}")
    return fallback_route


# ============================================
# 2) REWRITE ‚Äì KH√îNG ƒê·ª§NG C√ÇU QU√Å NG·∫ÆN
# ============================================
def rewrite_question(q: str) -> str:
    if len(q.split()) < 2:
        return q

    prompt = f"""
B·∫°n l√† m·ªôt tr·ª£ l√Ω th√¥ng minh. H√£y ƒê·ªåC HI·ªÇU √Ω ƒë·ªãnh c·ªßa ng∆∞·ªùi d√πng v√† vi·∫øt l·∫°i c√¢u h·ªèi sao cho r√µ r√†ng, ƒë·∫ßy ƒë·ªß nghƒ©a nh·∫•t.
N·∫øu c√¢u h·ªèi qu√° ng·∫Øn, d√πng t·ª´ ƒëa nghƒ©a ho·∫∑c thi·∫øu ch·ªß ng·ªØ, h√£y di·ªÖn gi·∫£i l·∫°i theo c√°ch ng∆∞·ªùi b√¨nh th∆∞·ªùng s·∫Ω h·ªèi ƒë·∫ßy ƒë·ªß.
ƒê·∫∂C BI·ªÜT:
- N·∫øu h·ªèi v·ªÅ "s·ªë", "g·ªçi", "alo" -> Th√™m t·ª´ kh√≥a "s·ªë ƒëi·ªán tho·∫°i li√™n h·ªá hotline".
- N·∫øu h·ªèi v·ªÅ "·ªü ƒë√¢u", "ch·ªó n√†o" -> Th√™m t·ª´ kh√≥a "ƒë·ªãa ƒëi·ªÉm v·ªã tr√≠".

V√≠ d·ª•:
- "s·ªë n√†o" -> "s·ªë ƒëi·ªán tho·∫°i li√™n h·ªá hotline l√† g√¨"
- "m·ªü c·ª≠a ko" -> "gi·ªù m·ªü c·ª≠a ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o"
- "li√™n h·ªá sao" -> "c√°ch th·ª©c li√™n h·ªá v·ªõi th∆∞ vi·ªán"

C√¢u g·ªëc: "{q}"

C√¢u vi·∫øt l·∫°i (ch·ªâ vi·∫øt 1 c√¢u duy nh·∫•t):
"""
    out = llm(prompt, temp=0.1, n=64)
    return out.strip() if out else q


# ============================================
# 3A) SEMANTIC SEARCH CHO FAQ
# ============================================
def search_faq_candidates(q_vec: np.ndarray, top_k: int = 10, filter_category: str = None):
    if len(FAQ_EMB) == 0:
        return []

    sims = np.dot(FAQ_EMB, q_vec)
    idx = np.argsort(-sims)[:top_k]

    candidates = []
    for i in idx:
        score = float(sims[i])
        if score < 0.08:
            continue

        q, a, cat = faq_rows[i]

        if filter_category and filter_category not in ["FAQ", "BOOKS", "MAJORS", "GREETING"]:
            if cat != filter_category:
                continue

        candidates.append(
            {
                "score": score,
                "question": q or "",
                "answer": a or "",
                "category": cat or "",
                "id": i,
            }
        )
    return candidates


# ============================================
# 3B) SEMANTIC SEARCH CHO BOOKS / MAJORS
# ============================================
def search_nonfaq(table: str, q_vec: np.ndarray, top_k: int = 10):
    candidates = []

    if table == "BOOKS":
        if len(BOOK_EMB) == 0:
            return []
        sims = np.dot(BOOK_EMB, q_vec)
        rows = book_rows
        th = 0.15
        idx = np.argsort(-sims)[:top_k]
        for i in idx:
            score = float(sims[i])
            if score < th:
                continue
            n, a, y, qty, s, m = rows[i]
            content = (
                f"S√°ch: {n}. T√°c gi·∫£: {a}. NƒÉm: {y}. "
                f"S·ªë l∆∞·ª£ng: {qty}. T√¨nh tr·∫°ng: {s}. Ng√†nh: {m or 'Chung'}"
            )
            candidates.append({
                "score": score,
                "question": "",
                "answer": content,
                "category": "BOOKS",
                "id": i
            })
        return candidates

    # MAJORS
    if len(MAJOR_EMB) == 0:
        return []
    sims = np.dot(MAJOR_EMB, q_vec)
    rows = major_rows
    th = 0.20
    idx = np.argsort(-sims)[:top_k]
    for i in idx:
        score = float(sims[i])
        if score < th:
            continue
        name, code, desc = rows[i]
        content = f"Ng√†nh: {name}. M√£ ng√†nh: {code}. M√¥ t·∫£: {desc or 'ƒêang c·∫≠p nh·∫≠t'}"
        candidates.append({
            "score": score,
            "question": "",
            "answer": content,
            "category": "MAJORS",
            "id": i
        })
    return candidates


# ============================================
# 3C) LLM RERANK CHO FAQ/BOOKS/MAJORS
# ============================================
def rerank_with_llm(user_q: str, candidates: list):
    if not candidates:
        return None

    block = ""
    for i, c in enumerate(candidates, start=1):
        block += f"{i}. [{c['category']}] {c['answer']}\n"

    prompt = f"""
B·∫°n l√† chuy√™n gia t∆∞ v·∫•n th√¥ng minh.
Nhi·ªám v·ª•: T√¨m c√¢u tr·∫£ l·ªùi PH√ô H·ª¢P NH·∫§T cho c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng trong danh s√°ch b√™n d∆∞·ªõi.

C√¢u h·ªèi: "{user_q}"

Danh s√°ch ·ª©ng vi√™n:
{block}

H∆Ø·ªöNG D·∫™N T∆Ø DUY:
- H√£y hi·ªÉu √ù NGHƒ®A c·ªßa c√¢u h·ªèi (kh√¥ng ch·ªâ b·∫Øt t·ª´ kh√≥a).
- V√≠ d·ª•: H·ªèi "Fanpage" th√¨ c√¢u ch·ª©a "Facebook" l√† ƒë√∫ng. H·ªèi "Quy tr√¨nh" th√¨ c√¢u h∆∞·ªõng d·∫´n c√°c b∆∞·ªõc l√† ƒë√∫ng.
- N·∫øu c√¢u h·ªèi t√¨m "ƒê·ªãa ƒëi·ªÉm" (·ªü ƒë√¢u), h√£y ch·ªçn c√¢u ch·ª©a th√¥ng tin v·ªã tr√≠.
- N·∫øu c√¢u h·ªèi t√¨m "Danh s√°ch" (g·ªìm nh·ªØng g√¨), h√£y ch·ªçn c√¢u li·ªát k√™ ƒë·∫ßy ƒë·ªß nh·∫•t.

Y√äU C·∫¶U:
- N·∫øu t√¨m th·∫•y c√¢u tr·∫£ l·ªùi ph√π h·ª£p: Tr·∫£ v·ªÅ S·ªê TH·ª® T·ª∞ (v√≠ d·ª•: 1, 2...).
- N·∫øu kh√¥ng c√≥ c√¢u n√†o kh·ªõp: Tr·∫£ v·ªÅ 0.

Ch·ªâ tr·∫£ v·ªÅ 1 con s·ªë duy nh·∫•t.
"""
    out = llm(prompt, temp=0.1, n=128).strip()

    match = re.search(r'\d+', out)
    if match:
        idx = int(match.group()) - 1
        if 0 <= idx < len(candidates):
            return candidates[idx]

    # Fallback: tin top 1 n·∫øu score r·∫•t cao
    if candidates and candidates[0]['score'] > 0.45:
        print(f"[Rerank] LLM t·ª´ ch·ªëi, nh∆∞ng Top 1 score cao ({candidates[0]['score']:.2f}) -> Ch·ªçn Top 1.")
        return candidates[0]

    return None


def strict_answer(question: str, knowledge: str) -> str:
    print(f"[DEBUG STRICT] Q: {question} | Knowledge: {knowledge[:50]}...")
    prompt = f"""
B·∫°n l√† tr·ª£ l√Ω ·∫£o c·ªßa th∆∞ vi·ªán. 
NHI·ªÜM V·ª§: Tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n th√¥ng tin cung c·∫•p b√™n d∆∞·ªõi.

TH√îNG TIN (KNOWLEDGE):
{knowledge}

C√ÇU H·ªéI (QUESTION): "{question}"

QUY T·∫ÆC B·∫ÆT BU·ªòC:
1. ‚ö†Ô∏è TUY·ªÜT ƒê·ªêI TR·∫¢ L·ªúI B·∫∞NG TI·∫æNG VI·ªÜT.
2. N·∫øu th√¥ng tin c√≥ v·∫ª li√™n quan (d√π ch·ªâ m·ªôt ph·∫ßn), H√ÉY TR·∫¢ L·ªúI NGAY.
3. V√≠ d·ª•: H·ªèi "s√°ch c√¥ng ngh·ªá" m√† c√≥ "C√¥ng ngh·ªá ph·∫ßn m·ªÅm" -> TR·∫¢ L·ªúI th√¥ng tin s√°ch ƒë√≥.
4. N·∫øu th√¥ng tin l√† danh s√°ch, h√£y tr√≠ch xu·∫•t √Ω ch√≠nh.
5. ‚ö†Ô∏è ƒê·ªêI V·ªöI T√äN RI√äNG (T√°c gi·∫£, T√™n s√°ch, Ng∆∞·ªùi li√™n h·ªá...): PH·∫¢I TR√çCH XU·∫§T CH√çNH X√ÅC 100%, KH√îNG ƒê∆Ø·ª¢C R√öT G·ªåN.
6. N·∫øu c√¢u h·ªèi d√πng t·ª´ ƒë·ªìng nghƒ©a, h√£y t·ª± suy lu·∫≠n.
7. N·∫øu c√≥ s·ªë li·ªáu/th·ªëng k√™, h√£y ƒë∆∞a ra con s·ªë ƒë√≥.
8. Tuy·ªát ƒë·ªëi KH√îNG tr·∫£ l·ªùi "{FALLBACK_MSG}" n·∫øu b·∫°n t√¨m th·∫•y th√¥ng tin li√™n quan.

N·∫øu th√¥ng tin HO√ÄN TO√ÄN KH√îNG LI√äN QUAN th√¨ m·ªõi n√≥i: "{FALLBACK_MSG}"

C√¢u tr·∫£ l·ªùi c·ªßa b·∫°n (Ti·∫øng Vi·ªát):
"""
    out = llm(prompt, temp=0.05, n=256)
    print(f"[DEBUG STRICT OUT] {out}")

    if not out:
        return FALLBACK_MSG

    out = out.strip()

    # Ch·∫•p nh·∫≠n c√¢u tr·∫£ l·ªùi c√≥ s·ªë / email / link
    if any(c.isdigit() for c in out) or "@" in out or "http" in out:
        return out

    if "kh√¥ng c√≥ th√¥ng tin" in out.lower() and len(out) < 15:
        return FALLBACK_MSG

    return out


# ============================================
#  MAIN PROCESS
# ============================================
def process_message(text: str) -> str:
    print("[CHAT.PY] ƒê√É G·ªåI N√ÉO")
    if not text.strip():
        return "Xin ch√†o üëã B·∫°n mu·ªën h·ªèi th√¥ng tin g√¨ trong th∆∞ vi·ªán?"

    # B0: vector cho router
    q_vec_route = embed_model.encode(normalize(text), normalize_embeddings=True)

    # B1: Router (LLM + Embedding)
    route = route_llm(text, q_vec_route)

    # B2: Rewrite
    rewritten = rewrite_question(text)
    q_vec = embed_model.encode(normalize(rewritten), normalize_embeddings=True)


    if route == "GREETING":
        return "Xin ch√†o! T√¥i l√† tr·ª£ l√Ω ·∫£o th∆∞ vi·ªán. B·∫°n c·∫ßn t√¨m s√°ch, h·ªèi quy ƒë·ªãnh hay th√¥ng tin ng√†nh h·ªçc?"

    # BOOKS
    if route == "BOOKS":
        candidates = search_nonfaq("BOOKS", q_vec, top_k=15)
        if not candidates:
            return "Kh√¥ng t√¨m th·∫•y s√°ch n√†o ph√π h·ª£p."

        print(f"[DEBUG BOOKS] Found {len(candidates)} candidates.")
        best_cand = rerank_with_llm(rewritten, candidates)
        if not best_cand:
            best_cand = candidates[0]

        return strict_answer(rewritten, best_cand['answer'])

    # MAJORS
    if route == "MAJORS":
        candidates = search_nonfaq("MAJORS", q_vec, top_k=15)
        if not candidates:
            return "Kh√¥ng t√¨m th·∫•y ng√†nh h·ªçc n√†o ph√π h·ª£p."

        print(f"[DEBUG MAJORS] Found {len(candidates)} candidates.")
        best_cand = rerank_with_llm(rewritten, candidates)
        if not best_cand:
            best_cand = candidates[0]

        return strict_answer(rewritten, best_cand['answer'])

    # M·∫∑c ƒë·ªãnh: FAQ
    filter_cat = None  # hi·ªán t·∫°i ch∆∞a l·ªçc theo category nh·ªè
    print(f"\n[DEBUG] Filter Category: {filter_cat}")

    candidates = search_faq_candidates(q_vec, top_k=20, filter_category=None)

    if not candidates:
        print("[DEBUG] ‚ùå Kh√¥ng t√¨m th·∫•y candidate n√†o (do ƒëi·ªÉm th·∫•p h∆°n ng∆∞·ª°ng).")
        return "Xin l·ªói, t√¥i ch∆∞a t√¨m th·∫•y th√¥ng tin ph√π h·ª£p trong c∆° s·ªü d·ªØ li·ªáu."

    print(f"[DEBUG] Found {len(candidates)} candidates:")
    for c in candidates:
        print(f"  - [{c['score']:.4f}] {c['answer'][:50]}... (Cat: {c['category']})")

    best_cand = rerank_with_llm(rewritten, candidates)
    if not best_cand:
        print("[DEBUG] ‚ùå Rerank LLM t·ª´ ch·ªëi t·∫•t c·∫£ candidates. L·∫•y Top 1.")
        best_cand = candidates[0]
    else:
        print(f"[DEBUG] ‚úÖ Rerank ch·ªçn: {best_cand['answer'][:50]}...")

    final_ans = strict_answer(rewritten, best_cand['answer'])
    return final_ans


# ============================================
#  CLI
# ============================================
if __name__ == "__main__":
    print("ü§ñ Chatbot 4-B∆Ø·ªöC (Router ‚Üí Rewrite ‚Üí Search+Rerank ‚Üí Strict Answer) ƒë√£ s·∫µn s√†ng!")
    while True:
        q = input("\nB·∫°n: ")
        if q.lower() in ["quit", "bye", "exit", "tho√°t"]:
            print("H·∫πn g·∫∑p l·∫°i b·∫°n ·ªü th∆∞ vi·ªán nh√©! üìö")
            break
        print("Bot:", process_message(q))
