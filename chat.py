# ============================================
#  CHATBOT 4-B∆Ø·ªöC ‚Äì HI·ªÇU NGHƒ®A, KH√îNG B·ªäA
#  Router (LLM + Embedding) ‚Üí Rewrite (LLM)
#  ‚Üí Search (Embedding + LLM Rerank) ‚Üí Strict Answer (LLM)
#  Model LLM:  Groq (Split Strategy: 8B & 70B)
#  Model Emb:  BAAI/bge-m3
# ============================================

import os
import re
import sqlite3
import numpy as np
from sentence_transformers import SentenceTransformer
import requests
import time
import random
from dotenv import load_dotenv

# ==== C·∫§U H√åNH GROQ (SPLIT MODEL STRATEGY) ====
GROQ_MODEL_SMART = "llama-3.3-70b-versatile"  # D√πng cho Rerank, Answer (Th√¥ng minh)
GROQ_MODEL_FAST = "llama-3.1-8b-instant"      # D√πng cho Router, Rewrite (T·ªëc ƒë·ªô)
GROQ_API_KEY = "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"

FAQ_DB_PATH = r"D:\HTML\a - Copy\faq.db"
ENV_PATH = r"D:\HTML\a - Copy\rag\.env"

# Load .env
try:
    if os.path.exists(ENV_PATH):
        load_dotenv(ENV_PATH, override=True)
    else:
        load_dotenv()
except Exception:
    pass

if not GROQ_API_KEY:
    print("‚ö† Ch∆∞a c√≥ GROQ_API_KEY.")
else:
    print(f"‚úÖ ƒê√£ c·∫•u h√¨nh Groq (Smart: 70B | Fast: 8B).")

FALLBACK_MSG = "Hi·ªán t·∫°i th∆∞ vi·ªán ch∆∞a c√≥ th√¥ng tin ch√≠nh x√°c cho c√¢u n√†y. B·∫°n m√¥ t·∫£ r√µ h∆°n gi√∫p m√¨nh nh√©."

# ============================================
#  EMBEDDING MODEL
# ============================================
print("ƒêang t·∫£i model embedding (l·∫ßn ƒë·∫ßu s·∫Ω h∆°i l√¢u)...")
try:
    embed_model = SentenceTransformer("BAAI/bge-m3")
except Exception as e:
    print(f"‚ö† L·ªói load model embedding: {e}")
    print("ƒêang d√πng fallback model (keepitreal/vietnamese-sbert)...")
    embed_model = SentenceTransformer("keepitreal/vietnamese-sbert")


# ============================================
#  TEXT NORMALIZE
# ============================================
def normalize(x: str) -> str:
    return " ".join(x.lower().strip().split())


# ============================================
#  LLM CALL (GROQ DIRECT)
# ============================================
def llm(prompt: str, temp: float = 0.15, n: int = 1024, model: str = GROQ_MODEL_SMART) -> str:
    """
    G·ªçi Groq API tr·ª±c ti·∫øp v·ªõi c∆° ch·∫ø RETRY ƒê∆†N GI·∫¢N (Linear Backoff).
    H·ªó tr·ª£ ch·ªçn Model (Fast vs Smart).
    """
    if not GROQ_API_KEY:
        return ""

    headers = {
        "Authorization": f"Bearer {GROQ_API_KEY}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "model": model,
        "messages": [
            {"role": "user", "content": prompt}
        ],
        "temperature": temp,
        "max_tokens": n,
    }

    max_retries = 3
    fixed_delay = 2.0  # Ch·ªù c·ªë ƒë·ªãnh 2 gi√¢y n·∫øu l·ªói

    for attempt in range(max_retries):
        try:
            resp = requests.post(
                "https://api.groq.com/openai/v1/chat/completions",
                headers=headers,
                json=payload,
                timeout=15
            )
            
            if resp.status_code == 200:
                data = resp.json()
                return data["choices"][0]["message"]["content"].strip()
            
            if resp.status_code == 429:
                print(f"‚ö† Groq qu√° t·∫£i (429). ƒêang ch·ªù {fixed_delay}s ƒë·ªÉ th·ª≠ l·∫°i ({attempt+1}/{max_retries})...")
                time.sleep(fixed_delay)
                continue
                
            print(f"‚ö† L·ªói Groq {resp.status_code}: {resp.text}")
            return ""

        except Exception as e:
            print(f"‚ö† L·ªói g·ªçi Groq: {e}")
            return ""
    
    print("‚ùå ƒê√£ th·ª≠ l·∫°i 3 l·∫ßn nh∆∞ng Groq v·∫´n b·∫≠n.")
    return ""


# ============================================
#  LOAD & EMBED DB
# ============================================
print("ƒêang t·∫£i d·ªØ li·ªáu t·ª´ faq.db...")

if not os.path.exists(FAQ_DB_PATH):
    print(f"‚ùå Kh√¥ng t√¨m th·∫•y file {FAQ_DB_PATH}. H√£y ch·∫°y sync_all.py / sync_faq.py tr∆∞·ªõc!")
    FAQ_TEXTS, BOOK_TEXTS, MAJOR_TEXTS = [], [], []
    FAQ_EMB = np.zeros((0, 768))
    BOOK_EMB = np.zeros((0, 768))
    MAJOR_EMB = np.zeros((0, 768))
    faq_rows, book_rows, major_rows = [], [], []
else:
    conn = sqlite3.connect(FAQ_DB_PATH)
    cur = conn.cursor()

    # FAQ
    cur.execute("SELECT question, answer, category FROM faq WHERE approved = 1 OR approved IS NULL")
    faq_rows = cur.fetchall()
    FAQ_TEXTS = [normalize(f"{cat or ''}: {a or ''}") for _, a, cat in faq_rows]

    # BOOKS
    cur.execute("""
        SELECT b.name, b.author, b.year, b.quantity, b.status, m.name
        FROM books b LEFT JOIN majors m ON b.major_id = m.major_id
    """)
    book_rows = cur.fetchall()
    BOOK_TEXTS = [normalize(f"s√°ch {n}. t√°c gi·∫£ {a}. ng√†nh {m or ''}") for n, a, _, _, _, m in book_rows]

    # MAJORS
    cur.execute("SELECT name, major_id, description FROM majors")
    major_rows = cur.fetchall()
    MAJOR_TEXTS = [normalize(f"ng√†nh {n}. m√£ {mid}. {desc or ''}") for n, mid, desc in major_rows]

    conn.close()

    print("ƒêang t·∫°o embedding (l·∫ßn ƒë·∫ßu s·∫Ω h∆°i l√¢u)...")
    FAQ_EMB = embed_model.encode(FAQ_TEXTS, normalize_embeddings=True) if FAQ_TEXTS else np.zeros((0, 768))
    BOOK_EMB = embed_model.encode(BOOK_TEXTS, normalize_embeddings=True) if BOOK_TEXTS else np.zeros((0, 768))
    MAJOR_EMB = embed_model.encode(MAJOR_TEXTS, normalize_embeddings=True) if MAJOR_TEXTS else np.zeros((0, 768))

    print(f"‚úÖ ƒê√£ t·∫£i: FAQ={len(faq_rows)} | BOOKS={len(book_rows)} | MAJORS={len(major_rows)}")


# ============================================
#  ROUTER ‚Äì FALLBACK B·∫∞NG EMBEDDING
# ============================================
def auto_route_by_embedding(q_vec: np.ndarray) -> str:
    best_type = "FAQ"
    best_score = -1.0

    if len(FAQ_EMB) > 0:
        s = float(np.max(np.dot(FAQ_EMB, q_vec)))
        best_type, best_score = "FAQ", s

    if len(BOOK_EMB) > 0:
        s = float(np.max(np.dot(BOOK_EMB, q_vec)))
        if s > best_score:
            best_type, best_score = "BOOKS", s

    if len(MAJOR_EMB) > 0:
        s = float(np.max(np.dot(MAJOR_EMB, q_vec)))
        if s > best_score:
            best_type, best_score = "MAJORS", s

    return best_type


def is_greeting(text: str) -> bool:
    t = text.lower().strip()
    greet_words = ["xin ch√†o", "ch√†o b·∫°n", "ch√†o ad", "hello", "hi", "alo"]
    return any(w in t for w in greet_words)


# ============================================
# 1) ROUTER ‚Äì D√ôNG MODEL FAST (8B)
# ============================================
def route_llm(question: str, q_vec: np.ndarray) -> str:
    if is_greeting(question) and len(question.split()) <= 4:
        print("[ROUTER] Detected GREETING")
        return "GREETING"

    prompt = f"""
Ph√¢n lo·∫°i c√¢u h·ªèi v√†o 1 trong 3 nh√≥m d·ª±a tr√™n B·∫¢N CH·∫§T:

1. BOOKS (S√°ch & T√†i li·ªáu):
   - Ch·ªâ ch·ªçn khi ng∆∞·ªùi d√πng t√¨m ki·∫øm T√ÄI LI·ªÜU, S√ÅCH, GI√ÅO TR√åNH, LU·∫¨N VƒÇN c·ª• th·ªÉ.
   - V√≠ d·ª•: "T√¨m s√°ch Python", "Gi√°o tr√¨nh Kinh t·∫ø l∆∞·ª£ng", "T√†i li·ªáu v·ªÅ AI".

2. MAJORS (Ng√†nh h·ªçc & ƒê√†o t·∫°o):
   - Ch·ªâ ch·ªçn khi ng∆∞·ªùi d√πng h·ªèi v·ªÅ CH∆Ø∆†NG TR√åNH ƒê√ÄO T·∫†O, TUY·ªÇN SINH, KHOA/VI·ªÜN.
   - V√≠ d·ª•: "Ng√†nh CNTT h·ªçc g√¨", "M√£ ng√†nh 7480201", "Khoa Lu·∫≠t ·ªü ƒë√¢u".

3. FAQ (Th√¥ng tin chung & Kh√°c):
   - T·∫§T C·∫¢ c√°c c√¢u h·ªèi c√≤n l·∫°i.
   - Bao g·ªìm: Quy ƒë·ªãnh, Th·ªß t·ª•c, Gi·ªù l√†m vi·ªác, Wifi, T√†i kho·∫£n.
   - Bao g·ªìm: C∆† S·ªû V·∫¨T CH·∫§T, ƒê·ªäA ƒêI·ªÇM (Ph√≤ng ·ªëc, Canteen, B√£i xe...), S·ª∞ KI·ªÜN.
   - Bao g·ªìm: S·ªê L∆Ø·ª¢NG, TH·ªêNG K√ä (T·ªïng s·ªë s√°ch, C√≥ bao nhi√™u t√†i li·ªáu...).

L∆ØU √ù ∆ØU TI√äN:
- H·ªèi v·ªÅ "T·ªïng s·ªë l∆∞·ª£ng", "Th·ªëng k√™", "C√≥ bao nhi√™u" -> CH·ªåN FAQ (k·ªÉ c·∫£ c√≥ t·ª´ "s√°ch").
- H·ªèi v·ªÅ "·ªû ƒë√¢u", "Ph√≤ng n√†o", "T·∫ßng m·∫•y" (V·ªã tr√≠) -> CH·ªåN FAQ (k·ªÉ c·∫£ c√≥ t·ª´ "s√°ch").
- N·∫øu c√¢u h·ªèi kh√¥ng r√µ r√†ng -> CH·ªåN FAQ.

C√¢u h·ªèi: "{question}"

Ch·ªâ tr·∫£ v·ªÅ ƒë√∫ng 1 t·ª´: FAQ ho·∫∑c BOOKS ho·∫∑c MAJORS.
"""
    # D√ôNG MODEL FAST (8B)
    out = llm(prompt, temp=0.05, n=10, model=GROQ_MODEL_FAST).upper().strip()
    clean_out = re.sub(r'[^A-Z]', '', out)
    print(f"[ROUTER LLM] Output: '{out}' -> Clean: '{clean_out}'")

    if clean_out in ["FAQ", "BOOKS", "MAJORS"]:
        print(f"[ROUTER] ‚úÖ LLM ch·ªçn: {clean_out}")
        return clean_out

    print(f"[ROUTER] ‚ö†Ô∏è LLM kh√¥ng ch·∫Øc ch·∫Øn -> D√πng auto_route_by_embedding (Real DB)...")
    return auto_route_by_embedding(q_vec)


# ============================================
# 2) REWRITE ‚Äì D√ôNG MODEL FAST (8B)
# ============================================
def rewrite_question(q: str) -> str:
    if len(q.split()) < 2:
        return q

    prompt = f"""
B·∫°n l√† m·ªôt tr·ª£ l√Ω th√¥ng minh. H√£y ƒê·ªåC HI·ªÇU √Ω ƒë·ªãnh c·ªßa ng∆∞·ªùi d√πng v√† vi·∫øt l·∫°i c√¢u h·ªèi sao cho r√µ r√†ng, ƒë·∫ßy ƒë·ªß nghƒ©a nh·∫•t.
N·∫øu c√¢u h·ªèi qu√° ng·∫Øn, d√πng t·ª´ ƒëa nghƒ©a ho·∫∑c thi·∫øu ch·ªß ng·ªØ, h√£y di·ªÖn gi·∫£i l·∫°i theo c√°ch ng∆∞·ªùi b√¨nh th∆∞·ªùng s·∫Ω h·ªèi ƒë·∫ßy ƒë·ªß.
ƒê·∫∂C BI·ªÜT:
- N·∫øu h·ªèi v·ªÅ "s·ªë", "g·ªçi", "alo" -> Th√™m t·ª´ kh√≥a "s·ªë ƒëi·ªán tho·∫°i li√™n h·ªá hotline".
- N·∫øu h·ªèi v·ªÅ "·ªü ƒë√¢u", "ch·ªó n√†o" -> Th√™m t·ª´ kh√≥a "ƒë·ªãa ƒëi·ªÉm v·ªã tr√≠".

V√≠ d·ª•:
- "s·ªë n√†o" -> "s·ªë ƒëi·ªán tho·∫°i li√™n h·ªá hotline l√† g√¨"
- "m·ªü c·ª≠a ko" -> "gi·ªù m·ªü c·ª≠a ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o"
- "li√™n h·ªá sao" -> "c√°ch th·ª©c li√™n h·ªá v·ªõi th∆∞ vi·ªán"

C√¢u g·ªëc: "{q}"

C√¢u vi·∫øt l·∫°i (ch·ªâ vi·∫øt 1 c√¢u duy nh·∫•t):
"""
    # D√ôNG MODEL FAST (8B)
    out = llm(prompt, temp=0.1, n=64, model=GROQ_MODEL_FAST)
    return out.strip() if out else q


# ============================================
# 3A) SEMANTIC SEARCH CHO FAQ
# ============================================
def search_faq_candidates(q_vec: np.ndarray, top_k: int = 10, filter_category: str = None):
    if len(FAQ_EMB) == 0: return []
    sims = np.dot(FAQ_EMB, q_vec)
    idx = np.argsort(-sims)[:top_k]
    candidates = []
    for i in idx:
        score = float(sims[i])
        if score < 0.08: continue
        q, a, cat = faq_rows[i]
        if filter_category and filter_category not in ["FAQ", "BOOKS", "MAJORS", "GREETING"]:
            if cat != filter_category: continue
        candidates.append({"score": score, "question": q or "", "answer": a or "", "category": cat or "", "id": i})
    return candidates


# ============================================
# 3B) SEMANTIC SEARCH CHO BOOKS / MAJORS
# ============================================
def search_nonfaq(table: str, q_vec: np.ndarray, top_k: int = 10):
    candidates = []
    if table == "BOOKS":
        if len(BOOK_EMB) == 0: return []
        sims = np.dot(BOOK_EMB, q_vec)
        rows = book_rows
        th = 0.15
        idx = np.argsort(-sims)[:top_k]
        for i in idx:
            score = float(sims[i])
            if score < th: continue
            n, a, y, qty, s, m = rows[i]
            content = f"S√°ch: {n}. T√°c gi·∫£: {a}. NƒÉm: {y}. S·ªë l∆∞·ª£ng: {qty}. T√¨nh tr·∫°ng: {s}. Ng√†nh: {m or 'Chung'}"
            candidates.append({"score": score, "question": "", "answer": content, "category": "BOOKS", "id": i})
        return candidates

    if len(MAJOR_EMB) == 0: return []
    sims = np.dot(MAJOR_EMB, q_vec)
    rows = major_rows
    th = 0.20
    idx = np.argsort(-sims)[:top_k]
    for i in idx:
        score = float(sims[i])
        if score < th: continue
        name, code, desc = rows[i]
        content = f"Ng√†nh: {name}. M√£ ng√†nh: {code}. M√¥ t·∫£: {desc or 'ƒêang c·∫≠p nh·∫≠t'}"
        candidates.append({"score": score, "question": "", "answer": content, "category": "MAJORS", "id": i})
    return candidates


# ============================================
# 3C) LLM RERANK ‚Äì D√ôNG MODEL SMART (70B)
# ============================================
def rerank_with_llm(user_q: str, candidates: list):
    if not candidates: return None
    block = ""
    for i, c in enumerate(candidates, start=1):
        block += f"{i}. [{c['category']}] {c['answer']}\n"

    prompt = f"""
B·∫°n l√† chuy√™n gia t∆∞ v·∫•n th√¥ng minh.
Nhi·ªám v·ª•: T√¨m c√¢u tr·∫£ l·ªùi PH√ô H·ª¢P NH·∫§T cho c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng trong danh s√°ch b√™n d∆∞·ªõi.

C√¢u h·ªèi: "{user_q}"

Danh s√°ch ·ª©ng vi√™n:
{block}

H∆Ø·ªöNG D·∫™N T∆Ø DUY:
- H√£y hi·ªÉu √ù NGHƒ®A c·ªßa c√¢u h·ªèi (kh√¥ng ch·ªâ b·∫Øt t·ª´ kh√≥a).
- N·∫øu c√¢u h·ªèi t√¨m "ƒê·ªãa ƒëi·ªÉm" (·ªü ƒë√¢u), h√£y ch·ªçn c√¢u ch·ª©a th√¥ng tin v·ªã tr√≠.
- N·∫øu c√¢u h·ªèi t√¨m "Danh s√°ch" (g·ªìm nh·ªØng g√¨), h√£y ch·ªçn c√¢u li·ªát k√™ ƒë·∫ßy ƒë·ªß nh·∫•t.

Y√äU C·∫¶U:
- N·∫øu t√¨m th·∫•y c√¢u tr·∫£ l·ªùi ph√π h·ª£p: Tr·∫£ v·ªÅ S·ªê TH·ª® T·ª∞ (v√≠ d·ª•: 1, 2...).
- N·∫øu kh√¥ng c√≥ c√¢u n√†o kh·ªõp: Tr·∫£ v·ªÅ 0.

Ch·ªâ tr·∫£ v·ªÅ 1 con s·ªë duy nh·∫•t.
"""
    # D√ôNG MODEL SMART (70B)
    out = llm(prompt, temp=0.1, n=128, model=GROQ_MODEL_SMART).strip()
    match = re.search(r'\d+', out)
    if match:
        idx = int(match.group()) - 1
        if 0 <= idx < len(candidates):
            return candidates[idx]

    if candidates and candidates[0]['score'] > 0.45:
        print(f"[Rerank] LLM t·ª´ ch·ªëi, nh∆∞ng Top 1 score cao ({candidates[0]['score']:.2f}) -> Ch·ªçn Top 1.")
        return candidates[0]
    return None


# ============================================
# 4) STRICT ANSWER ‚Äì D√ôNG MODEL SMART (70B)
# ============================================
def strict_answer(question: str, knowledge: str) -> str:
    print(f"[DEBUG STRICT] Q: {question} | Knowledge: {knowledge[:50]}...")
    prompt = f"""
B·∫°n l√† tr·ª£ l√Ω ·∫£o c·ªßa th∆∞ vi·ªán. 
NHI·ªÜM V·ª§: Tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n th√¥ng tin cung c·∫•p b√™n d∆∞·ªõi.

TH√îNG TIN (KNOWLEDGE):
{knowledge}

C√ÇU H·ªéI (QUESTION): "{question}"

QUY T·∫ÆC:
1. Tr·∫£ l·ªùi ng·∫Øn g·ªçn, ƒë√∫ng tr·ªçng t√¢m b·∫±ng Ti·∫øng Vi·ªát.
2. D√πng th√¥ng tin trong ph·∫ßn KNOWLEDGE ƒë·ªÉ tr·∫£ l·ªùi.
3. N·∫øu th√¥ng tin c√≥ ch·ª©a s·ªë li·ªáu, ƒë·ªãa ƒëi·ªÉm, quy tr√¨nh -> H√£y tr√≠ch xu·∫•t ra ƒë·ªÉ tr·∫£ l·ªùi.
4. N·∫øu th√¥ng tin kh√¥ng kh·ªõp ho√†n to√†n nh∆∞ng c√≥ li√™n quan -> H√£y tr·∫£ l·ªùi d·ª±a tr√™n nh·ªØng g√¨ c√≥ th·ªÉ.

N·∫øu th√¥ng tin HO√ÄN TO√ÄN KH√îNG LI√äN QUAN th√¨ m·ªõi n√≥i: "{FALLBACK_MSG}"

C√¢u tr·∫£ l·ªùi c·ªßa b·∫°n:
"""
    # D√ôNG MODEL SMART (70B)
    out = llm(prompt, temp=0.05, n=256, model=GROQ_MODEL_SMART)
    print(f"[DEBUG STRICT OUT] {out}")

    if not out: return FALLBACK_MSG
    out = out.strip()
    if any(c.isdigit() for c in out) or "@" in out or "http" in out: return out
    if "kh√¥ng c√≥ th√¥ng tin" in out.lower() and len(out) < 15: return FALLBACK_MSG
    return out


# ============================================
#  MAIN PROCESS
# ============================================
def process_message(text: str) -> str:
    print("[CHAT.PY] ƒê√É G·ªåI N√ÉO")
    if not text.strip():
        return "Xin ch√†o üëã B·∫°n mu·ªën h·ªèi th√¥ng tin g√¨ trong th∆∞ vi·ªán?"

    q_vec_route = embed_model.encode(normalize(text), normalize_embeddings=True)
    route = route_llm(text, q_vec_route)

    rewritten = rewrite_question(text)
    q_vec = embed_model.encode(normalize(rewritten), normalize_embeddings=True)

    if route == "GREETING":
        return "Xin ch√†o! T√¥i l√† tr·ª£ l√Ω ·∫£o th∆∞ vi·ªán. B·∫°n c·∫ßn t√¨m s√°ch, h·ªèi quy ƒë·ªãnh hay th√¥ng tin ng√†nh h·ªçc?"

    candidates = []
    if route == "BOOKS":
        candidates = search_nonfaq("BOOKS", q_vec, top_k=15)
    elif route == "MAJORS":
        candidates = search_nonfaq("MAJORS", q_vec, top_k=15)
    else:
        candidates = search_faq_candidates(q_vec, top_k=20)

    if not candidates:
        return "Xin l·ªói, t√¥i ch∆∞a t√¨m th·∫•y th√¥ng tin ph√π h·ª£p."

    print(f"[DEBUG {route}] Found {len(candidates)} candidates.")
    best_cand = rerank_with_llm(rewritten, candidates)
    if not best_cand:
        print("[DEBUG] ‚è© Skip Rerank -> Ch·ªçn Top 1.")
        best_cand = candidates[0]
    else:
        print(f"[DEBUG] ‚úÖ Rerank ch·ªçn: {best_cand['answer'][:50]}...")

    return strict_answer(rewritten, best_cand['answer'])


if __name__ == "__main__":
    print("ü§ñ Chatbot 4-B∆Ø·ªöC (Router/Rewrite: 8B | Rerank/Answer: 70B) ƒë√£ s·∫µn s√†ng!")
    while True:
        q = input("\nB·∫°n: ")
        if q.lower() in ["quit", "bye", "exit", "tho√°t"]:
            print("H·∫πn g·∫∑p l·∫°i b·∫°n ·ªü th∆∞ vi·ªán nh√©! üìö")
            break
        print("Bot:", process_message(q))
