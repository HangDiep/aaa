# ============================================
#  CHATBOT 4-B∆Ø·ªöC ‚Äì HI·ªÇU NGHƒ®A, KH√îNG B·ªäA
#  PHI√äN B·∫¢N T·ªêI ∆ØU RAM
# ============================================

import os
import sqlite3
import numpy as np
from sentence_transformers import SentenceTransformer
import requests
import json
import re
import time
import random
import gc  # ‚úÖ Garbage collector
from dotenv import load_dotenv

# Load .env
ENV_PATH = r"D:\HTML\a - Copy\rag\.env"
try:
    if os.path.exists(ENV_PATH):
        load_dotenv(ENV_PATH, override=True)
    else:
        load_dotenv()
except Exception:
    pass

FAQ_DB_PATH = os.getenv("FAQ_DB_PATH")
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
GROQ_MODEL = os.getenv("GROQ_MODEL", "glm-4-plus")

FALLBACK_MSG = "Hi·ªán t·∫°i th∆∞ vi·ªán ch∆∞a c√≥ th√¥ng tin ch√≠nh x√°c cho c√¢u n√†y. B·∫°n m√¥ t·∫£ r√µ h∆°n gi√∫p m√¨nh nh√©."

# ============================================
#  EMBEDDING MODEL - LAZY LOAD + AUTO CLEANUP
# ============================================
embed_model = None
last_model_use = 0
MODEL_TIMEOUT = 300  # ‚úÖ Gi·∫£i ph√≥ng model sau 5 ph√∫t kh√¥ng d√πng

def get_model():
    global embed_model, last_model_use
    
    if embed_model is not None:
        last_model_use = time.time()
        return embed_model
    
    try:
        print("üîÑ ƒêang load model BAAI/bge-m3...")
        embed_model = SentenceTransformer("BAAI/bge-m3")
        print("‚úÖ Load BAAI/bge-m3 th√†nh c√¥ng!")
    except Exception as e:
        print(f"‚ö† L·ªói load BAAI/bge-m3: {e}")
        print("üîÑ ƒêang d√πng fallback model keepitreal/vietnamese-sbert...")
        embed_model = SentenceTransformer("keepitreal/vietnamese-sbert")
        print("‚úÖ Load fallback th√†nh c√¥ng!")
    
    last_model_use = time.time()
    return embed_model

def cleanup_model_if_idle():
    """‚úÖ Gi·∫£i ph√≥ng model n·∫øu kh√¥ng d√πng l√¢u"""
    global embed_model, last_model_use
    if embed_model is not None and (time.time() - last_model_use) > MODEL_TIMEOUT:
        print("üßπ Gi·∫£i ph√≥ng embedding model (idle qu√° l√¢u)...")
        del embed_model
        embed_model = None
        gc.collect()

# ============================================
#  TEXT NORMALIZE
# ============================================
def normalize(x: str) -> str:
    return " ".join(x.lower().strip().split())

# ============================================
#  LLM CALL - T·ªêI ∆ØU H√ìA
# ============================================
def llm(prompt: str, temp: float = 0.15, n: int = 1024) -> str:
    """
    G·ªçi Zhipu AI API v·ªõi retry logic
    ‚úÖ Gi·∫£m timeout, gi·∫£m max_tokens m·∫∑c ƒë·ªãnh
    """
    if not GROQ_API_KEY:
        return ""

    headers = {
        "Authorization": f"Bearer {GROQ_API_KEY}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "model": GROQ_MODEL,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": temp,
        "max_tokens": n,
    }

    max_retries = 2  # ‚úÖ Gi·∫£m t·ª´ 3 xu·ªëng 2
    base_delay = 1   # ‚úÖ Gi·∫£m t·ª´ 2s xu·ªëng 1s

    for attempt in range(max_retries):
        try:
            resp = requests.post(
                "https://open.bigmodel.cn/api/paas/v4/chat/completions",
                headers=headers,
                json=payload,
                timeout=20  # ‚úÖ Gi·∫£m t·ª´ 30s xu·ªëng 20s
            )
            
            if resp.status_code == 200:
                data = resp.json()
                result = data["choices"][0]["message"]["content"].strip()
                del data  # ‚úÖ Gi·∫£i ph√≥ng response data
                return result
            
            if resp.status_code == 429:
                wait_time = base_delay * (2 ** attempt) + random.uniform(0, 0.5)
                print(f"‚ö† Zhipu AI qu√° t·∫£i (429). ƒêang ch·ªù {wait_time:.1f}s...")
                time.sleep(wait_time)
                continue
                
            print(f"‚ö† L·ªói Zhipu AI {resp.status_code}: {resp.text}")
            return ""

        except Exception as e:
            print(f"‚ö† L·ªói g·ªçi Zhipu AI: {e}")
            return ""
    
    return ""

# ============================================
#  CONNECT TO QDRANT - LAZY INIT
# ============================================
from qdrant_client import QdrantClient

QDRANT_URL = os.getenv("QDRANT_URL", "http://localhost:6333")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")

qdrant_client = None

def get_qdrant_client():
    """‚úÖ Lazy initialization cho Qdrant client"""
    global qdrant_client
    if qdrant_client is None:
        print("üîó K·∫øt n·ªëi t·ªõi Qdrant...")
        if QDRANT_API_KEY:
            qdrant_client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)
        else:
            qdrant_client = QdrantClient(url=QDRANT_URL)
        
        try:
            collections = qdrant_client.get_collections().collections
            collection_names = [c.name for c in collections]
            print(f"‚úÖ ƒê√£ k·∫øt n·ªëi Qdrant: {len(collections)} collections ({', '.join(collection_names)})")
        except Exception as e:
            print(f"‚ùå L·ªói k·∫øt n·ªëi Qdrant: {e}")
    
    return qdrant_client

# ============================================
#  ROUTER - T·ªêI ∆ØU H√ìA
# ============================================
def auto_route_by_embedding(q_vec: np.ndarray) -> str:
    """Fallback routing b·∫±ng embedding"""
    best_type = "FAQ"
    best_score = -1.0
    client = get_qdrant_client()

    try:
        # ‚úÖ Ch·ªâ query limit=1 thay v√¨ nhi·ªÅu
        faq_results = client.query_points("faq", query=q_vec.tolist(), limit=1).points
        if faq_results:
            best_type, best_score = "FAQ", faq_results[0].score

        book_results = client.query_points("books", query=q_vec.tolist(), limit=1).points
        if book_results and book_results[0].score > best_score:
            best_type, best_score = "BOOKS", book_results[0].score

        major_results = client.query_points("majors", query=q_vec.tolist(), limit=1).points
        if major_results and major_results[0].score > best_score:
            best_type, best_score = "MAJORS", major_results[0].score
    except Exception as e:
        print(f"‚ö† L·ªói auto_route_by_embedding: {e}")

    return best_type

def is_greeting(text: str) -> bool:
    t = text.lower().strip()
    greet_words = ["xin ch√†o", "ch√†o b·∫°n", "ch√†o ad", "hello", "hi", "alo"]
    return any(w in t for w in greet_words)

def route_llm(question: str, q_vec: np.ndarray) -> str:
    """Router v·ªõi LLM + Embedding fallback"""
    if is_greeting(question) and len(question.split()) <= 4:
        print("[ROUTER] Detected GREETING")
        return "GREETING"

    prompt = f"""
Ph√¢n lo·∫°i c√¢u h·ªèi v√†o 1 trong 3 nh√≥m d·ª±a tr√™n B·∫¢N CH·∫§T:

1. BOOKS (S√°ch & T√†i li·ªáu):
   - Ch·ªâ ch·ªçn khi ng∆∞·ªùi d√πng t√¨m ki·∫øm T√ÄI LI·ªÜU, S√ÅCH, GI√ÅO TR√åNH, LU·∫¨N VƒÇN c·ª• th·ªÉ.
   - V√≠ d·ª•: "T√¨m s√°ch Python", "Gi√°o tr√¨nh Kinh t·∫ø l∆∞·ª£ng", "T√†i li·ªáu v·ªÅ AI".

2. MAJORS (Ng√†nh h·ªçc & ƒê√†o t·∫°o):
   - Ch·ªâ ch·ªçn khi ng∆∞·ªùi d√πng h·ªèi v·ªÅ CH∆Ø∆†NG TR√åNH ƒê√ÄO T·∫†O, TUY·ªÇN SINH, KHOA/VI·ªÜN.
   - V√≠ d·ª•: "Ng√†nh CNTT h·ªçc g√¨", "M√£ ng√†nh 7480201", "Khoa Lu·∫≠t ·ªü ƒë√¢u".

3. FAQ (Th√¥ng tin chung & Kh√°c):
   - T·∫§T C·∫¢ c√°c c√¢u h·ªèi c√≤n l·∫°i.
   - Bao g·ªìm: Quy ƒë·ªãnh, Th·ªß t·ª•c, Gi·ªù l√†m vi·ªác, Wifi, T√†i kho·∫£n.
   - Bao g·ªìm: C∆† S·ªû V·∫¨T CH·∫§T, ƒê·ªäA ƒêI·ªÇM (Ph√≤ng ·ªëc, Canteen, B√£i xe...), S·ª∞ KI·ªÜN.
   - Bao g·ªìm: S·ªê L∆Ø·ª¢NG, TH·ªêNG K√ä (T·ªïng s·ªë s√°ch, C√≥ bao nhi√™u t√†i li·ªáu...).

L∆ØU √ù ∆ØU TI√äN:
- H·ªèi v·ªÅ "T·ªïng s·ªë l∆∞·ª£ng", "Th·ªëng k√™", "C√≥ bao nhi√™u" -> CH·ªåN FAQ (k·ªÉ c·∫£ c√≥ t·ª´ "s√°ch").
- H·ªèi v·ªÅ "·ªû ƒë√¢u", "Ph√≤ng n√†o", "T·∫ßng m·∫•y" (V·ªã tr√≠) -> CH·ªåN FAQ (k·ªÉ c·∫£ c√≥ t·ª´ "s√°ch").
- N·∫øu c√¢u h·ªèi kh√¥ng r√µ r√†ng -> CH·ªåN FAQ.

C√¢u h·ªèi: "{question}"

Ch·ªâ tr·∫£ v·ªÅ ƒë√∫ng 1 t·ª´: FAQ ho·∫∑c BOOKS ho·∫∑c MAJORS.
"""
    out = llm(prompt, temp=0.05, n=10).upper().strip()
    clean_out = re.sub(r'[^A-Z]', '', out)

    print(f"[ROUTER LLM] Output: '{out}' -> Clean: '{clean_out}'")

    if clean_out in ["FAQ", "BOOKS", "MAJORS"]:
        print(f"[ROUTER] ‚úÖ LLM ch·ªçn: {clean_out}")
        return clean_out

    print(f"[ROUTER] ‚ö†Ô∏è LLM kh√¥ng ch·∫Øc ch·∫Øn -> D√πng auto_route_by_embedding...")
    fallback_route = auto_route_by_embedding(q_vec)
    print(f"[ROUTER] -> Vector (DB) ch·ªçn: {fallback_route}")
    return fallback_route

# ============================================
#  REWRITE - T·ªêI ∆ØU H√ìA
# ============================================
def rewrite_question(q: str) -> str:
    if len(q.split()) < 2:
        return q

    prompt = f"""
B·∫°n l√† m·ªôt tr·ª£ l√Ω th√¥ng minh. H√£y ƒê·ªåC HI·ªÇU √Ω ƒë·ªãnh c·ªßa ng∆∞·ªùi d√πng v√† vi·∫øt l·∫°i c√¢u h·ªèi sao cho r√µ r√†ng, ƒë·∫ßy ƒë·ªß nghƒ©a nh·∫•t.
N·∫øu c√¢u h·ªèi qu√° ng·∫Øn, d√πng t·ª´ ƒëa nghƒ©a ho·∫∑c thi·∫øu ch·ªß ng·ªØ, h√£y di·ªÖn gi·∫£i l·∫°i theo c√°ch ng∆∞·ªùi b√¨nh th∆∞·ªùng s·∫Ω h·ªèi ƒë·∫ßy ƒë·ªß.
ƒê·∫∂C BI·ªÜT:
- N·∫øu h·ªèi v·ªÅ "s·ªë", "g·ªçi", "alo" -> Th√™m t·ª´ kh√≥a "s·ªë ƒëi·ªán tho·∫°i li√™n h·ªá hotline".
- N·∫øu h·ªèi v·ªÅ "·ªü ƒë√¢u", "ch·ªó n√†o" -> Th√™m t·ª´ kh√≥a "ƒë·ªãa ƒëi·ªÉm v·ªã tr√≠".

V√≠ d·ª•:
- "s·ªë nao" -> "s·ªë ƒëi·ªán tho·∫°i li√™n h·ªá hotline l√† g√¨"
- "m·ªü c·ª≠a ko" -> "gi·ªù m·ªü c·ª≠a ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o"
- "li√™n h·ªá sao" -> "c√°ch th·ª©c li√™n h·ªá v·ªõi th∆∞ vi·ªán"

C√¢u g·ªëc: "{q}"

C√¢u vi·∫øt l·∫°i (ch·ªâ vi·∫øt 1 c√¢u duy nh·∫•t):
"""
    out = llm(prompt, temp=0.1, n=64)
    return out.strip() if out else q

# ============================================
#  SEARCH - T·ªêI ∆ØU H√ìA
# ============================================
def search_faq_candidates(q_vec: np.ndarray, top_k: int = 10, filter_category: str = None):
    """‚úÖ Gi·∫£m top_k t·ª´ 20 xu·ªëng 10"""
    client = get_qdrant_client()
    try:
        results = client.query_points(
            collection_name="faq",
            query=q_vec.tolist(),
            limit=top_k,
            score_threshold=0.08
        ).points
        
        candidates = []
        for hit in results:
            payload = hit.payload
            score = hit.score
            
            if filter_category and filter_category not in ["FAQ", "BOOKS", "MAJORS", "GREETING"]:
                if payload.get("category") != filter_category:
                    continue
            
            candidates.append({
                "score": score,
                "question": payload.get("question", ""),
                "answer": payload.get("answer", ""),
                "category": payload.get("category", ""),
                "id": hit.id
            })
        return candidates
    except Exception as e:
        print(f"‚ö† L·ªói query Qdrant FAQ: {e}")
        return []

def search_nonfaq(table: str, q_vec: np.ndarray, top_k: int = 10):
    """‚úÖ Gi·∫£m top_k t·ª´ 15 xu·ªëng 10"""
    client = get_qdrant_client()
    try:
        if table == "BOOKS":
            results = client.query_points(
                collection_name="books",
                query=q_vec.tolist(),
                limit=top_k,
                score_threshold=0.15
            ).points
            
            candidates = []
            for hit in results:
                p = hit.payload
                content = (
                    f"S√°ch: {p.get('name')}. T√°c gi·∫£: {p.get('author')}. NƒÉm: {p.get('year')}. "
                    f"S·ªë l∆∞·ª£ng: {p.get('quantity')}. T√¨nh tr·∫°ng: {p.get('status')}. Ng√†nh: {p.get('major', 'Chung')}"
                )
                candidates.append({
                    "score": hit.score,
                    "question": "",
                    "answer": content,
                    "category": "BOOKS",
                    "id": hit.id
                })
            return candidates
        
        elif table == "MAJORS":
            results = client.query_points(
                collection_name="majors",
                query=q_vec.tolist(),
                limit=top_k,
                score_threshold=0.20
            ).points
            
            candidates = []
            for hit in results:
                p = hit.payload
                content = f"Ng√†nh: {p.get('name')}. M√£ ng√†nh: {p.get('major_id')}. M√¥ t·∫£: {p.get('description', 'ƒêang c·∫≠p nh·∫≠t')}"
                candidates.append({
                    "score": hit.score,
                    "question": "",
                    "answer": content,
                    "category": "MAJORS",
                    "id": hit.id
                })
            return candidates
        
        return []
    except Exception as e:
        print(f"‚ö† L·ªói query Qdrant {table}: {e}")
        return []

# ============================================
#  RERANK - T·ªêI ∆ØU H√ìA
# ============================================
def rerank_with_llm(user_q: str, candidates: list):
    """‚úÖ Gi·∫£m max_tokens t·ª´ 128 xu·ªëng 64"""
    if not candidates:
        return None

    # ‚úÖ Ch·ªâ rerank top 5 thay v√¨ t·∫•t c·∫£
    top_candidates = candidates[:5]
    
    block = ""
    for i, c in enumerate(top_candidates, start=1):
        block += f"{i}. [{c['category']}] {c['answer']}\n"

    prompt = f"""
B·∫°n l√† chuy√™n gia t∆∞ v·∫•n th√¥ng minh.
Nhi·ªám v·ª•: T√¨m c√¢u tr·∫£ l·ªùi PH√ô H·ª¢P NH·∫§T cho c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng trong danh s√°ch b√™n d∆∞·ªõi.

C√¢u h·ªèi: "{user_q}"

Danh s√°ch ·ª©ng vi√™n:
{block}

H∆Ø·ªöNG D·∫™N T∆Ø DUY:
- H√£y hi·ªÉu √ù NGHƒ®A c·ªßa c√¢u h·ªèi (kh√¥ng ch·ªâ b·∫Øt t·ª´ kh√≥a).
- V√≠ d·ª•: H·ªèi "Fanpage" th√¨ c√¢u ch·ª©a "Facebook" l√† ƒë√∫ng. H·ªèi "Quy tr√¨nh" th√¨ c√¢u h∆∞·ªõng d·∫´n c√°c b∆∞·ªõc l√† ƒë√∫ng.
- N·∫øu c√¢u h·ªèi t√¨m "ƒê·ªãa ƒëi·ªÉm" (·ªü ƒë√¢u), h√£y ch·ªçn c√¢u ch·ª©a th√¥ng tin v·ªã tr√≠.
- N·∫øu c√¢u h·ªèi t√¨m "Danh s√°ch" (g·ªìm nh·ªØng g√¨), h√£y ch·ªçn c√¢u li·ªát k√™ ƒë·∫ßy ƒë·ªß nh·∫•t.

Y√äU C·∫¶U:
- N·∫øu t√¨m th·∫•y c√¢u tr·∫£ l·ªùi ph√π h·ª£p: Tr·∫£ v·ªÅ S·ªê TH·ª® T·ª∞ (v√≠ d·ª•: 1, 2...).
- N·∫øu kh√¥ng c√≥ c√¢u n√†o kh·ªõp: Tr·∫£ v·ªÅ 0.

Ch·ªâ tr·∫£ v·ªÅ 1 con s·ªë duy nh·∫•t.
"""
    out = llm(prompt, temp=0.1, n=64).strip()

    match = re.search(r'\d+', out)
    if match:
        idx = int(match.group()) - 1
        if 0 <= idx < len(top_candidates):
            return top_candidates[idx]

    # Fallback: tin top 1 n·∫øu score r·∫•t cao
    if top_candidates and top_candidates[0]['score'] > 0.45:
        print(f"[Rerank] LLM t·ª´ ch·ªëi, nh∆∞ng Top 1 score cao ({top_candidates[0]['score']:.2f}) -> Ch·ªçn Top 1.")
        return top_candidates[0]

    return None

# ============================================
#  STRICT ANSWER - T·ªêI ∆ØU H√ìA
# ============================================
def strict_answer(question: str, knowledge: str) -> str:
    """‚úÖ Gi·∫£m max_tokens t·ª´ 128 xu·ªëng 120 (c√¢n b·∫±ng RAM vs ch·∫•t l∆∞·ª£ng)"""
    print(f"[DEBUG STRICT] Q: {question} | Knowledge: {knowledge[:50]}...")
    prompt = f"""
B·∫°n l√† tr·ª£ l√Ω ·∫£o c·ªßa th∆∞ vi·ªán. Tr·∫£ l·ªùi NG·∫ÆN G·ªåN, ƒê√öNG TR·ªåNG T√ÇM.

TH√îNG TIN:
{knowledge}

C√ÇU H·ªéI: "{question}"

QUY T·∫ÆC:
1. Tr·∫£ l·ªùi NG·∫ÆN (1-2 c√¢u), ch·ªâ th√¥ng tin CH√çNH X√ÅC t·ª´ KNOWLEDGE
2. KH√îNG th√™m l·ªùi ch√†o, KH√îNG h·ªèi l·∫°i, KH√îNG gi·∫£i th√≠ch d√†i d√≤ng
3. N·∫øu h·ªèi v·ªÅ email/hotline/facebook ‚Üí CH·ªà tr·∫£ th√¥ng tin ƒë√≥, KH√îNG th√™m g√¨ kh√°c
4. N·∫øu KNOWLEDGE kh√¥ng li√™n quan ‚Üí Tr·∫£: "{FALLBACK_MSG}"

V√ç D·ª§:
Q: "email th∆∞ vi·ªán"
K: "Email: thuvien@ttn.edu.vn, Hotline: 0123456789"
A: "Email c·ªßa th∆∞ vi·ªán l√† thuvien@ttn.edu.vn nh√©!"

Q: "facebook th∆∞ vi·ªán"
K: "Email: thuvien@ttn.edu.vn, Hotline: 0123456789"
A: "{FALLBACK_MSG}"

Tr·∫£ l·ªùi (NG·∫ÆN G·ªåN):
"""
    out = llm(prompt, temp=0.1, n=120)
    print(f"[DEBUG STRICT OUT] {out}")

    if not out:
        return FALLBACK_MSG

    out = out.strip()
    
    # Lo·∫°i b·ªè c√¢u h·ªèi th·ª´a ·ªü cu·ªëi
    if "?" in out:
        sentences = out.split("?")
        if len(sentences) > 1 and len(sentences[-1].strip()) < 10:
            out = sentences[0].strip() + "."
    
    # Lo·∫°i b·ªè l·ªùi ch√†o th·ª´a
    greetings = ["Ch√†o b·∫°n!", "Xin ch√†o!", "D·∫°,", "V√¢ng,"]
    for g in greetings:
        if out.startswith(g):
            out = out[len(g):].strip()
    
    # Ch·∫•p nh·∫≠n c√¢u tr·∫£ l·ªùi c√≥ s·ªë / email / link
    if any(c.isdigit() for c in out) or "@" in out or "http" in out:
        return out

    if "kh√¥ng c√≥ th√¥ng tin" in out.lower() and len(out) < 15:
        return FALLBACK_MSG

    return out

# ============================================
#  MAIN PROCESS - T·ªêI ∆ØU H√ìA
# ============================================
def process_message(text: str) -> str:
    """
    ‚úÖ T·ªëi ∆∞u h√≥a:
    - Ch·ªâ t·∫°o 1 vector thay v√¨ 2
    - Cleanup sau m·ªói request
    """
    print("[CHAT.PY] ƒê√É G·ªåI N√ÉO")
    if not text.strip():
        return "Xin ch√†o üëã B·∫°n mu·ªën h·ªèi th√¥ng tin g√¨ trong th∆∞ vi·ªán?"

    try:
        # ‚úÖ L·∫•y model (lazy load)
        model = get_model()
        
        # B0: T·∫°o vector 1 l·∫ßn duy nh·∫•t
        normalized_text = normalize(text)
        q_vec = model.encode(normalized_text, normalize_embeddings=True)

        # B1: Router (LLM + Embedding)
        route = route_llm(text, q_vec)

        # B2: Rewrite
        rewritten = rewrite_question(text)
        
        # ‚úÖ Ch·ªâ t·∫°o vector m·ªõi n·∫øu rewritten kh√°c text
        if rewritten != text:
            q_vec_search = model.encode(normalize(rewritten), normalize_embeddings=True)
        else:
            q_vec_search = q_vec

        if route == "GREETING":
            return "Xin ch√†o! T√¥i l√† tr·ª£ l√Ω ·∫£o th∆∞ vi·ªán. B·∫°n c·∫ßn t√¨m s√°ch, h·ªèi quy ƒë·ªãnh hay th√¥ng tin ng√†nh h·ªçc?"

        # BOOKS
        if route == "BOOKS":
            candidates = search_nonfaq("BOOKS", q_vec_search, top_k=10)
            if not candidates:
                return "Kh√¥ng t√¨m th·∫•y s√°ch n√†o ph√π h·ª£p."

            print(f"[DEBUG BOOKS] Found {len(candidates)} candidates.")
            best_cand = rerank_with_llm(rewritten, candidates)
            if not best_cand:
                best_cand = candidates[0]

            return strict_answer(rewritten, best_cand['answer'])

        # MAJORS
        if route == "MAJORS":
            candidates = search_nonfaq("MAJORS", q_vec_search, top_k=10)
            if not candidates:
                return "Kh√¥ng t√¨m th·∫•y ng√†nh h·ªçc n√†o ph√π h·ª£p."

            print(f"[DEBUG MAJORS] Found {len(candidates)} candidates.")
            best_cand = rerank_with_llm(rewritten, candidates)
            if not best_cand:
                best_cand = candidates[0]

            return strict_answer(rewritten, best_cand['answer'])

        # M·∫∑c ƒë·ªãnh: FAQ
        candidates = search_faq_candidates(q_vec_search, top_k=10, filter_category=None)

        if not candidates:
            print("[DEBUG] ‚ùå Kh√¥ng t√¨m th·∫•y candidate n√†o (do ƒëi·ªÉm th·∫•p h∆°n ng∆∞·ª°ng).")
            return "Xin l·ªói, t√¥i ch∆∞a t√¨m th·∫•y th√¥ng tin ph√π h·ª£p trong c∆° s·ªü d·ªØ li·ªáu."

        print(f"[DEBUG] Found {len(candidates)} candidates:")
        for c in candidates:
            print(f"  - [{c['score']:.4f}] {c['answer'][:50]}... (Cat: {c['category']})")

        best_cand = rerank_with_llm(rewritten, candidates)
        if not best_cand:
            print("[DEBUG] ‚ùå Rerank LLM t·ª´ ch·ªëi t·∫•t c·∫£ candidates. L·∫•y Top 1.")
            best_cand = candidates[0]
        else:
            print(f"[DEBUG] ‚úÖ Rerank ch·ªçn: {best_cand['answer'][:50]}...")

        final_ans = strict_answer(rewritten, best_cand['answer'])
        return final_ans
    
    finally:
        # ‚úÖ Cleanup sau m·ªói request
        gc.collect()
        cleanup_model_if_idle()

# ============================================
#  CLI
# ============================================
if __name__ == "__main__":
    print("ü§ñ Chatbot 4-B∆Ø·ªöC (Phi√™n b·∫£n T·ªêI ∆ØU RAM) ƒë√£ s·∫µn s√†ng!")
    while True:
        q = input("\nB·∫°n: ")
        if q.lower() in ["quit", "bye", "exit", "tho√°t"]:
            print("H·∫πn g·∫∑p l·∫°i b·∫°n ·ªü th∆∞ vi·ªán nh√©! üìö")
            break
        print("Bot:", process_message(q))
