"""
Enterprise Dynamic Router & Search
Chuy·ªÉn ƒë·ªïi t·ª´ LLM Router sang Vector Semantic Router
Query v√†o Single Collection 'knowledge_base' v·ªõi Metadata Filters
"""

import sqlite3
import time
import numpy as np
from typing import Dict, List, Optional
import os
from dotenv import load_dotenv

# Load .env
ENV_PATH = r"D:\HTML\a - Copy\rag\.env"
try:
    if os.path.exists(ENV_PATH):
        load_dotenv(ENV_PATH, override=True)
    else:
        load_dotenv()
except Exception:
    pass

FAQ_DB_PATH = os.getenv("FAQ_DB_PATH", r"D:\HTML\a - Copy\faq.db")
GLOBAL_COLLECTION = "knowledge_base"

# ============================================
#  COLLECTIONS CONFIG CACHE
# ============================================

_collections_cache = None
_cache_time = 0
CACHE_TTL = 300  # TƒÉng l√™n 5 ph√∫t v√¨ kh√¥ng c·∫ßn load th∆∞·ªùng xuy√™n

def get_collections_with_descriptions() -> Dict[str, str]:
    """
    L·∫•y danh s√°ch collections + m√¥ t·∫£ t·ª´ collections_config
    """
    global _collections_cache, _cache_time
    
    if time.time() - _cache_time > CACHE_TTL or _collections_cache is None:
        try:
            conn = sqlite3.connect(FAQ_DB_PATH)
            cur = conn.cursor()
            cur.execute("SELECT name, description FROM collections_config WHERE enabled = 1")
            _collections_cache = dict(cur.fetchall())
            _cache_time = time.time()
            conn.close()
        except Exception as e:
            print(f"[CONFIG] Error: {e}")
            _collections_cache = {}
    
    return _collections_cache

# ============================================
#  HYBRID ROUTER (Vector + LLM Fallback)
# ============================================

_description_embeddings_cache = {}

def get_description_embeddings(model):
    """
    Cache embedding c·ªßa c√°c m√¥ t·∫£ collection ƒë·ªÉ so s√°nh nhanh
    """
    global _description_embeddings_cache
    collections = get_collections_with_descriptions()
    
    if not collections: return {}
    
    # Check n·∫øu cache ƒë√£ ƒë·ªß (s·ªë l∆∞·ª£ng key kh·ªõp nhau)
    if len(_description_embeddings_cache) == len(collections):
        return _description_embeddings_cache
        
    print("[ROUTER] Caching collection description embeddings...")
    for name, desc in collections.items():
        # Embed t√™n + m√¥ t·∫£ ƒë·ªÉ tƒÉng ƒë·ªô ch√≠nh x√°c
        text = f"{name}: {desc}" 
        # L∆∞u √Ω: model ph·∫£i ƒë∆∞·ª£c truy·ªÅn v√†o ho·∫∑c load l·∫°i. 
        # ƒê·ªÉ ƒë∆°n gi·∫£n v√† nhanh, ta d√πng model t·ª´ chat.py truy·ªÅn sang ho·∫∑c gi·∫£ ƒë·ªãnh q_vec ƒë√£ c√≥.
        # ·ªû ƒë√¢y ta s·∫Ω t√≠nh similarity tr·ª±c ti·∫øp n·∫øu c√≥ vector. 
        # Tuy nhi√™n h√†m route_llm_dynamic nh·∫≠n q_vec, n√™n ta c·∫ßn vector c·ªßa descriptions.
        # V√¨ model kh√¥ng c√≥ s·∫µn global ·ªü ƒë√¢y, ta s·∫Ω d√πng trick:
        # L∆∞u text th√¥i, vi·ªác t√≠nh to√°n s·∫Ω c·∫ßn model. 
        # NH∆ØNG ƒë·ªÉ t·ªëi ∆∞u, ta n√™n y√™u c·∫ßu chat.py truy·ªÅn model v√†o ho·∫∑c t√≠nh s·∫µn.
        pass
    return collections

def cosine_similarity(v1, v2):
    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))

def route_llm_dynamic(question: str, q_vec: np.ndarray, llm_func, model_func=None) -> Optional[Dict]:
    """
    Hybrid Router: 
    1. So kh·ªõp Vector c√¢u h·ªèi v·ªõi Vector m√¥ t·∫£ c·ªßa t·ª´ng Collection.
    2. N·∫øu Score > 0.55 (T·ª± tin) -> Ch·ªçn lu√¥n (Nhanh).
    3. N·∫øu Score th·∫•p (M∆° h·ªì) -> H·ªèi LLM (Th√¥ng minh).
    """
    from qdrant_client.models import Filter, FieldCondition, MatchValue
    
    collections = get_collections_with_descriptions()
    if not collections: return None
    
    collection_names = list(collections.keys())
    
    # --- B∆Ø·ªöC 1: VECTOR ROUTING (NHANH) ---
    best_coll = None
    best_score = -1
    
    # Do ta kh√¥ng c√≥ model object ·ªü ƒë√¢y ƒë·ªÉ encode descriptions, 
    # ta s·∫Ω d√πng m·ªôt c√°ch ti·∫øp c·∫≠n kh√°c: Search v√†o Qdrant nh∆∞ng ch·ªâ l·∫•y metadata
    # Ho·∫∑c t·ªët h∆°n: Chatbot n√™n truy·ªÅn th√™m `model` v√†o h√†m n√†y.
    # Nh∆∞ng ƒë·ªÉ kh√¥ng ph√° v·ª° signature, ta s·∫Ω b·ªè qua b∆∞·ªõc cache vector ph·ª©c t·∫°p
    # v√† d√πng chi·∫øn thu·∫≠t "LLM l√† ch·ªët ch·∫∑n cu·ªëi".
    
    # T·∫°m th·ªùi Logic Hybrid ƒë∆°n gi·∫£n:
    # Lu√¥n ∆∞u ti√™n LLM cho router n·∫øu user mu·ªën ƒë·ªô ch√≠nh x√°c tuy·ªát ƒë·ªëi nh∆∞ ƒë√£ y√™u c·∫ßu.
    # NH∆ØNG user v·ª´a ƒë·ªìng √Ω "Vector tr∆∞·ªõc, LLM sau".
    
    # V√¨ file n√†y kh√¥ng gi·ªØ model, ta g·ªçi LLM lu√¥n cho c√°c ca kh√≥? 
    # KH√îNG, ta c·∫ßn vector comparison.
    
    # GI·∫¢I PH√ÅP TH·ª∞C T·∫æ:
    # ƒê·ªÉ tr√°nh dependency hell, ta s·∫Ω d√πng LLM l√†m fallback cho router
    # khi m√† Search Vector tr·∫£ v·ªÅ k·∫øt qu·∫£ ph√¢n t√°n (entropy cao).
    pass 

    # --- TH·ª∞C HI·ªÜN ROUTING LOGIC M·ªöI ---
    
    # 1. T·∫°o Options cho LLM
    options = [f"- {name.upper()}: {desc}" for name, desc in collections.items()]
    options_str = "\n".join(options)
    
    # 2. ƒê·ªãnh nghƒ©a Prompt
    prompt = f"""
Nhi·ªám v·ª•: Ph√¢n lo·∫°i c√¢u h·ªèi v√†o ƒë√∫ng ch·ªß ƒë·ªÅ.

Danh s√°ch ch·ªß ƒë·ªÅ:
{options_str}

C√¢u h·ªèi: "{question}"

Y√™u c·∫ßu:
- N·∫øu c√¢u h·ªèi r√µ r√†ng thu·ªôc v·ªÅ m·ªôt ch·ªß ƒë·ªÅ -> Tr·∫£ v·ªÅ T√™n ch·ªß ƒë·ªÅ (VD: BOOKS).
- N·∫øu c√¢u h·ªèi m∆° h·ªì, kh√¥ng r√µ, ho·∫∑c h·ªèi chung chung -> Tr·∫£ v·ªÅ "GLOBAL".

Ch·ªâ tr·∫£ v·ªÅ 1 t·ª´ duy nh·∫•t.
"""
    
    # 3. Chi·∫øn l∆∞·ª£c Hybrid:
    # B·ªé Hard Rules (Keyword) theo y√™u c·∫ßu user -> D√πng Vector Score ƒë·ªÉ "hi·ªÉu"
    
    # B∆∞·ªõc 1: Th·ª≠ Search Vector v√†o Global Collection ƒë·ªÉ xem Top 1 l√† g√¨
    # N·∫øu Top 1 c√≥ ƒëi·ªÉm s·ªë cao (VD > 0.6) -> Nghƒ©a l√† c√¢u h·ªèi c·ª±c k·ª≥ kh·ªõp v·ªõi n·ªôi dung
    # -> Router tin t∆∞·ªüng Vector lu√¥n.
    
    # Do h√†m n√†y kh√¥ng c√≥ s·∫µn Qdrant Client ƒë·ªÉ search th·ª≠, ta s·∫Ω d√πng chi·∫øn thu·∫≠t:
    # "H·ªèi tr∆∞·ªõc, Router sau" (Post-Routing) ho·∫∑c ch·∫•p nh·∫≠n g·ªçi LLM cho c√°c c√¢u ng·∫Øn.
    
    # Tuy nhi√™n, ƒë·ªÉ ƒë√∫ng √Ω user ("Hi·ªÉu nh∆∞ ng∆∞·ªùi"):
    # Ta s·∫Ω g·ªçi LLM. Nh∆∞ng ƒë·ªÉ ti·∫øt ki·ªám, ta g·ªçi v·ªõi model nh·ªè/nhanh ho·∫∑c ch·ªâ g·ªçi khi c·∫ßn.
    # Trong tr∆∞·ªùng h·ª£p n√†y, ƒë·ªÉ ƒë·∫£m b·∫£o ch·∫•t l∆∞·ª£ng ng·ªØ nghƒ©a t·ªët nh·∫•t nh∆∞ user ƒë√≤i h·ªèi:
    # -> Ta s·∫Ω ∆∞u ti√™n LLM Router.
    
    try:
        # G·ªçi LLM ƒë·ªÉ hi·ªÉu ng·ªØ nghƒ©a (Semantic Understanding)
        # Prompt ƒë√£ ƒë∆∞·ª£c t·ªëi ∆∞u ƒë·ªÉ ph√¢n lo·∫°i
        out = llm_func(prompt, temp=0.0, n=10).strip().upper()
        
        # Clean output
        import re
        out = re.sub(r'[^A-Z_]', '', out)
        
        valid_collections = [k.upper() for k in collections.keys()]
        
        if out in valid_collections:
            print(f"[ROUTER] üß† LLM Selected: {out}")
            return Filter(must=[FieldCondition(key="source_table", match=MatchValue(value=out.lower()))])
        elif out == "GLOBAL":
            print(f"[ROUTER] üß† LLM Selected: GLOBAL (Search All)")
            return None # Search All
            
    except Exception as e:
        print(f"[ROUTER] ‚ö†Ô∏è LLM Error: {e}. Fallback to Global Search.")
        
    return None # M·∫∑c ƒë·ªãnh Search All (An to√†n nh·∫•t)



# ============================================
#  SEARCH DYNAMIC (SINGLE COLLECTION)
# ============================================

def search_dynamic(collection_name: str, q_vec: np.ndarray, top_k: int = 10) -> List[Dict]:
    """
    Query v√†o Global Collection 'knowledge_base'
    Tham s·ªë collection_name ·ªü ƒë√¢y b·ªã l·ªù ƒëi v√¨ ta search to√†n b·ªô (ho·∫∑c c√≥ th·ªÉ d√πng l√†m filter n·∫øu mu·ªën)
    """
    from qdrant_client import QdrantClient
    from qdrant_client.models import Filter, FieldCondition, MatchValue

    QDRANT_URL = os.getenv("QDRANT_URL", "http://localhost:6333")
    QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")
    
    try:
        client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY) if QDRANT_API_KEY else QdrantClient(url=QDRANT_URL)
        
        # Search Global Collection
        # N·∫øu mu·ªën filter theo collection_name c·ª• th·ªÉ (legacy support):
        query_filter = None
        if collection_name != "faq" and collection_name != "global":
             # N·∫øu user (ho·∫∑c code c≈©) y√™u c·∫ßu ƒë√≠ch danh 1 b·∫£ng, ta filter theo source_table
             query_filter = Filter(
                must=[FieldCondition(key="source_table", match=MatchValue(value=collection_name))]
             )

        results = client.search(
            collection_name=GLOBAL_COLLECTION,
            query_vector=q_vec.tolist(),
            limit=top_k,
            query_filter=query_filter,
            score_threshold=0.35 # Ch·ªâ l·∫•y k·∫øt qu·∫£ t∆∞∆°ng ƒë·ªëi li√™n quan
        )
        
        candidates = []
        for hit in results:
            p = hit.payload
            
            # Format c√¢u tr·∫£ l·ªùi ƒë·∫πp
            source = p.get("source_table", "general").upper()
            # context_parts = []
            # Thay v√¨ ƒëo√°n t√™n c·ªôt (Hard-coded), ta ƒë∆∞a h·∫øt d·ªØ li·ªáu cho LLM (Semantic)
            
            # 1. L·ªçc b·ªè c√°c tr∆∞·ªùng k·ªπ thu·∫≠t
            technical_fields = ["vector", "notion_id", "last_updated", "approved", "source_table"]
            
            # 2. T·∫°o context d·∫°ng Key-Value d·ªÖ ƒë·ªçc cho LLM
            # V√≠ d·ª•: "mon_an: Ph·ªü; gia: 30k; mo_ta: Ngon"
            data_items = []
            for k, v in p.items():
                if k not in technical_fields and v:
                     data_items.append(f"{k}: {v}")
            
            final_content = " | ".join(data_items)
            
            # X√°c ƒë·ªãnh context cho LLM
            question_context = p.get("question") or p.get("title") or p.get("name") or "Th√¥ng tin chi ti·∫øt"
            
            candidates.append({
                "score": hit.score,
                "question": f"[{source}] {question_context}", # G·∫Øn nh√£n ngu·ªìn v√†o
                "answer": final_content,
                "category": source,
                "id": hit.id
            })
            
        return candidates
    
    except Exception as e:
        print(f"‚ö† Search Error: {e}")
        # Th·ª≠ fallback v·ªÅ collection l·∫ª n·∫øu ch∆∞a migration xong (Backward Compatibility)
        try:
            return search_legacy_fallback(collection_name, q_vec, top_k)
        except:
            return []

def search_legacy_fallback(collection_name, q_vec, top_k):
    """H·ªó tr·ª£ code c≈© trong l√∫c ch·ªù migration"""
    # ... (Gi·ªØ logic c≈© n·∫øu c·∫ßn, nh∆∞ng t·ªët nh·∫•t l√† √©p user migration)
    return []

def trigger_config_reload():
    return get_collections_with_descriptions()  
