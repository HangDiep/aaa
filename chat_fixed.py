
import os
import random
import json
import sqlite3
import datetime
from typing import Optional

import numpy as np
import torch
import requests

from model import NeuralNet
from nltk_utils import tokenize, bag_of_words
from state_manager import StateManager
import requests  # NEW
# --------------------# ---- OLLAMA AUGMENT (append thÃªm cÃ¢u tráº£ lá»i) ----
USE_OLLAMA_AUGMENT = True           # báº­t/táº¯t tÃ­nh nÄƒng bá»• sung
OLLAMA_MODEL = "qwen2:1.5b"         # hoáº·c "llama3.2:3b"
OLLAMA_URL = "http://127.0.0.1:11434/api/generate"

# --------------------
# Cáº¤U HÃŒNH LÆ¯U LOG
# --------------------
CHAT_DB_PATH = "chat.db"

# Inbox cÃ¢u há»i Ä‘á»ƒ Ä‘áº©y lÃªn Notion
FAQ_DB_PATH = "D:/HTML/chat2/rag/faqs.db"   # giá»¯ nguyÃªn nhÆ° push_logs.py

CONF_THRESHOLD = 0.60  # ngÆ°á»¡ng tá»± tin intent
LOG_ALL_QUESTIONS = True  # True = log má»i cÃ¢u; False = chá»‰ log khi bot chÆ°a hiá»ƒu / tá»± tin tháº¥p

# --------------------
# DB: conversations (chat.db)
# --------------------
conn = sqlite3.connect(CHAT_DB_PATH)
cur = conn.cursor()
cur.execute("""
CREATE TABLE IF NOT EXISTS conversations (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    user_message TEXT,
    bot_reply   TEXT,
    intent_tag  TEXT,
    confidence  REAL,
    time        TEXT
);
""")
conn.commit()

# --------------------
# DB: questions_log (faqs.db) - táº¡o náº¿u chÆ°a cÃ³
# --------------------
def ensure_questions_log():
    os.makedirs(os.path.dirname(FAQ_DB_PATH), exist_ok=True)
    conn2 = sqlite3.connect(FAQ_DB_PATH)
    cur2 = conn2.cursor()
    cur2.execute("""
    CREATE TABLE IF NOT EXISTS questions_log (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        question   TEXT,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        synced     INTEGER DEFAULT 0
    )
    """)
    conn2.commit(); conn2.close()

def log_question_for_notation(question: str):
    """Ghi 1 cÃ¢u há»i vÃ o 'inbox' Ä‘á»ƒ push lÃªn Notion sau nÃ y (push_logs.py)."""
    if not question or not question.strip():
        return
    ensure_questions_log()
    conn2 = sqlite3.connect(FAQ_DB_PATH)
    cur2 = conn2.cursor()
    cur2.execute("INSERT INTO questions_log (question, synced) VALUES (?, 0)", (question.strip(),))
    conn2.commit(); conn2.close()

# --------------------
# MODEL
# --------------------
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Äá»c intents (Äƒn BOM náº¿u cÃ³)
with open("intents.json", "r", encoding="utf-8-sig") as f:
    intents = json.load(f)

# Load model Ä‘Ã£ train
FILE = "data.pth"
_data = torch.load(FILE, map_location=device)

input_size = _data["input_size"]
hidden_size = _data["hidden_size"]
output_size = _data["output_size"]
all_words = _data["all_words"]
tags = _data["tags"]
model_state = _data["model_state"]

model = NeuralNet(input_size, hidden_size, output_size).to(device)
model.load_state_dict(model_state)
model.eval()

# --------------------
# STATE / FLOW
# --------------------
try:
    state_mgr = StateManager("flows.json")
except Exception:
    state_mgr = StateManager()

INTERRUPT_INTENTS = set()
CANCEL_WORDS = {"há»§y","huá»·","huy","cancel","thoÃ¡t","dá»«ng","Ä‘á»•i chá»§ Ä‘á»","doi chu de"}

print("ðŸ¤– Chatbot Ä‘Ã£ sáºµn sÃ ng! GÃµ 'quit' Ä‘á»ƒ thoÃ¡t.")

conn = ensure_main_db()
cur = conn.cursor()

try:
    while True:
        sentence = input("Báº¡n: ").strip()
        lower_sentence = sentence.lower()

        if lower_sentence == "quit":
            break

        # Lá»‡nh há»§y luá»“ng thá»§ cÃ´ng
        if lower_sentence in CANCEL_WORDS:
            try:
                state_mgr.exit_flow()
            except Exception:
                pass
            reply = "ÄÃ£ há»§y luá»“ng hiá»‡n táº¡i. Báº¡n muá»‘n há»i gÃ¬ tiáº¿p?"
            print("Bot:", reply)
            cur.execute(
                "INSERT INTO conversations(user_message, bot_reply, intent_tag, confidence, time) VALUES (?,?,?,?,?)",
                (sentence, reply, None, 0.0, datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")),
            )
            conn.commit()
            continue

        # Khá»Ÿi táº¡o
        reply: Optional[str] = None
        tag_to_log: Optional[str] = None
        confidence: float = 0.0

        # --- NLU: dá»± Ä‘oÃ¡n intent ---
        tokens = tokenize(sentence)
        X = bag_of_words(tokens, all_words)
        X = torch.from_numpy(X).unsqueeze(0).to(device)

        with torch.no_grad():
            output = model(X)
            probs = torch.softmax(output, dim=1)
            prob, pred_idx = torch.max(probs, dim=1)
            tag = tags[pred_idx.item()]
            confidence = float(prob.item())

        # --- Æ¯U TIÃŠN NGá»® Cáº¢NH ---
        # 0) Náº¿u Ä‘ang á»Ÿ trong flow: state manager xá»­ lÃ½ TRÆ¯á»šC
        if getattr(state_mgr, "active_flow", None):
            try:
                ctx_reply = state_mgr.handle(tag, sentence)
            except Exception:
                ctx_reply = None
            if ctx_reply:
                reply = ctx_reply
                tag_to_log = tag

        # 1) Æ¯u tiÃªn kiá»ƒm tra sÃ¡ch náº¿u chá»©a tá»« khÃ³a
        if reply is None:
            book_keywords = [
                "sÃ¡ch", "tá»“n kho", "mÆ°á»£n",
                "cáº¥u trÃºc dá»¯ liá»‡u", "trÃ­ tuá»‡ nhÃ¢n táº¡o", "láº­p trÃ¬nh python"
            ]
            if any(w in lower_sentence for w in book_keywords):
                inv = get_inventory_response(sentence)
                if not inv:  # thá»­ theo tá»«ng keyword
                    for kw in sentence.split():
                        inv = get_inventory_response(kw)
                        if inv:
                            break
                if inv:
                    reply = inv
                    tag_to_log = "inventory_search"

        # 2) TÃ¬m trong FAQ náº¿u cÃ¢u há»i thiÃªn vá» thÆ° viá»‡n
        if reply is None:
            faq_keywords = ["thÆ° viá»‡n", "Ä‘á»‹a chá»‰", "giá»", "liÃªn há»‡", "ná»™i quy"]
            if any(w in lower_sentence for w in faq_keywords):
                faq = get_faq_response(sentence)
                if not faq:
                    for kw in sentence.split():
                        faq = get_faq_response(kw)
                        if faq:
                            break
                if faq:
                    reply = faq
                    tag_to_log = "faq_search"

        # 3) Bootstrap theo tá»« khÃ³a trong flows.json
        if reply is None:
            try:
                boot = state_mgr.bootstrap_by_text(sentence)
            except Exception:
                boot = None
            if boot:
                reply = boot

        # 4) Náº¿u váº«n chÆ°a cÃ³ -> dÃ¹ng responses theo intent (chá»‰ khi Ä‘á»§ tá»± tin)
        if reply is None and confidence > CONF_THRESHOLD:
            resp_list = next((it["responses"] for it in intents["intents"] if it["tag"] == tag), None)
            if resp_list:
                reply = random.choice(resp_list)
                tag_to_log = tag

        # 5) Fallback cuá»‘i
        if reply is None:
            reply = "Xin lá»—i, mÃ¬nh chÆ°a hiá»ƒu Ã½ báº¡n."

        print("Bot:", reply)

        # --- LÆ°u log ---
        cur.execute(
            "INSERT INTO conversations(user_message, bot_reply, intent_tag, confidence, time) VALUES (?,?,?,?,?)",
            (sentence, reply, tag_to_log, confidence, datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")),
        )
        conn.commit()

        # --- Ghi inbox Ä‘á»ƒ Ä‘áº©y lÃªn Notion (Ä‘áº·t BÃŠN TRONG vÃ²ng láº·p!) ---
        should_push_to_notion = (
            LOG_ALL_QUESTIONS
            or reply.strip().startswith("Xin lá»—i, mÃ¬nh chÆ°a hiá»ƒu")
            or confidence < CONF_THRESHOLD
            or tag_to_log is None
        )
        if should_push_to_notion:
            try:
                # âœ… gá»i HÃ€M Ä‘Ãºng tÃªn (khÃ´ng gÃ¡n biáº¿n)
                log_question_for_notion(f"User: {sentence}\nBot: {reply}")
            except Exception as e:
                # KhÃ´ng Ä‘á»ƒ logging lÃ m há»ng flow chat
                print(f"[Notion inbox] Lá»—i: {e}")

finally:
    try:
        conn.close()
    except Exception:
        pass
        