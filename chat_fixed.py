
import os
import random
import json
import sqlite3
import datetime
from typing import Optional

import numpy as np
import torch
import requests

from model import NeuralNet
from nltk_utils import tokenize, bag_of_words
from state_manager import StateManager


# =========================
# Config
# =========================
DB_PATH = "chat.db"
# ðŸ‘‰ Sá»­a Ä‘Æ°á»ng dáº«n nÃ y theo mÃ¡y cá»§a báº¡n náº¿u cáº§n
FAQ_DB_PATH = os.path.normpath("D:/HTML/chat2/rag/faqs.db")
CONF_THRESHOLD = 0.60  # táº¡m háº¡ Ä‘á»ƒ dá»… kÃ­ch hoáº¡t intent khi data cÃ²n má»ng
LOG_ALL_QUESTIONS = True  # True = log má»i cÃ¢u; False = chá»‰ log khi bot chÆ°a hiá»ƒu / tá»± tin tháº¥p

# API endpoints (FastAPI backend)
FAQ_API_URL = "http://localhost:8000/search"
INVENTORY_API_URL = "http://localhost:8000/inventory"

# Flow control
INTERRUPT_INTENTS = set()  # khÃ´ng ngáº¯t flow báº±ng intent; chá»‰ há»§y báº±ng CANCEL_WORDS
CANCEL_WORDS = {"há»§y", "huá»·", "huy", "cancel", "thoÃ¡t", "dá»«ng", "Ä‘á»•i chá»§ Ä‘á»", "doi chu de"}


# =========================
# DB helpers
# =========================
def ensure_main_db() -> sqlite3.Connection:
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS conversations (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_message TEXT,
            bot_reply   TEXT,
            intent_tag  TEXT,
            confidence  REAL,
            time        TEXT
        );
        """
    )
    conn.commit()
    return conn


def ensure_questions_log_db() -> None:
    dir_name = os.path.dirname(FAQ_DB_PATH)
    if dir_name and not os.path.exists(dir_name):
        os.makedirs(dir_name, exist_ok=True)
    conn2 = sqlite3.connect(FAQ_DB_PATH)
    cur2 = conn2.cursor()
    cur2.execute(
        """
        CREATE TABLE IF NOT EXISTS questions_log (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            question   TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            synced     INTEGER DEFAULT 0
        )
        """
    )
    conn2.commit()
    conn2.close()


def log_question_for_notion(question: str) -> None:
    """Ghi 1 cÃ¢u há»i + tráº£ lá»i vÃ o inbox Ä‘á»ƒ push lÃªn Notion (push_logs.py)."""
    if not question or not question.strip():
        return
    ensure_questions_log_db()
    try:
        conn2 = sqlite3.connect(FAQ_DB_PATH)
        cur2 = conn2.cursor()
        cur2.execute(
            "INSERT INTO questions_log (question, synced) VALUES (?, 0)",
            (question.strip(),),
        )
        conn2.commit()
    finally:
        try:
            conn2.close()
        except Exception:
            pass


# =========================
# Model load
# =========================

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Äá»c intents (Äƒn BOM náº¿u cÃ³)
with open("intents.json", "r", encoding="utf-8-sig") as f:
    intents = json.load(f)

# Load model Ä‘Ã£ train
FILE = "data.pth"
_data = torch.load(FILE, map_location=device)

input_size = _data["input_size"]
hidden_size = _data["hidden_size"]
output_size = _data["output_size"]
all_words = _data["all_words"]
tags = _data["tags"]
model_state = _data["model_state"]

model = NeuralNet(input_size, hidden_size, output_size).to(device)
model.load_state_dict(model_state)
model.eval()

# State manager: cá»‘ gáº¯ng dÃ¹ng flows.json náº¿u cÃ³
try:
    state_mgr = StateManager("flows.json")
except Exception:
    state_mgr = StateManager()


# =========================
# API helpers
# =========================
def get_faq_response(sentence: str) -> Optional[str]:
    try:
        resp = requests.get(FAQ_API_URL, params={"q": sentence}, timeout=5)
        if resp.status_code == 200:
            data = resp.json()
            if isinstance(data, list) and data:
                ans = data[0].get("answer")
                if ans:
                    return ans
        return None
    except requests.RequestException as e:
        print(f"[FAQ] Lá»—i káº¿t ná»‘i API: {e}")
        return None
    except Exception as e:
        print(f"[FAQ] Lá»—i xá»­ lÃ½ dá»¯ liá»‡u: {e}")
        return None


def get_inventory_response(sentence: str) -> Optional[str]:
    try:
        resp = requests.get(INVENTORY_API_URL, params={"book_name": sentence}, timeout=5)
        if resp.status_code == 200:
            data = resp.json()
            if isinstance(data, list) and data:
                book = data[0]
                name = book.get("name")
                author = book.get("author", "?")
                year = book.get("year", "?")
                quantity = book.get("quantity", "?")
                status = book.get("status", "?")
                if name:
                    return (
                        f"SÃ¡ch '{name}' cá»§a tÃ¡c giáº£ {author}, nÄƒm xuáº¥t báº£n {year}, "
                        f"sá»‘ lÆ°á»£ng: {quantity}, tráº¡ng thÃ¡i: {status}"
                    )
        return None
    except requests.RequestException as e:
        print(f"[Inventory] Lá»—i káº¿t ná»‘i API: {e}")
        return None
    except Exception as e:
        print(f"[Inventory] Lá»—i xá»­ lÃ½ dá»¯ liá»‡u: {e}")
        return None


# =========================
# Runtime
# =========================
print("ðŸ¤– Chatbot Ä‘Ã£ sáºµn sÃ ng! GÃµ 'quit' Ä‘á»ƒ thoÃ¡t.")

conn = ensure_main_db()
cur = conn.cursor()

try:
    while True:
        sentence = input("Báº¡n: ").strip()
        lower_sentence = sentence.lower()

        if lower_sentence == "quit":
            break

        # Lá»‡nh há»§y luá»“ng thá»§ cÃ´ng
        if lower_sentence in CANCEL_WORDS:
            try:
                state_mgr.exit_flow()
            except Exception:
                pass
            reply = "ÄÃ£ há»§y luá»“ng hiá»‡n táº¡i. Báº¡n muá»‘n há»i gÃ¬ tiáº¿p?"
            print("Bot:", reply)
            cur.execute(
                "INSERT INTO conversations(user_message, bot_reply, intent_tag, confidence, time) VALUES (?,?,?,?,?)",
                (sentence, reply, None, 0.0, datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")),
            )
            conn.commit()
            continue

        # Khá»Ÿi táº¡o
        reply: Optional[str] = None
        tag_to_log: Optional[str] = None
        confidence: float = 0.0

        # --- NLU: dá»± Ä‘oÃ¡n intent ---
        tokens = tokenize(sentence)
        X = bag_of_words(tokens, all_words)
        X = torch.from_numpy(X).unsqueeze(0).to(device)

        with torch.no_grad():
            output = model(X)
            probs = torch.softmax(output, dim=1)
            prob, pred_idx = torch.max(probs, dim=1)
            tag = tags[pred_idx.item()]
            confidence = float(prob.item())

        # --- Æ¯U TIÃŠN NGá»® Cáº¢NH ---
        # 0) Náº¿u Ä‘ang á»Ÿ trong flow: state manager xá»­ lÃ½ TRÆ¯á»šC
        if getattr(state_mgr, "active_flow", None):
            try:
                ctx_reply = state_mgr.handle(tag, sentence)
            except Exception:
                ctx_reply = None
            if ctx_reply:
                reply = ctx_reply
                tag_to_log = tag

        # 1) Æ¯u tiÃªn kiá»ƒm tra sÃ¡ch náº¿u chá»©a tá»« khÃ³a
        if reply is None:
            book_keywords = [
                "sÃ¡ch", "tá»“n kho", "mÆ°á»£n",
                "cáº¥u trÃºc dá»¯ liá»‡u", "trÃ­ tuá»‡ nhÃ¢n táº¡o", "láº­p trÃ¬nh python"
            ]
            if any(w in lower_sentence for w in book_keywords):
                inv = get_inventory_response(sentence)
                if not inv:  # thá»­ theo tá»«ng keyword
                    for kw in sentence.split():
                        inv = get_inventory_response(kw)
                        if inv:
                            break
                if inv:
                    reply = inv
                    tag_to_log = "inventory_search"

        # 2) TÃ¬m trong FAQ náº¿u cÃ¢u há»i thiÃªn vá» thÆ° viá»‡n
        if reply is None:
            faq_keywords = ["thÆ° viá»‡n", "Ä‘á»‹a chá»‰", "giá»", "liÃªn há»‡", "ná»™i quy"]
            if any(w in lower_sentence for w in faq_keywords):
                faq = get_faq_response(sentence)
                if not faq:
                    for kw in sentence.split():
                        faq = get_faq_response(kw)
                        if faq:
                            break
                if faq:
                    reply = faq
                    tag_to_log = "faq_search"

        # 3) Bootstrap theo tá»« khÃ³a trong flows.json
        if reply is None:
            try:
                boot = state_mgr.bootstrap_by_text(sentence)
            except Exception:
                boot = None
            if boot:
                reply = boot

        # 4) Náº¿u váº«n chÆ°a cÃ³ -> dÃ¹ng responses theo intent (chá»‰ khi Ä‘á»§ tá»± tin)
        if reply is None and confidence > CONF_THRESHOLD:
            resp_list = next((it["responses"] for it in intents["intents"] if it["tag"] == tag), None)
            if resp_list:
                reply = random.choice(resp_list)
                tag_to_log = tag

        # 5) Fallback cuá»‘i
        if reply is None:
            reply = "Xin lá»—i, mÃ¬nh chÆ°a hiá»ƒu Ã½ báº¡n."

        print("Bot:", reply)

        # --- LÆ°u log ---
        cur.execute(
            "INSERT INTO conversations(user_message, bot_reply, intent_tag, confidence, time) VALUES (?,?,?,?,?)",
            (sentence, reply, tag_to_log, confidence, datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")),
        )
        conn.commit()

        # --- Ghi inbox Ä‘á»ƒ Ä‘áº©y lÃªn Notion (Ä‘áº·t BÃŠN TRONG vÃ²ng láº·p!) ---
        should_push_to_notion = (
            LOG_ALL_QUESTIONS
            or reply.strip().startswith("Xin lá»—i, mÃ¬nh chÆ°a hiá»ƒu")
            or confidence < CONF_THRESHOLD
            or tag_to_log is None
        )
        if should_push_to_notion:
            try:
                # âœ… gá»i HÃ€M Ä‘Ãºng tÃªn (khÃ´ng gÃ¡n biáº¿n)
                log_question_for_notion(f"User: {sentence}\nBot: {reply}")
            except Exception as e:
                # KhÃ´ng Ä‘á»ƒ logging lÃ m há»ng flow chat
                print(f"[Notion inbox] Lá»—i: {e}")

finally:
    try:
        conn.close()
    except Exception:
        pass
        