import os, random, json, sqlite3, re, time
# chat_fixed.py
import numpy as np
import torch, requests
from model import NeuralNet
from nltk_utils import tokenize, bag_of_words
from state_manager import StateManager
import threading
from dotenv import load_dotenv
from notion_client import Client
from typing import Optional, List, Dict
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import socket
from datetime import datetime



# ============== C·∫§U H√åNH ==============
ENV_PATH = r"D:\HTML\a\rag\.env"
try:
    if os.path.exists(ENV_PATH):
        load_dotenv(ENV_PATH, override=True)
        # Sau load_dotenv:
except Exception:
    pass

print("=== DEBUG ENV CHECK ===")
print("ENV_PATH =", ENV_PATH, "| exists:", os.path.exists(ENV_PATH))
print("NOTION_API_KEY =", os.getenv("NOTION_API_KEY"))
print("NOTION_BASE_URL =", os.getenv("NOTION_BASE_URL"))
print("DATABASE_ID_FAQ =", os.getenv("DATABASE_ID_FAQ"))
print("========================")

_notion_cached = None
_notion_warned_once = False  # ch·ªâ c·∫£nh b√°o 1 l·∫ßn khi l·ªói HTTP push

# Ollama (c√≥ th·ªÉ t·∫Øt n·∫øu l·ªói m·∫°ng)
OLLAMA_URL = os.getenv("OLLAMA_URL", "http://127.0.0.1:11434")
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "qwen2:1.5b")
OLLAMA_TIMEOUT = float(os.getenv("OLLAMA_TIMEOUT", "60"))
ENABLE_OLLAMA_APPEND = os.getenv("ENABLE_OLLAMA_APPEND", "true").lower() != "false"
MAX_OLLAMA_APPEND_TOKENS = 150
print("[Ollama] URL:", OLLAMA_URL, "| model:", OLLAMA_MODEL, "| timeout:", OLLAMA_TIMEOUT)
FAQ_API_URL = "http://localhost:8000/search"
INVENTORY_API_URL = "http://localhost:8000/inventory"

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
CHAT_DB_PATH = os.path.join(BASE_DIR, "chat.db")
print(f"[ChatDB] Using: {CHAT_DB_PATH}")
DB_PATH = CHAT_DB_PATH

FAQ_DB_PATH = os.path.join(BASE_DIR, "faq.db")
CONF_THRESHOLD = 0.60
LOG_ALL_QUESTIONS = True

INTERRUPT_INTENTS = set()
CANCEL_WORDS = {"h·ªßy", "hu·ª∑", "huy", "cancel", "tho√°t", "d·ª´ng", "ƒë·ªïi ch·ªß ƒë·ªÅ", "doi chu de"}

# ============== DB helpers ==============
def ensure_main_db() -> sqlite3.Connection:
    os.makedirs(os.path.dirname(DB_PATH), exist_ok=True) if os.path.dirname(DB_PATH) else None
    conn = sqlite3.connect(DB_PATH, check_same_thread=False)
    cur = conn.cursor()
    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS conversations (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_message TEXT,
            bot_reply   TEXT,
            intent_tag  TEXT,
            confidence  REAL,
            time        TEXT
        );
        """
    )
    conn.commit()
    return conn

def ensure_questions_log_db() -> None:
    dir_name = os.path.dirname(FAQ_DB_PATH)
    if dir_name and not os.path.exists(dir_name):
        os.makedirs(dir_name, exist_ok=True)
    conn2 = sqlite3.connect(FAQ_DB_PATH)
    cur2 = conn2.cursor()
    cur2.execute(
        """
        CREATE TABLE IF NOT EXISTS questions_log (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            question   TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            synced     INTEGER DEFAULT 0
        )
        """
    )
    conn2.commit()
    conn2.close()

def log_question_for_notion(question: str) -> None:
    if not question or not question.strip():
        return
    ensure_questions_log_db()
    conn2 = sqlite3.connect(FAQ_DB_PATH)
    cur2 = conn2.cursor()
    cur2.execute(
        "INSERT INTO questions_log (question, synced) VALUES (?, 0)",
        (question.strip(),),
    )
    conn2.commit()
    conn2.close()

# ============== Model load ==============
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

with open("intents.json", "r", encoding="utf-8-sig") as f:
    intents = json.load(f)

_data = torch.load("data.pth", map_location=device)
input_size  = _data["input_size"]
hidden_size = _data["hidden_size"]
output_size = _data["output_size"]
all_words   = _data["all_words"]
tags        = _data["tags"]
model_state = _data["model_state"]

model = NeuralNet(input_size, hidden_size, output_size).to(device)
model.load_state_dict(model_state)
model.eval()

try:
    state_mgr = StateManager("flows.json")
except Exception:
    state_mgr = StateManager()

def _now():
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")


# ============== FAQ / Inventory ==============
def get_faq_response(sentence: str) -> Optional[str]:
    try:
        resp = requests.get(FAQ_API_URL, params={"q": sentence}, timeout=5)
        if resp.status_code != 200:
            print(f"[FAQ] HTTP {resp.status_code}: {resp.text[:200]}")
            return None
        data = resp.json()
        if not isinstance(data, list) or not data:
            return None
        lines: List[str] = []
        lines.append("üìñ **K·∫øt qu·∫£ FAQ:**\n")
        lines.append("| C√¢u h·ªèi | Tr·∫£ l·ªùi |")
        lines.append("|---------|---------|")
        for item in data:
            q = item.get("question", "").strip()
            a = item.get("answer", "").strip()
            if q or a:
                q = q.replace("|", "ÔΩú")
                a = a.replace("|", "ÔΩú")
                lines.append(f"| {q} | {a} |")
        return "\n".join(lines) if len(lines) > 3 else None
    except requests.RequestException as e:
        print(f"[FAQ] L·ªói k·∫øt n·ªëi API: {e}")
        return None
    except Exception as e:
        print(f"[FAQ] L·ªói x·ª≠ l√Ω d·ªØ li·ªáu: {e}")
        return None

def get_inventory_response(sentence: str) -> Optional[str]:
    try:
        resp = requests.get(INVENTORY_API_URL, params={"book_name": sentence}, timeout=5)
        if resp.status_code != 200:
            print(f"[Inventory] HTTP {resp.status_code}: {resp.text[:200]}")
            return None
        data = resp.json()
        if isinstance(data, list) and data:
            book = data[0]
            name = book.get("name")
            author = book.get("author", "?")
            year = book.get("year", "?")
            quantity = book.get("quantity", "?")
            status = book.get("status", "?")
            if name:
                return (
                    f"S√°ch '{name}' c·ªßa t√°c gi·∫£ {author}, nƒÉm xu·∫•t b·∫£n {year}, "
                    f"s·ªë l∆∞·ª£ng: {quantity}, tr·∫°ng th√°i: {status}"
                )
        return None
    except requests.RequestException as e:
        print(f"[Inventory] L·ªói k·∫øt n·ªëi API: {e}")
        return None
    except Exception as e:
        print(f"[Inventory] L·ªói x·ª≠ l√Ω d·ªØ li·ªáu: {e}")
        return None



# ============== CORE chat ==============

def ollama_alive() -> bool:
    try:
        r = requests.get(f"{OLLAMA_URL.rstrip('/')}/api/tags", timeout=3)
        return r.status_code == 200
    except Exception:
        return False
        


def _dns_ok(host: str, timeout_s: float = 3.0) -> bool:
    try:
        socket.setdefaulttimeout(timeout_s)
        socket.getaddrinfo(host, 443)
        return True
    except Exception:
        return False
def pull_approved_from_notion_to_sqlite():
    token, dbid, mode, base = _resolve_notion_env()
    url = f"{base.rstrip('/')}/databases/{dbid}/query"
    headers = {
        "Authorization": f"Bearer {token}",
        "Notion-Version": os.getenv("NOTION_VERSION", "2022-06-28"),
        "Content-Type": "application/json",
    }
    body = {
        "filter": {
            "and": [
                {"property": "Approved", "checkbox": {"equals": True}},
                # N·∫øu b·∫°n t·∫°o th√™m c·ªôt "Synced" (checkbox) trong Notion:
                # {"property": "Synced", "checkbox": {"equals": False}},
            ]
        }
    }
    r = requests.post(url, headers=headers, json=body, timeout=12)
    r.raise_for_status()
    data = r.json()

    conn = ensure_main_db()
    cur = conn.cursor()

    for row in data.get("results", []):
        props = row.get("properties", {})
        q = props.get("Question", {}).get("rich_text", [{}])[0].get("plain_text", "")
        a = props.get("Answer", {}).get("rich_text", [{}])[0].get("plain_text", "")

        # l∆∞u v√†o SQLite (v√≠ d·ª• conversations hay b·∫£ng ri√™ng)
        cur.execute(
            "INSERT INTO conversations(user_message, bot_reply, intent_tag, confidence, time) VALUES (?,?,?,?,?)",
            (q, a, None, 1.0, _now()),
        )
        # ƒê√°nh d·∫•u ƒë√£ sync n·∫øu b·∫°n c√≥ c·ªôt Synced trong Notion:
        # page_id = row["id"]
        # requests.patch(f"{base.rstrip('/')}/pages/{page_id}",
        #    headers={**headers, "Content-Type": "application/json"},
        #    json={"properties": {"Synced": {"checkbox": True}}})

    conn.commit()
    conn.close()

# ============== Notion helpers (ntn_ token, auto-mapping) ==============
from functools import lru_cache

def _resolve_notion_env():
    try:
        if os.path.exists(ENV_PATH):
            load_dotenv(ENV_PATH, override=True)
    except Exception:
        pass
    token = os.getenv("NOTION_TOKEN") or os.getenv("NOTION_API_KEY") or ""
    dbid  = (
        os.getenv("NOTION_DATABASE_ID")
        or os.getenv("DATABASE_ID_FAQ")
        or os.getenv("DATABASE_ID_BOOKS")
        or os.getenv("DATABASE_ID_MAJORS")
        or ""
    )
    base  = (os.getenv("NOTION_BASE_URL") or "https://api.notion.com/v1").rstrip("/")
    mode  = "sdk" if token.startswith("secret_") else "http"  # ntn_ => http

    # Fallback an to√†n n·∫øu ƒëang tr·ªè t·ªõi ntn-api nh∆∞ng DNS/route h·ªèng
    if token.startswith("ntn_") and "ntn-api.notion.so" in base:
        if not _dns_ok("ntn-api.notion.so"):
            base = "https://api.notion.com/v1"

    return token, dbid, mode, base

def _rt(txt: str):
    return [{"type": "text", "text": {"content": txt or ""}}]

def _http_session_with_retry(total=2, backoff=0.6):
    s = requests.Session()
    retry = Retry(
        total=total,
        backoff_factor=backoff,
        status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=["GET", "POST", "HEAD"],
    )
    s.mount("https://", HTTPAdapter(max_retries=retry))
    s.mount("http://", HTTPAdapter(max_retries=retry))
    return s

def _ntn_session():
    # nh·∫π h∆°n, ∆∞u ti√™n gi·∫£m ch·ªù
    return _http_session_with_retry(total=1, backoff=0.4)

def ntn_ok(base: str) -> bool:
    """Preflight: confirm CF/Notion ph·∫£n h·ªìi ƒë·ªÉ tr√°nh timeout k√©o d√†i."""
    base = (base or "").rstrip("/")
    try:
        r = requests.get("https://api.notion.com/v1/status", timeout=6)
        if r.status_code not in (200, 400, 401, 405):
            print("[Preflight] api.notion.com status:", r.status_code)
    except requests.exceptions.RequestException:
        return False

    if "ntn-api.notion.so" in base:
        try:
            rr = requests.head(f"{base}/pages", timeout=6)
            return rr.status_code in (200,201,400,401,403,405,429,500,502,503,504,530)
        except requests.exceptions.RequestException:
            return False
    return True

def _http_create_page(token: str, base_url: str, payload: dict, timeout_s: float = 15.0):
    """POST /pages, tr·∫£ (ok, status, body_text)."""
    url = f"{base_url.rstrip('/')}/pages"
    headers = {
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json",
        "Accept": "application/json",
        "User-Agent": "Mozilla/5.0",
        "Notion-Version": os.getenv("NOTION_VERSION", "2022-06-28"),
        "Host": "ntn-api.notion.so" if "ntn-api.notion.so" in base_url else "api.notion.com",
    }
    try:
        sess = _ntn_session()
        r = sess.post(url, headers=headers, json=payload, timeout=timeout_s, allow_redirects=True)
        ok = r.status_code in (200, 201)
        return ok, r.status_code, r.text
    except requests.exceptions.Timeout:
        return False, 408, "timeout"
    except Exception as e:
        return False, -1, f"{type(e).__name__}: {e}"

@lru_cache(maxsize=8)
def _fetch_db_schema(token: str, base: str, dbid: str) -> dict:
    """L·∫•y schema DB ƒë·ªÉ auto-map properties (cache theo (token,base,dbid))."""
    url = f"{base.rstrip('/')}/databases/{dbid}"
    headers = {
        "Authorization": f"Bearer {token}",
        "Notion-Version": os.getenv("NOTION_VERSION", "2022-06-28"),
        "Accept": "application/json",
    }
    sess = _http_session_with_retry(total=2, backoff=0.5)
    r = sess.get(url, headers=headers, timeout=10)
    if r.status_code not in (200, 201):
        raise RuntimeError(f"GET /databases/{dbid} FAIL {r.status_code}: {r.text[:500]}")
    return r.json()

def _pick_prop_by_type(props: dict, want_type: str, prefer_names: list[str]) -> Optional[str]:
    """Ch·ªçn t√™n c·ªôt theo type: ∆∞u ti√™n theo danh s√°ch t√™n g·ª£i √Ω, fallback c·ªôt b·∫•t k·ª≥ c√πng type."""
    # ∆∞u ti√™n theo t√™n
    lower_props = {k.lower(): k for k in props.keys()}
    for name in prefer_names:
        key = lower_props.get(name.lower())
        if key and props.get(key, {}).get("type") == want_type:
            return key
    # fallback: l·∫•y c·ªôt ƒë·∫ßu ti√™n c√≥ type ph√π h·ª£p
    for k, v in props.items():
        if v.get("type") == want_type:
            return k
    return None

def _ensure_select_option(token: str, base: str, dbid: str, prop_name: str, option_name: str) -> str:
    """
    ƒê·∫£m b·∫£o option select t·ªìn t·∫°i; n·∫øu ch∆∞a c√≥ s·∫Ω th√™m (best effort).
    Tr·∫£ l·∫°i option_name (c√≥ th·ªÉ ƒë√£ t·ªìn t·∫°i ho·∫∑c v·ª´a t·∫°o).
    """
    # ƒê·ªçc schema
    schema = _fetch_db_schema(token, base, dbid)
    props = schema.get("properties", {})
    prop = props.get(prop_name, {})
    if prop.get("type") != "select":
        return option_name  # kh√¥ng ph·∫£i select th√¨ b·ªè qua

    options = prop.get("select", {}).get("options", []) or []
    names = {opt.get("name"): opt.get("id") for opt in options if isinstance(opt, dict)}
    if option_name in names:
        return option_name

    # Th·ª≠ th√™m option qua update database
    url = f"{base.rstrip('/')}/databases/{dbid}"
    headers = {
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json",
        "Notion-Version": os.getenv("NOTION_VERSION", "2022-06-28"),
    }
    new_opt = {"name": option_name}
    body = {
        "properties": {
            prop_name: {
                "select": {
                    "options": options + [new_opt]
                }
            }
        }
    }
    try:
        r = requests.patch(url, headers=headers, json=body, timeout=12)
        if r.status_code in (200, 201):
            return option_name
        else:
            # Kh√¥ng t·∫°o ƒë∆∞·ª£c option ‚Üí v·∫´n d√πng t√™n option (Notion s·∫Ω reject n·∫øu ch∆∞a c√≥)
            print(f"[Notion] WARN: add select option FAIL {r.status_code}: {r.text[:400]}")
            return option_name
    except Exception as e:
        print(f"[Notion] WARN: add select option error: {e}")
        return option_name


def _build_dynamic_payload_force(dbid: str, q: str, a: str) -> dict:
    title_txt = (q or "C√¢u h·ªèi").strip()[:200]
    today_iso = datetime.now().date().isoformat()

    props = {
        "Question": {"rich_text": [{"type": "text", "text": {"content": q or ""}}]},
        "Answer":   {"rich_text": [{"type": "text", "text": {"content": a or ""}}]},
        # Cho item xu·∫•t hi·ªán ngay ·ªü view ch√≠nh:
        "Approved": {"checkbox": True},  # <-- b·∫≠t n·∫øu view ƒëang l·ªçc Approved = checked
        "Language": {"select": {"name": "Ti·∫øng Vi·ªát"}},  # <-- kh·ªõp filter Language
        "Last Update": {"date": {"start": today_iso}},
    }

    # N·∫øu b·∫£ng c·ªßa b·∫°n B·∫ÆT BU·ªòC c√≥ Category ƒë·ªÉ v√†o view, set th√™m 1 value h·ª£p l·ªá:
    # props["Category"] = {"select": {"name": "Quy ƒë·ªãnh"}}

    return {
        "parent": {"database_id": dbid},
        "properties": props,
    }




def push_to_notion(q: str, a: str):
    """
    ƒê·∫©y ngay t·ª´ng d√≤ng l√™n Notion (ntn_). T·ª± d√≤ schema v√† map properties.
    In l·ªói chi ti·∫øt khi fail ƒë·ªÉ b·∫°n s·ª≠a ƒë√∫ng ch·ªó.
    """
    global _notion_warned_once
    q = (q or "").strip(); a = (a or "").strip()
    if not q:
        return

    token, dbid, mode, base = _resolve_notion_env()
    if not token or not dbid:
        print("[Notion] B·ªè qua: thi·∫øu token/dbid.")
        return

    # Ch·ªâ h·ªó tr·ª£ http (ntn_) ·ªü ƒë√¢y; n·∫øu b·∫°n d√πng secret_, c√≥ th·ªÉ nh√°nh SDK.
    if mode != "http":
        print("[Notion] B·∫°n ƒëang d√πng secret_; nh√°nh HTTP n√†y d√†nh cho ntn_.")
        return

    # Preflight ‚Äì tr√°nh ƒë·ª£i timeout v√¥ √≠ch
    # üëâ Preflight: c√≥ th·ªÉ B·ªé QUA n·∫øu FORCE_PUSH_NOTION=1
    force_push = os.getenv("FORCE_PUSH_NOTION", "0") == "1"
    if not force_push and not ntn_ok(base):
        if not _notion_warned_once:
            print("[Notion] Gateway hi·ªán kh√¥ng reachable ‚Üí b·ªè qua l·∫ßn n√†y.")
            _notion_warned_once = True
        return
    else:
        if force_push:
            print("[Notion] FORCE: b·ªè qua preflight, th·ª≠ push tr·ª±c ti·∫øp...")


    # Build payload theo schema th·ª±c t·∫ø
    try:
        payload = _build_dynamic_payload_force(dbid, q, a)

    except Exception as e:
        print(f"[Notion] Build payload error: {e}")
        return

    ok, status, body = _http_create_page(token, base, payload, timeout_s=15.0)
    if ok:
        print(f"[Notion] OK ({status})")
    else:
        # In body ƒë·∫ßy ƒë·ªß ƒë·ªÉ th·∫•y l·ªói th·∫≠t (property n√†o sai type/t√™n/option)
        print(f"[Notion] FAIL ({status})\n{body[:2000]}")


def _ntn_session():
    s = requests.Session()
    retry = Retry(
        total=1,               # ch·ªâ 1 l·∫ßn retry nh·∫π ƒë·ªÉ kh√¥ng ch·ªù l√¢u
        backoff_factor=0.4,
        status_forcelist=[429,500,502,503,504],
        allowed_methods=["POST", "HEAD"],
    )
    s.mount("https://", HTTPAdapter(max_retries=retry))
    s.mount("http://", HTTPAdapter(max_retries=retry))
    return s
# ============== Ollama append (an to√†n) ==============
def sanitize_vi(extra: str) -> str:
    if not extra: return ""
    extra = re.sub(r'[\u3400-\u9FFF\uF900-\uFAFF]+', '', extra)
    extra = re.sub(r'[\U0001F300-\U0001FAFF]', '', extra)
    extra = extra.replace('‚Äú','').replace('‚Äù','').replace('"','').strip()
    extra = re.sub(r'\s+', ' ', extra)
    banned_starts = ("ch√†o m·ª´ng", "r·∫•t ti·∫øc", "xin ch√†o", "c·∫£m ∆°n")
    if extra.lower().startswith(banned_starts): return ""
    if len(extra.split()) < 3: return ""
    return extra
def get_recent_history(limit=6):
    """L·∫•y lu√¢n phi√™n Q/A g·∫ßn nh·∫•t, m·ªõi ‚Üí c≈© (t·ªëi ƒëa limit d√≤ng)."""
    try:
        conn = sqlite3.connect(DB_PATH)
        cur = conn.cursor()
        cur.execute("""
            SELECT user_message, bot_reply, time
            FROM conversations
            ORDER BY id DESC
            LIMIT ?
        """, (limit,))
        rows = cur.fetchall()
        conn.close()
        # ƒë·∫£o l·∫°i cho th√†nh c≈© ‚Üí m·ªõi
        rows.reverse()
        return rows
    except Exception:
        return []

def ollama_generate_continuation(base_reply: str, user_message: str, max_sentences=3) -> str:
    url = f"{OLLAMA_URL.rstrip('/')}/api/generate"
    history = get_recent_history(limit=8)

    # Gh√©p l·ªãch s·ª≠: Q/A ng·∫Øn g·ªçn
    hist_lines = []
    for q, a, t in history:
        q = (q or "").strip()
        a = (a or "").strip()
        if q or a:
            hist_lines.append(f"- User: {q}")
            hist_lines.append(f"  Bot: {a}")
    hist_block = "\n".join(hist_lines[-14:])  # tr√°nh d√†i qu√°

    system_prompt = (
        "B·∫°n l√† tr·ª£ l√Ω th∆∞ vi·ªán DHTN. D·ª±a v√†o l·ªãch s·ª≠ h·ªôi tho·∫°i d∆∞·ªõi ƒë√¢y, "
        "h√£y VI·∫æT TI·∫æP ph·∫ßn tr·∫£ l·ªùi cho m∆∞·ª£t m√†, ch·ªâ th√™m √Ω b·ªï sung h·ª£p l√Ω, "
        "KH√îNG l·∫∑p l·∫°i nguy√™n vƒÉn, KH√îNG m·ªü ch·ªß ƒë·ªÅ m·ªõi, KH√îNG b·ªãa s·ªë li·ªáu. "
        "N·∫øu l·ªãch s·ª≠ kh√¥ng gi√∫p √≠ch, tr·∫£ v·ªÅ chu·ªói R·ªñNG.\n"
        "Gi·ªõi h·∫°n 1‚Äì3 c√¢u ng·∫Øn. Ch·ªâ ti·∫øng Vi·ªát."
    )

    user_prompt = (
        f"L·ªãch s·ª≠ g·∫ßn ƒë√¢y:\n{hist_block}\n\n"
        f"C√¢u tr·∫£ l·ªùi hi·ªán t·∫°i c·ªßa bot:\n{base_reply}\n\n"
        f"Ng∆∞·ªùi d√πng v·ª´a h·ªèi:\n{user_message}\n\n"
        f"Y√äU C·∫¶U: Vi·∫øt ti·∫øp ng·∫Øn g·ªçn (1‚Äì3 c√¢u) b·ªï sung √Ω d·ª±a tr√™n l·ªãch s·ª≠. "
        f"N·∫øu kh√¥ng ph√π h·ª£p, tr·∫£ v·ªÅ r·ªóng."
    )

    payload = {
        "model": OLLAMA_MODEL,
        "prompt": f"{system_prompt}\n\n{user_prompt}",
        "stream": False,
        "options": {
            "temperature": 0.2,
            "top_p": 0.9,
            "repeat_penalty": 1.15,
            "num_predict": 120
        }
    }

    try:
        r = requests.post(url, json=payload, timeout=OLLAMA_TIMEOUT)
        if r.status_code != 200:
            print(f"[Ollama-continue] HTTP {r.status_code}: {r.text[:200]}")
            return ""
        extra = (r.json().get("response") or "").strip()
        # l√†m s·∫°ch ng·∫Øn g·ªçn
        extra = re.sub(r'\s+', ' ', extra)
        if not extra or extra.lower() in ("", "r·ªóng", "(r·ªóng)"):
            return ""
        # c·∫Øt t·ªëi ƒëa 3 c√¢u
        sentences = [s.strip() for s in re.split(r'[.!?‚Ä¶]+', extra) if s.strip()]
        extra_short = ". ".join(sentences[:max_sentences]).strip()
        return (extra_short + ".") if extra_short and not extra_short.endswith(".") else extra_short
    except Exception as e:
        print("[Ollama-continue] Error:", e)
        return ""
    # t·ª± ƒë·ªông l·∫•y intent t·ª´ notion 
def get_all_categories():
    conn = sqlite3.connect(FAQ_DB_PATH)
    cur = conn.cursor()
    cur.execute("SELECT DISTINCT category FROM faq WHERE category IS NOT NULL")
    rows = cur.fetchall()
    conn.close()
    # tr·∫£ v·ªÅ list t√™n categories, lo·∫°i b·ªè None, r·ªóng
    cats = [ (r[0] or "").strip() for r in rows ]
    cats = [c for c in cats if c]
    cats.extend(["Th√¥ng tin ng√†nh", "Tra c·ª©u s√°ch"])
    return sorted(set(cats))
def get_all_major_names():
    conn = sqlite3.connect(FAQ_DB_PATH)
    cur = conn.cursor()
    cur.execute("SELECT name FROM majors")
    rows = cur.fetchall()
    conn.close()
    return [r[0].strip().lower() for r in rows]



# def classify_category(user_message: str) -> str:
#     url = f"{OLLAMA_URL.rstrip('/')}/api/generate"
#     msg = user_message.lower().strip()

#     categories = get_all_categories()
#     # gh√©p th√†nh bullet list
#     bullet = "\n".join(f"- {c}" for c in categories)

#     system_prompt = (
#         "B·∫°n l√† tr·ª£ l√Ω ·∫£o c·ªßa Th∆∞ vi·ªán.\n"
#         "Nhi·ªám v·ª•: ƒê·ªçc c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng v√† CH·ªà TR·∫¢ V·ªÄ T√äN M·ªòT Category "
#         "trong danh s√°ch sau (ph·∫£i ch·ªçn ƒë√∫ng 1):\n\n"
#         f"{bullet}\n\n"
#         "- \"Th√¥ng tin ng√†nh\": c√¢u h·ªèi v·ªÅ ng√†nh ƒë√†o t·∫°o, t√™n ng√†nh, m√£ ng√†nh, m√¥ t·∫£ ng√†nh, "
#         "s·ªë ng√†nh, ng√†nh n√†o c√≥ ƒë√†o t·∫°o...\n"
#         "- \"Tra c·ª©u s√°ch\": c√¢u h·ªèi v·ªÅ t√™n s√°ch, danh s√°ch s√°ch, s√°ch thu·ªôc ng√†nh n√†o, "
#         "s√°ch c√≤n hay h·∫øt...\n"
#         "N·∫øu c√¢u h·ªèi ch·ªâ l√† t√™n m·ªôt ng√†nh (v√≠ d·ª•: \"C√¥ng ngh·ªá th√¥ng tin\", \"Y h·ªçc\"), "
#         "th√¨ ch·ªçn \"Th√¥ng tin ng√†nh\".\n"
#         "N·∫øu kh√¥ng ch·∫Øc ch·∫Øn -> ch·ªçn Category c√≥ v·∫ª g·∫ßn nh·∫•t. "
#         "N·∫øu ho√†n to√†n kh√¥ng ph√π h·ª£p -> ch·ªçn 'Ch∆∞a ph√¢n lo·∫°i' n·∫øu c√≥.\n\n"
#         "H√£y TR·∫¢ V·ªÄ duy nh·∫•t t√™n Category, kh√¥ng gi·∫£i th√≠ch th√™m."
#     )


#     user_prompt = f"C√¢u h·ªèi ng∆∞·ªùi d√πng: \"{user_message}\""

#     payload = {
#         "model": OLLAMA_MODEL,
#         "prompt": system_prompt + "\n\n" + user_prompt,
#         "stream": False,
#         "options": {
#             "temperature": 0.0,
#             "num_predict": 32
#         }
#     }

#     try:
#         r = requests.post(url, json=payload, timeout=OLLAMA_TIMEOUT)
#         resp = (r.json().get("response") or "").strip()
#         cat = resp.splitlines()[0].strip()
#         return cat or "Ch∆∞a ph√¢n lo·∫°i"
#     except Exception as e:
#         print("[Category] Error:", e)
#         return "Ch∆∞a ph√¢n lo·∫°i"
    
def answer_from_majors(user_message: str) -> str:
    try:
        # --- 1. Tr√≠ch t√™n ng√†nh ---
        extract_prompt = f"""
B·∫°n l√† tr·ª£ l√Ω th∆∞ vi·ªán.
H√£y tr√≠ch t√™n NG√ÄNH t·ª´ c√¢u h·ªèi sau.
N·∫øu kh√¥ng t√¨m th·∫•y ng√†nh ‚Üí tr·∫£ v·ªÅ r·ªóng.

C√¢u h·ªèi: "{user_message}"

Ch·ªâ tr·∫£ v·ªÅ t√™n ng√†nh (vd: C√¥ng ngh·ªá th√¥ng tin, Kinh t·∫ø, CNTT).
Kh√¥ng gi·∫£i th√≠ch th√™m.
"""
        payload = {
            "model": OLLAMA_MODEL,
            "prompt": extract_prompt,
            "stream": False,
            "options": {"temperature": 0.0, "num_predict": 50}
        }
        r = requests.post(f"{OLLAMA_URL}/api/generate", json=payload, timeout=OLLAMA_TIMEOUT)

        major_key = (r.json().get("response") or "").strip().split("\n")[0]
        major_key = re.sub(r'[^0-9a-zA-Z√Ä-·ªπ\s]', '', major_key)

        if not major_key:
            return "M√¨nh ch∆∞a x√°c ƒë·ªãnh ƒë∆∞·ª£c ng√†nh trong c√¢u h·ªèi."

        # --- 2. T√¨m ng√†nh trong b·∫£ng majors ---
        conn = sqlite3.connect(FAQ_DB_PATH)
        cur = conn.cursor()
        cur.execute("""
            SELECT name, major_id, description
            FROM majors
            WHERE name LIKE ? OR major_id LIKE ?
        """, (f"%{major_key}%", f"%{major_key}%"))

        rows = cur.fetchall()
        conn.close()

        if not rows:
            return f"Kh√¥ng t√¨m th·∫•y ng√†nh li√™n quan: {major_key}"

        # format
        text = "\n".join(f"- {name} (M√£: {mid}): {desc}" for name, mid, desc in rows)

        # --- 3. Vi·∫øt c√¢u tr·∫£ l·ªùi ---
        answer_prompt = f"""
Ng∆∞·ªùi d√πng h·ªèi: "{user_message}"
D∆∞·ªõi ƒë√¢y l√† th√¥ng tin ng√†nh t√¨m ƒë∆∞·ª£c:

{text}

H√£y tr·∫£ l·ªùi t·ª± nhi√™n, KH√îNG b·ªãa th√™m.
"""
        payload2 = {
            "model": OLLAMA_MODEL,
            "prompt": answer_prompt,
            "stream": False,
            "options": {"temperature": 0.2, "num_predict": 150}
        }
        rr = requests.post(f"{OLLAMA_URL}/api/generate", json=payload2, timeout=OLLAMA_TIMEOUT)
        return (rr.json().get("response") or "").strip()

    except Exception as e:
        return f"[L·ªñI majors] {e}"


# def classify_category(user_message: str) -> str:
#     """
#     Ph√¢n lo·∫°i √Ω ƒë·ªãnh (Intent) d·ª±a tr√™n √Ω nghƒ©a, kh√¥ng d√πng keyword matching.
#     D√πng LLM ƒë·ªÉ suy lu·∫≠n ng·ªØ nghƒ©a ‚Äì hi·ªÉu c·∫£ sai ch√≠nh t·∫£, vi·∫øt t·∫Øt, c√¢u h·ªèi thi·∫øu.
#     """

#     url = f"{OLLAMA_URL.rstrip('/')}/api/generate"
    
#     categories = get_all_categories()
#     if not categories:
#         return "Ch∆∞a ph√¢n lo·∫°i"

#     bullet = "\n".join(f"- {c}" for c in categories)

#     system_prompt = f"""
# B·∫°n l√† tr·ª£ l√Ω ·∫£o c·ªßa Th∆∞ vi·ªán. B·∫°n ph√¢n t√≠ch √ù NGHƒ®A c√¢u h·ªèi, kh√¥ng d·ª±a tr√™n t·ª´ kh√≥a.
# Nhi·ªám v·ª•: ch·ªçn CH√çNH X√ÅC 1 category ph√π h·ª£p nh·∫•t t·ª´ danh s√°ch sau:

# {bullet}

# === H∆Ø·ªöNG D·∫™N HI·ªÇU √ù (KH√îNG D√ôNG KEYWORD) ===
# - "Th√¥ng tin ng√†nh": khi ng∆∞·ªùi d√πng nh·∫Øc t√™n ng√†nh (CNTT, C√¥ng ngh·ªá th√¥ng tin, Y h·ªçc‚Ä¶)
#   k·ªÉ c·∫£ h·ªç ch·ªâ vi·∫øt t√™n ng√†nh CH·ªÆNG KH√îNG c√≥ t·ª´ ‚Äúng√†nh‚Äù.
#   Hi·ªÉu c·∫£ sai ch√≠nh t·∫£: "c√¥ng ngh√™ th√¥ng tin", "C.N.T.T", "cnt"
#   C√°c c√¢u d·∫°ng:
#     ‚Ä¢ "CNTT l√† g√¨?"
#     ‚Ä¢ "Ng√†nh ƒë√≥ c√≥ nh·ªØng m√¥n n√†o?"
#     ‚Ä¢ "Kinh t·∫ø h·ªçc ra l√†m g√¨?"
#     ‚Ä¢ "kh·ªëi y c√≥ bao nhi√™u ng√†nh?"
# - "Tra c·ª©u s√°ch": khi ng∆∞·ªùi d√πng h·ªèi v·ªÅ danh s√°ch s√°ch, t√™n s√°ch, s√°ch c·ªßa ng√†nh n√†o,
#   s√°ch c√≤n kh√¥ng, s√°ch t√°c gi·∫£ n√†o‚Ä¶
#   Hi·ªÉu c·∫£ c√¢u kh√¥ng r√µ:
#     ‚Ä¢ "C√≥ s√°ch AI kh√¥ng?"
#     ‚Ä¢ "li·ªát k√™ s√°ch CNTT"
#     ‚Ä¢ "Python c√≤n kh√¥ng?"
#     ‚Ä¢ "m·∫°ng m√°y t√≠nh c√≥ bao nhi√™u b·∫£n?"
# - N·∫øu user ch·ªâ nh·∫≠p 1 t·ª´ ho·∫∑c c·ª•m t·ª´:
#   ‚Üí N·∫øu gi·ªëng m·ªôt ng√†nh ‚Üí ch·ªçn "Th√¥ng tin ng√†nh"
#   ‚Üí N·∫øu gi·ªëng t√™n s√°ch ‚Üí ch·ªçn "Tra c·ª©u s√°ch"

# - N·∫øu c√¢u h·ªèi kh√¥ng thu·ªôc 2 nh√≥m tr√™n, ch·ªçn category c√≥ v·∫ª ph√π h·ª£p nh·∫•t
# - N·∫øu ho√†n to√†n kh√¥ng ch·∫Øc ‚Üí tr·∫£ v·ªÅ: "Ch∆∞a ph√¢n lo·∫°i"

# CH·ªà TR·∫¢ V·ªÄ DUY NH·∫§T T√äN CATEGORY.
# Kh√¥ng gi·∫£i th√≠ch th√™m.
# """

#     user_prompt = f"C√¢u h·ªèi ng∆∞·ªùi d√πng: \"{user_message}\""

#     payload = {
#         "model": OLLAMA_MODEL,
#         "prompt": system_prompt + "\n" + user_prompt,
#         "stream": False,
#         "options": {"temperature": 0.0, "num_predict": 32},
#     }

#     try:
#         r = requests.post(url, json=payload, timeout=OLLAMA_TIMEOUT)
#         raw = (r.json().get("response") or "").strip()
#         cat = raw.splitlines()[0].strip()
#         return cat or "Ch∆∞a ph√¢n lo·∫°i"
#     except:
#         return "Ch∆∞a ph√¢n lo·∫°i"
def classify_category(user_message: str) -> str:
    """
    Ph√¢n lo·∫°i intent 100% theo NG·ªÆ NGHƒ®A b·∫±ng LLM.
    Kh√¥ng d√πng keyword.
    Hi·ªÉu c·∫£ khi user ch·ªâ g√µ t√™n ng√†nh ho·∫∑c t√™n s√°ch.
    """
    url = f"{OLLAMA_URL.rstrip('/')}/api/generate"
    msg = user_message.strip()

    # L·∫•y danh s√°ch ng√†nh t·ª´ DB ‚Üí t·ª± h·ªçc
    conn = sqlite3.connect(FAQ_DB_PATH)
    cur = conn.cursor()
    cur.execute("SELECT name FROM majors")
    major_names = [r[0] for r in cur.fetchall()]
    conn.close()

    bullet = "\n".join(f"- {m}" for m in major_names)

    system_prompt = f"""
B·∫°n l√† tr·ª£ l√Ω th∆∞ vi·ªán.
Nhi·ªám v·ª•: Ph√¢n t√≠ch c√¢u c·ªßa ng∆∞·ªùi d√πng v√† ch·ªçn ch√≠nh x√°c 1 trong 2 category sau:

1) "Th√¥ng tin ng√†nh"  ‚Üí khi ng∆∞·ªùi d√πng:
    - G√µ t√™n ng√†nh (vd: C√¥ng ngh·ªá th√¥ng tin, CNTT, Y h·ªçc‚Ä¶)
    - Vi·∫øt sai ch√≠nh t·∫£ nh∆∞ng g·∫ßn gi·ªëng t√™n ng√†nh
    - H·ªèi m√¥ t·∫£ ng√†nh, ng√†nh h·ªçc g√¨, ra l√†m g√¨,‚Ä¶

2) "Tra c·ª©u s√°ch" ‚Üí khi ng∆∞·ªùi d√πng:
    - H·ªèi v·ªÅ s√°ch, t√™n s√°ch, li·ªát k√™ s√°ch
    - H·ªèi s√°ch c√≤n kh√¥ng, s√°ch ng√†nh n√†o
    - H·ªèi s√°ch theo t√°c gi·∫£, nƒÉm xu·∫•t b·∫£n,‚Ä¶

=== Danh s√°ch ng√†nh h·ª£p l·ªá ===
{bullet}

QUY T·∫ÆC:
- N·∫øu user ch·ªâ g√µ 1 t·ª´/c·ª•m t·ª´ v√† gi·ªëng v·ªõi **t√™n ng√†nh** ‚Üí ch·ªçn "Th√¥ng tin ng√†nh".
- N·∫øu user h·ªèi lo·∫°i s√°ch / t√™n s√°ch ‚Üí ch·ªçn "Tra c·ª©u s√°ch".
- Tr·∫£ v·ªÅ duy nh·∫•t 1 trong 2 chu·ªói:
    Th√¥ng tin ng√†nh
    Tra c·ª©u s√°ch
"""

    payload = {
        "model": OLLAMA_MODEL,
        "prompt": system_prompt + "\n\nC√¢u c·ªßa user: " + msg,
        "stream": False,
        "options": {"temperature": 0.0, "num_predict": 32}
    }

    try:
        r = requests.post(url, json=payload, timeout=OLLAMA_TIMEOUT)
        raw = (r.json().get("response") or "").strip().splitlines()[0]
        return raw if raw in ["Th√¥ng tin ng√†nh", "Tra c·ª©u s√°ch"] else "Tra c·ª©u s√°ch"
    except:
        return "Tra c·ª©u s√°ch"



def answer_from_books(user_message: str) -> str:
    try:
        text = user_message.strip().lower()
        conn = sqlite3.connect(FAQ_DB_PATH)
        cur = conn.cursor()

        # ========== 1) Ki·ªÉm tra user nh·∫≠p t√™n NG√ÄNH ==========
        cur.execute("SELECT name, major_id FROM majors")
        majors = cur.fetchall()

        for name, major_id in majors:
            if text == name.lower().strip():
                cur.execute("""
                    SELECT name, author, year, quantity, status
                    FROM books
                    WHERE major_id = ?
                """, (major_id,))
                books = cur.fetchall()
                conn.close()

                if not books:
                    return f"Ng√†nh {name} hi·ªán ch∆∞a c√≥ s√°ch."

                block = "\n".join(
                    f"- {n} ‚Äì {a}, {y}, SL: {q}, Tr·∫°ng th√°i: {s}"
                    for n, a, y, q, s in books
                )
                return f"Danh s√°ch s√°ch thu·ªôc ng√†nh **{name}**:\n\n{block}"

        # ========== 2) Ki·ªÉm tra user h·ªèi T√ÅC GI·∫¢ ==========
        cur.execute("SELECT DISTINCT author FROM books")
        authors = [r[0].lower().strip() for r in cur.fetchall()]

        for a in authors:
            if a in text or text in a:
                cur.execute("""
                    SELECT name, year, quantity, status
                    FROM books
                    WHERE lower(author) = ?
                """, (a,))
                books = cur.fetchall()
                conn.close()

                if not books:
                    return f"T√°c gi·∫£ {a} ch∆∞a c√≥ s√°ch trong h·ªá th·ªëng."

                block = "\n".join(
                    f"- {n}, {y}, SL: {q}, Tr·∫°ng th√°i: {s}"
                    for n, y, q, s in books
                )
                return f"C√°c s√°ch c·ªßa t√°c gi·∫£ **{a}**:\n\n{block}"

        # ========== 3) Ki·ªÉm tra user nh·∫≠p T√äN S√ÅCH ==========
        cur.execute("""
            SELECT name, author, year, quantity, status, major_id
            FROM books
        """)
        rows = cur.fetchall()

        for n, a, y, q, s, m in rows:
            if text == n.lower().strip():
                # T√¨m t√™n ng√†nh
                cur.execute("SELECT name FROM majors WHERE major_id = ?", (m,))
                major_name = cur.fetchone()
                major_label = major_name[0] if major_name else "Kh√¥ng r√µ"

                conn.close()
                return (
                    f"**Th√¥ng tin s√°ch:**\n"
                    f"- T√™n: {n}\n"
                    f"- T√°c gi·∫£: {a}\n"
                    f"- NƒÉm XB: {y}\n"
                    f"- S·ªë l∆∞·ª£ng: {q}\n"
                    f"- Tr·∫°ng th√°i: {s}\n"
                    f"- Ng√†nh: {major_label}"
                )

        # ========== 4) N·∫øu kh√¥ng tr√πng g√¨ ‚Üí d√πng LLM tr√≠ch keyword ==========
        extract_prompt = f"""
B·∫°n l√† tr·ª£ l√Ω th∆∞ vi·ªán.
Nhi·ªám v·ª•: tr√≠ch T√äN S√ÅCH ho·∫∑c T√äN T√ÅC GI·∫¢ t·ª´ c√¢u h·ªèi sau.

Ch·ªâ tr·∫£ v·ªÅ:
- Ho·∫∑c 1 t√™n s√°ch
- Ho·∫∑c 1 t√™n t√°c gi·∫£
- N·∫øu kh√¥ng t√¨m th·∫•y ‚Üí tr·∫£ r·ªóng

C√¢u h·ªèi: "{user_message}"
"""

        payload = {
            "model": OLLAMA_MODEL,
            "prompt": extract_prompt,
            "stream": False,
            "options": {"temperature": 0.0, "num_predict": 50}
        }
        r = requests.post(f"{OLLAMA_URL}/api/generate", json=payload, timeout=OLLAMA_TIMEOUT)
        key = (r.json().get("response") or "").split("\n")[0].strip()
        key = key.lower()

        if not key:
            return "Kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p."

        # ========== 5) T√¨m theo t√™n s√°ch g·∫ßn ƒë√∫ng ==========
        cur = sqlite3.connect(FAQ_DB_PATH).cursor()
        cur.execute("""
            SELECT name, author, year, quantity, status, major_id
            FROM books
            WHERE lower(name) LIKE ?
        """, (f"%{key}%",))
        book_rows = cur.fetchall()

        if book_rows:
            n, a, y, q, s, m = book_rows[0]
            cur.execute("SELECT name FROM majors WHERE major_id = ?", (m,))
            major = cur.fetchone()
            major_label = major[0] if major else "Kh√¥ng r√µ"

            return (
                f"**Th√¥ng tin s√°ch:**\n"
                f"- T√™n: {n}\n"
                f"- T√°c gi·∫£: {a}\n"
                f"- NƒÉm XB: {y}\n"
                f"- S·ªë l∆∞·ª£ng: {q}\n"
                f"- Tr·∫°ng th√°i: {s}\n"
                f"- Ng√†nh: {major_label}"
            )

        # Kh√¥ng t√¨m th·∫•y g√¨ c·∫£
        return f"Kh√¥ng t√¨m th·∫•y s√°ch li√™n quan t·ªõi: **{key}**"

    except Exception as e:
        return f"[L·ªñI books] {e}"



def process_message(sentence: str) -> str:
    sentence = (sentence or "").strip()
    if not sentence:
        return "Xin l·ªói, m√¨nh ch∆∞a hi·ªÉu √Ω b·∫°n."

    reply: Optional[str] = None
    tag_to_log: Optional[str] = None
    confidence: float = 0.0

    if ollama_alive():
        try:
            # 1) Ph√¢n lo·∫°i Category (Intent) b·∫±ng LLM
            category = classify_category(sentence)
            tag_to_log = category  # lu√¥n log intent = category

            # 2) R·∫Ω nh√°nh theo category l·ªõn
            
            if category == "Th√¥ng tin ng√†nh":
                major_reply = answer_from_majors(sentence)
                if major_reply:
                    reply = major_reply
                    tag_to_log = category

            elif category == "Tra c·ª©u s√°ch":
                book_reply = answer_from_books(sentence)
                if book_reply:
                    reply = book_reply
                    tag_to_log = category
            else:
                # 3) M·∫∑c ƒë·ªãnh: d√πng FAQ (Notion ‚Üí faq.db)
                conn_faq = sqlite3.connect(FAQ_DB_PATH)   # faq.db
                cur_faq = conn_faq.cursor()
                cur_faq.execute("""
                    SELECT question, answer
                    FROM faq
                    WHERE category = ?
                      AND (approved = 1 OR approved IS NULL)
                """, (category,))
                rows = cur_faq.fetchall()
                conn_faq.close()

                if rows:
                    # Gh√©p block Q/A cho LLM ƒë·ªçc v√† tr·∫£ l·ªùi
                    faq_block_lines = []
                    for idx, (q, a) in enumerate(rows, start=1):
                        q = (q or "").strip()
                        a = (a or "").strip()
                        faq_block_lines.append(f"{idx}) Q: {q}\n   A: {a}")
                    faq_block = "\n\n".join(faq_block_lines)

                    answer_prompt = (
                        "B·∫°n l√† chatbot c·ªßa Th∆∞ vi·ªán.\n"
                        f"C√ÇU H·ªéI C·ª¶A NG∆Ø·ªúI D√ôNG:\n{sentence}\n\n"
                        f"DANH S√ÅCH C√ÇU H·ªéI ‚Äì C√ÇU TR·∫¢ L·ªúI TRONG CATEGORY \"{category}\":\n\n"
                        f"{faq_block}\n\n"
                        "NHI·ªÜM V·ª§:\n"
                        "1. ƒê·ªçc k·ªπ c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng v√† c√°c Answer (A) ·ªü tr√™n.\n"
                        "2. Tr·∫£ l·ªùi d·ª±a tr√™n N·ªòI DUNG c√°c Answer n√†y. C√≥ th·ªÉ gh√©p th√¥ng tin t·ª´ nhi·ªÅu Answer n·∫øu c·∫ßn.\n"
                        "3. KH√îNG ƒë∆∞·ª£c b·ªãa th√™m th√¥ng tin ngo√†i nh·ªØng g√¨ c√≥ trong Answer.\n"
                        "4. N·∫øu kh√¥ng c√≥ Answer n√†o ph√π h·ª£p, h√£y n√≥i: "
                        "\"Hi·ªán t·∫°i m√¨nh ch∆∞a c√≥ th√¥ng tin ch√≠nh x√°c trong h·ªá th·ªëng th∆∞ vi·ªán v·ªÅ c√¢u h·ªèi n√†y.\"\n\n"
                        "B√¢y gi·ªù h√£y tr·∫£ l·ªùi ng∆∞·ªùi d√πng:"
                    )

                    payload = {
                        "model": OLLAMA_MODEL,
                        "prompt": answer_prompt,
                        "stream": False,
                        "options": {
                            "temperature": 0.2,
                            "num_predict": 200
                        }
                    }

                    r = requests.post(f"{OLLAMA_URL.rstrip('/')}/api/generate",
                                      json=payload, timeout=OLLAMA_TIMEOUT)
                    if r.status_code == 200:
                        reply_llm = (r.json().get("response") or "").strip()
                        if reply_llm:
                            reply = reply_llm
                            confidence = 0.9  # t·∫°m g√°n cao, sau ch·ªânh sau
        except Exception as e:
            print("[process_message] FAQ/LLM error:", e)

    # 2) Fallback: n·∫øu v·∫´n ch∆∞a c√≥ c√¢u tr·∫£ l·ªùi, tr·∫£ m·∫∑c ƒë·ªãnh
    if reply is None or not reply.strip():
        reply = "Xin l·ªói, m√¨nh ch∆∞a hi·ªÉu √Ω b·∫°n."
        confidence = 0.0

    # 3) Append th√™m c√¢u cho m∆∞·ª£t, d√πng h√†m c≈© (n·∫øu b·∫≠t)
    if ENABLE_OLLAMA_APPEND and reply.strip() and ollama_alive():
        extra = ollama_generate_continuation(reply, sentence, max_sentences=3)
        if extra:
            reply = f"{reply.strip()} {extra.strip()}"
        


    # 4) Ghi SQLite (b·∫£ng conversations) nh∆∞ tr∆∞·ªõc
    conn = ensure_main_db()
    cur  = conn.cursor()
    cur.execute(
        "INSERT INTO conversations(user_message, bot_reply, intent_tag, confidence, time) "
        "VALUES (?,?,?,?,?)",
        (sentence, reply, tag_to_log, confidence, _now()),
    )
    conn.commit()
    conn.close()

    # 5) Ghi th√™m v√†o faq.db (inbox) nh∆∞ c≈©
    try:
        log_question_for_notion(f"User: {sentence}\nBot: {reply}")
    except Exception as e:
        print(f"[Notion inbox] L·ªói ghi faq.db: {e}")

    # 6) ƒê·∫©y Notion (kh√¥ng ch·∫∑n lu·ªìng chat) ‚Äì gi·ªØ logic c≈©
    should_push = (
        LOG_ALL_QUESTIONS
        or reply.strip().startswith("Xin l·ªói, m√¨nh ch∆∞a hi·ªÉu")
        or confidence < CONF_THRESHOLD
        or tag_to_log is None
    )
    if should_push:
        try:
            threading.Thread(target=push_to_notion, args=(sentence, reply), daemon=True).start()
        except Exception as e:
            print("Notion push error:", e)

    return reply

# ============== CLI ==============
def _test_push_notion_once():
    token, dbid, mode, base = _resolve_notion_env()
    tok_prefix = (token.split("_",1)[0]+"_") if "_" in token else token[:6]
    print("[TEST] mode:", mode, "| dbid:", dbid, "| base:", base, "| token_prefix:", tok_prefix)

    # Test /status (Cloudflare/Notion)
    try:
        r = requests.get("https://api.notion.com/v1/status", timeout=6)
        print("[TEST] status api.notion.com:", r.status_code)
    except Exception as e:
        print("[TEST] status error:", e)

    if not token or not dbid:
        print("[TEST] Thi·∫øu token/dbid")
        return

    # T·∫°o payload ƒë·ªông ƒë√∫ng schema th·ª±c t·∫ø c·ªßa database
    q = "Ping t·ª´ script"
    a = "N·∫øu th·∫•y page n√†y l√† OK."
    try:
        payload = _build_dynamic_payload_force(dbid, q, a) 
    except Exception as e:
        print(f"[TEST] Build payload error:", e)
        return

    ok, code, body = _http_create_page(token, base, payload, timeout_s=15.0)
    print(f"[TEST] POST {base}/pages ‚Üí", code, (body[:200] if isinstance(body, str) else body))



if __name__ == "__main__":
    print("ü§ñ Chatbot ƒë√£ s·∫µn s√†ng! G√µ 'quit' ƒë·ªÉ tho√°t.")
    conn = ensure_main_db()
    cur  = conn.cursor()
    #_test_push_notion_once()
    try:
        while True:
            sentence = input("B·∫°n: ").strip()
            if sentence.lower() == "quit":
                break
            print("Bot:", process_message(sentence))
    finally:
        conn.close()