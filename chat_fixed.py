# chat.py â€” MERGED (flows + FAQ/Inventory API + logs to chat.db & faqs.db)

import os
import random
import json
import sqlite3
import datetime
import requests
import torch
import numpy as np

from model import NeuralNet
from nltk_utils import tokenize, bag_of_words
from state_manager import StateManager

# ===================== Cáº¤U HÃŒNH =====================
CHAT_DB_PATH   = "chat.db"                       # log há»™i thoáº¡i
FAQ_DB_PATH    = "D:/HTML/chat2/rag/faqs.db"     # inbox cÃ¢u há»i Ä‘á»ƒ Ä‘áº©y Notion
INTENTS_PATH   = "intents.json"
WEIGHTS_PATH   = "data.pth"

CONF_THRESHOLD    = 0.60
LOG_ALL_QUESTIONS = True

CANCEL_WORDS = {"há»§y","huá»·","huy","cancel","thoÃ¡t","dá»«ng","Ä‘á»•i chá»§ Ä‘á»","doi chu de"}

# Tá»« khÃ³a heuristics Ä‘á»ƒ nháº­n diá»‡n nhanh cÃ¢u liÃªn quan sÃ¡ch/FAQ
BOOK_KEYWORDS = [
    "sÃ¡ch", "tá»“n kho", "mÆ°á»£n", "tráº£", "Ä‘áº·t", "cáº¥u trÃºc dá»¯ liá»‡u",
    "trÃ­ tuá»‡ nhÃ¢n táº¡o", "láº­p trÃ¬nh python"
]
FAQ_KEYWORDS = ["thÆ° viá»‡n", "Ä‘á»‹a chá»‰", "giá»", "liÃªn há»‡", "ná»™i quy"]

# ===================== DB (chat.db) =====================
conn = sqlite3.connect(CHAT_DB_PATH)
cur = conn.cursor()
cur.execute("""
CREATE TABLE IF NOT EXISTS conversations (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    user_message TEXT,
    bot_reply   TEXT,
    intent_tag  TEXT,
    confidence  REAL,
    time        TEXT
);
""")
conn.commit()

# ===================== DB (faqs.db) =====================
def ensure_questions_log():
    os.makedirs(os.path.dirname(FAQ_DB_PATH), exist_ok=True)
    conn2 = sqlite3.connect(FAQ_DB_PATH)
    cur2 = conn2.cursor()
    cur2.execute("""
    CREATE TABLE IF NOT EXISTS questions_log (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        question   TEXT,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        synced     INTEGER DEFAULT 0
    )
    """)
    conn2.commit(); conn2.close()

def log_question_for_notation(question: str):
    """Ghi 1 cÃ¢u há»i vÃ o 'inbox' Ä‘á»ƒ push Notion sau (push_logs.py)."""
    if not question or not question.strip():
        return
    ensure_questions_log()
    conn2 = sqlite3.connect(FAQ_DB_PATH)
    cur2 = conn2.cursor()
    cur2.execute("INSERT INTO questions_log (question, synced) VALUES (?, 0)", (question.strip(),))
    conn2.commit(); conn2.close()

# ===================== MODEL / INTENTS =====================
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

with open(INTENTS_PATH, 'r', encoding='utf-8-sig') as f:
    intents = json.load(f)

data = torch.load(WEIGHTS_PATH, map_location=device)
input_size  = data["input_size"]
hidden_size = data["hidden_size"]
output_size = data["output_size"]
all_words   = data["all_words"]
tags        = data["tags"]
model_state = data["model_state"]

model = NeuralNet(input_size, hidden_size, output_size).to(device)
model.load_state_dict(model_state)
model.eval()

# ===================== STATE / FLOW =====================
try:
    state_mgr = StateManager("flows.json")
except Exception:
    state_mgr = StateManager()

# ===================== API HELPERS =====================
def get_faq_response(sentence: str) -> str | None:
    """Gá»i API FAQ (RAG) â€“ tráº£ vá» cÃ¢u tráº£ lá»i Ä‘áº§u tiÃªn náº¿u cÃ³."""
    try:
        url = "http://localhost:8000/search"
        resp = requests.get(url, params={"q": sentence}, timeout=5)
        if resp.status_code == 200:
            data = resp.json()
            if isinstance(data, list) and data:
                ans = data[0].get("answer")
                return ans if isinstance(ans, str) and ans.strip() else None
        return None
    except requests.RequestException:
        return None

def get_inventory_response(sentence: str) -> str | None:
    """Gá»i API kiá»ƒm kho theo cÃ¢u Ä‘áº§y Ä‘á»§; náº¿u khÃ´ng ra cÃ³ thá»ƒ thá»­ theo tá»« khÃ³a."""
    try:
        url = "http://localhost:8000/inventory"
        resp = requests.get(url, params={"book_name": sentence}, timeout=5)
        if resp.status_code == 200:
            data = resp.json()
            if isinstance(data, list) and data:
                b = data[0]
                # báº£o vá»‡ key
                name   = b.get("name")
                author = b.get("author", "?")
                year   = b.get("year", "?")
                qty    = b.get("quantity", "?")
                status = b.get("status", "?")
                if name:
                    return f"SÃ¡ch '{name}' cá»§a tÃ¡c giáº£ {author}, nÄƒm xuáº¥t báº£n {year}, sá»‘ lÆ°á»£ng: {qty}, tráº¡ng thÃ¡i: {status}"
        return None
    except (requests.RequestException, ValueError, KeyError, IndexError):
        return None

print("ðŸ¤– Chatbot Ä‘Ã£ sáºµn sÃ ng! GÃµ 'quit' Ä‘á»ƒ thoÃ¡t.")

try:
    while True:
        sentence = input("Báº¡n: ").strip()
        if sentence.lower() == "quit":
            break

        # ===== Há»¦Y FLOW THá»¦ CÃ”NG =====
        if sentence.lower() in CANCEL_WORDS:
            try:
                if hasattr(state_mgr, "exit_flow"):
                    state_mgr.exit_flow()
                elif hasattr(state_mgr, "_exit_flow"):
                    state_mgr._exit_flow()
                else:
                    setattr(state_mgr, "active_flow", None)
                    setattr(state_mgr, "current_state", None)
            except Exception:
                pass
            reply = "ÄÃ£ há»§y luá»“ng hiá»‡n táº¡i. Báº¡n muá»‘n há»i gÃ¬ tiáº¿p?"
            print("Bot:", reply)
            cur.execute(
                "INSERT INTO conversations(user_message, bot_reply, intent_tag, confidence, time) VALUES (?,?,?,?,?)",
                (sentence, reply, None, 0.0, datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
            )
            conn.commit()
            continue

        # ===== KHá»žI Táº O =====
        reply = None
        tag_to_log = None
        confidence = 0.0

        # ===== NLU: dá»± Ä‘oÃ¡n intent =====
        tokens = tokenize(sentence)
        X = bag_of_words(tokens, all_words)
        X = torch.from_numpy(X).unsqueeze(0).to(device)

        with torch.no_grad():
            output = model(X)
            probs = torch.softmax(output, dim=1)
            prob, pred_idx = torch.max(probs, dim=1)
            tag = tags[pred_idx.item()]
            confidence = float(prob.item())

        # ===== Æ¯U TIÃŠN NGá»® Cáº¢NH (FLOW) =====
        # 0) Náº¿u Ä‘ang á»Ÿ flow: tiáº¿p tá»¥c flow trÆ°á»›c
        if getattr(state_mgr, "active_flow", None):
            try:
                ctx_reply = state_mgr.handle(tag, sentence)
            except Exception:
                ctx_reply = None
            if ctx_reply:
                reply = ctx_reply
                tag_to_log = tag

        # 1) Heuristic: náº¿u cÃ³ váº» há»i vá» SÃCH â†’ gá»i INVENTORY API trÆ°á»›c
        if reply is None and any(w in sentence.lower() for w in BOOK_KEYWORDS):
            inv = get_inventory_response(sentence)
            if not inv:
                # Thá»­ tÃ¡ch tá»« khÃ³a Ä‘Æ¡n láº»
                for kw in sentence.split():
                    inv = get_inventory_response(kw)
                    if inv:
                        break
            if inv:
                reply = inv
                tag_to_log = "inventory_search"

        # 2) Heuristic: náº¿u cÃ³ váº» cÃ¢u há»i FAQ thÆ° viá»‡n â†’ gá»i FAQ API
        if reply is None and any(w in sentence.lower() for w in FAQ_KEYWORDS):
            faq = get_faq_response(sentence)
            if not faq:
                for kw in sentence.split():
                    faq = get_faq_response(kw)
                    if faq:
                        break
            if faq:
                reply = faq
                tag_to_log = "faq_search"

        # 3) Náº¿u chÆ°a cÃ³ â†’ thá»­ khá»Ÿi Ä‘á»™ng/tiáº¿p flow theo intent (khi tá»± tin)
        if reply is None and confidence > CONF_THRESHOLD:
            try:
                ctx_reply = state_mgr.handle(tag, sentence)
            except Exception:
                ctx_reply = None
            if ctx_reply:
                reply = ctx_reply
                tag_to_log = tag

        # 4) Náº¿u váº«n chÆ°a cÃ³ â†’ bootstrap theo tá»« khÃ³a trong flows.json
        if reply is None:
            try:
                boot = state_mgr.bootstrap_by_text(sentence)
            except Exception:
                boot = None
            if boot:
                reply = boot

        # 5) Náº¿u váº«n chÆ°a cÃ³ â†’ dÃ¹ng responses theo intent (khi Ä‘á»§ tá»± tin)
        if reply is None and confidence > CONF_THRESHOLD:
            resp_list = next((it["responses"] for it in intents["intents"] if it["tag"] == tag), None)
            if resp_list:
                reply = random.choice(resp_list)
                tag_to_log = tag

        # 6) Fallback cuá»‘i
        if reply is None:
            reply = "Xin lá»—i, mÃ¬nh chÆ°a hiá»ƒu Ã½ báº¡n."

        print("Bot:", reply)

        # ===== LÆ¯U LOG Há»˜I THOáº I (chat.db) =====
        cur.execute(
            "INSERT INTO conversations(user_message, bot_reply, intent_tag, confidence, time) VALUES (?,?,?,?,?)",
            (sentence, reply, tag_to_log, confidence, datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
        )
        conn.commit()

        # ===== GHI 'INBOX CÃ‚U Há»ŽI' (faqs.db) Ä‘á»ƒ Ä‘áº©y Notion sau =====
        should_push_to_notion = (
            LOG_ALL_QUESTIONS or
            reply.strip().startswith("Xin lá»—i, mÃ¬nh chÆ°a hiá»ƒu") or
            confidence < CONF_THRESHOLD or
            tag_to_log is None
        )
        if should_push_to_notion:
            try:
                log_question_for_notation(f"User: {sentence}\nBot: {reply}")
            except Exception:
                # khÃ´ng Ä‘á»ƒ lá»—i logging lÃ m há»ng phiÃªn chat
                pass

finally:
    conn.close()
