# chat_fixed.py (revised)
import random
import json
import torch
from model import NeuralNet
from nltk_utils import tokenize, bag_of_words
import numpy as np
import sqlite3, datetime
from state_manager import StateManager
import requests


DB_PATH = "chat.db"
CONF_THRESHOLD = 0.60  # h·∫° t·∫°m ƒë·ªÉ d·ªÖ k√≠ch ho·∫°t intent khi data c√≤n m·ªèng


# --- K·∫øt n·ªëi & chu·∫©n b·ªã DB ---
conn = sqlite3.connect(DB_PATH)
cur = conn.cursor()
cur.execute("""
CREATE TABLE IF NOT EXISTS conversations (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    user_message TEXT,
    bot_reply   TEXT,
    intent_tag  TEXT,
    confidence  REAL,
    time        TEXT
);
""")
conn.commit()


device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


# ƒê·ªçc intents (ƒÉn BOM n·∫øu c√≥)
with open('intents.json', 'r', encoding='utf-8-sig') as f:
    intents = json.load(f)


# Load model ƒë√£ train
FILE = "data.pth"
data = torch.load(FILE, map_location=device)


input_size = data["input_size"]
hidden_size = data["hidden_size"]
output_size = data["output_size"]
all_words = data["all_words"]
tags = data["tags"]
model_state = data["model_state"]


model = NeuralNet(input_size, hidden_size, output_size).to(device)
model.load_state_dict(model_state)   # n·∫°p tr·ªçng s·ªë
model.eval()


# State manager: c·ªë g·∫Øng d√πng flows.json n·∫øu c√≥
try:
    state_mgr = StateManager("flows.json")
except Exception:
    state_mgr = StateManager()


INTERRUPT_INTENTS = set()  # kh√¥ng ng·∫Øt flow b·∫±ng intent; ch·ªâ h·ªßy b·∫±ng CANCEL_WORDS
CANCEL_WORDS = {"h·ªßy", "hu·ª∑", "huy", "cancel", "tho√°t", "d·ª´ng", "ƒë·ªïi ch·ªß ƒë·ªÅ", "doi chu de"}


print("ü§ñ Chatbot ƒë√£ s·∫µn s√†ng! G√µ 'quit' ƒë·ªÉ tho√°t.")


try:
    # H√†m g·ªçi API ƒë·ªÉ t√¨m ki·∫øm FAQ
    def get_faq_response(sentence):
        try:
            url = "http://localhost:8000/search"
            params = {"q": sentence}
            response = requests.get(url, params=params, timeout=5)
            if response.status_code == 200 and response.json():
                faqs = response.json()
                if faqs:
                    return faqs[0]["answer"]
            return None
        except requests.RequestException as e:
            print(f"L·ªói k·∫øt n·ªëi API: {e}")
            return None


    # H√†m g·ªçi API ƒë·ªÉ ki·ªÉm tra s√°ch
    def get_inventory_response(sentence):
        try:
            url = "http://localhost:8000/inventory"
            params = {"book_name": sentence}
            response = requests.get(url, params=params, timeout=5)
            if response.status_code == 200:
                data = response.json()
                if isinstance(data, list) and data:  # Check l√† list v√† kh√¥ng r·ªóng
                    book = data[0]
                    if 'name' in book:  # Check key t·ªìn t·∫°i
                        return f"S√°ch '{book['name']}' c·ªßa t√°c gi·∫£ {book['author']}, nƒÉm xu·∫•t b·∫£n {book['year']}, s·ªë l∆∞·ª£ng: {book['quantity']}, tr·∫°ng th√°i: {book['status']}"
                    else:
                        print(f"L·ªói d·ªØ li·ªáu s√°ch: Key 'name' kh√¥ng t·ªìn t·∫°i")
                        return None
                else:
                    return None  # Kh√¥ng t√¨m th·∫•y, kh√¥ng l·ªói
            else:
                print(f"L·ªói API status: {response.status_code}")
                return None
        except requests.RequestException as e:
            print(f"L·ªói k·∫øt n·ªëi API: {e}")
            return None
        except (KeyError, IndexError, ValueError) as e:
            print(f"L·ªói d·ªØ li·ªáu s√°ch: {e}")
            return None


    while True:
        sentence = input("B·∫°n: ").strip()
        if sentence.lower() == "quit":
            break


        # L·ªánh h·ªßy lu·ªìng th·ªß c√¥ng
        if sentence.lower() in CANCEL_WORDS:
            try:
                state_mgr.exit_flow()
            except Exception:
                pass
            reply = "ƒê√£ h·ªßy lu·ªìng hi·ªán t·∫°i. B·∫°n mu·ªën h·ªèi g√¨ ti·∫øp?"
            print("Bot:", reply)
            cur.execute(
                "INSERT INTO conversations(user_message, bot_reply, intent_tag, confidence, time) VALUES (?,?,?,?,?)",
                (sentence, reply, None, 0.0, datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
            )
            conn.commit()
            continue


        # Kh·ªüi t·∫°o
        reply = None
        tag_to_log = None
        confidence = 0.0


        # --- NLU: d·ª± ƒëo√°n intent ---
        tokens = tokenize(sentence)
        X = bag_of_words(tokens, all_words)
        X = torch.from_numpy(X).unsqueeze(0).to(device)


        with torch.no_grad():
            output = model(X)
            probs = torch.softmax(output, dim=1)
            prob, pred_idx = torch.max(probs, dim=1)
            tag = tags[pred_idx.item()]
            confidence = float(prob.item())


        # --- ∆ØU TI√äN NG·ªÆ C·∫¢NH ---
        # 0) N·∫øu ƒëang ·ªü trong flow: state manager x·ª≠ l√Ω TR∆Ø·ªöC
        if getattr(state_mgr, "active_flow", None):
            try:
                ctx_reply = state_mgr.handle(tag, sentence)
            except Exception:
                ctx_reply = None
            if ctx_reply:
                reply = ctx_reply
                tag_to_log = tag


        # 1) N·∫øu ch∆∞a c√≥ reply: th·ª≠ ki·ªÉm tra s√°ch trong inventory (∆∞u ti√™n n·∫øu ch·ª©a t·ª´ kh√≥a s√°ch ho·∫∑c t√™n s√°ch ph·ªï bi·∫øn)
        book_keywords = ["s√°ch", "t·ªìn kho", "m∆∞·ª£n", "c·∫•u tr√∫c d·ªØ li·ªáu", "tr√≠ tu·ªá nh√¢n t·∫°o", "l·∫≠p tr√¨nh python"]  # Th√™m t√™n s√°ch ph·ªï bi·∫øn ƒë·ªÉ nh·∫≠n di·ªán
        if reply is None and any(word in sentence.lower() for word in book_keywords):
            inventory_reply = get_inventory_response(sentence)
            if inventory_reply:
                reply = inventory_reply
                tag_to_log = "inventory_search"
            else:
                # Th·ª≠ t√¨m ki·∫øm v·ªõi t·ª´ kh√≥a ri√™ng l·∫ª
                keywords = sentence.split()
                for keyword in keywords:
                    inventory_reply = get_inventory_response(keyword)
                    if inventory_reply:
                        reply = inventory_reply
                        tag_to_log = "inventory_search"
                        break


        # 2) N·∫øu v·∫´n ch∆∞a c√≥ reply: th·ª≠ t√¨m ki·∫øm trong FAQ qua API (∆∞u ti√™n cho c√¢u h·ªèi th∆∞ vi·ªán)
        faq_keywords = ["th∆∞ vi·ªán", "ƒë·ªãa ch·ªâ", "gi·ªù", "li√™n h·ªá", "n·ªôi quy"]
        if reply is None and any(word in sentence.lower() for word in faq_keywords):
            faq_reply = get_faq_response(sentence)
            if faq_reply:
                reply = faq_reply
                tag_to_log = "faq_search"
            else:
                # Th·ª≠ t√¨m ki·∫øm v·ªõi t·ª´ kh√≥a ri√™ng l·∫ª
                keywords = sentence.split()
                for keyword in keywords:
                    faq_reply = get_faq_response(keyword)
                    if faq_reply:
                        reply = faq_reply
                        tag_to_log = "faq_search"
                        break


        # 3) N·∫øu v·∫´n ch∆∞a c√≥ reply: th·ª≠ bootstrap theo t·ª´ kh√≥a trong flows.json
        if reply is None:
            try:
                boot = state_mgr.bootstrap_by_text(sentence)
            except Exception:
                boot = None
            if boot:
                reply = boot


        # 4) N·∫øu v·∫´n ch∆∞a c√≥ -> d√πng responses theo intent (ch·ªâ khi ƒë·ªß t·ª± tin)
        if reply is None and confidence > CONF_THRESHOLD:
            resp_list = next((it["responses"] for it in intents["intents"] if it["tag"] == tag), None)
            if resp_list:
                reply = random.choice(resp_list)
                tag_to_log = tag


        # 5) Fallback cu·ªëi
        if reply is None:
            reply = "Xin l·ªói, m√¨nh ch∆∞a hi·ªÉu √Ω b·∫°n."


        print("Bot:", reply)


        # --- L∆∞u log ---
        cur.execute(
            "INSERT INTO conversations(user_message, bot_reply, intent_tag, confidence, time) VALUES (?,?,?,?,?)",
            (sentence, reply, tag_to_log, confidence, datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
        )
        conn.commit()


finally:
    conn.close()

