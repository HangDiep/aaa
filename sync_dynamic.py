"""
Dynamic Notion ‚Üí SQLite ‚Üí Qdrant Sync
T·ª± ƒë·ªông t·∫°o b·∫£ng m·ªõi khi ph√°t hi·ªán database m·ªõi t·ª´ Notion
"""

from fastapi import APIRouter, HTTPException, Request
from pydantic import BaseModel
from typing import Optional, Dict, Any
from datetime import datetime
import sqlite3
import os
import json
import subprocess

# Get absolute path to database
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DB_PATH = os.path.join(BASE_DIR, "faq.db")
print(f"[DYNAMIC SYNC] Using database: {DB_PATH}")
# T·∫°o router
router = APIRouter(prefix="/notion/dynamic", tags=["notion-dynamic-sync"])


# ==========================
#  Pydantic models
# ==========================

class DynamicSyncPayload(BaseModel):
    """
    Generic payload cho b·∫•t k·ª≥ b·∫£ng n√†o
    """
    notion_id: str
    table_name: str  # T√™n b·∫£ng (VD: thu_vien, faq, books...)
    data: Dict[str, Any]  # D·ªØ li·ªáu ƒë·ªông t·ª´ Notion
    approved: Optional[bool] = True


class DeletePayload(BaseModel):
    notion_id: str
    table_name: str


# ==========================
#  DB helper
# ==========================

def get_conn():
    return sqlite3.connect(DB_PATH)


def init_collections_config_table():
    """
    T·∫°o b·∫£ng collections_config ƒë·ªÉ l∆∞u metadata c·ªßa c√°c collections
    """
    conn = get_conn()
    cur = conn.cursor()

    cur.execute(
        """
        CREATE TABLE IF NOT EXISTS collections_config (
            name TEXT PRIMARY KEY,
            description TEXT,
            enabled INTEGER DEFAULT 1,
            priority INTEGER DEFAULT 0,
            created_at TEXT,
            updated_at TEXT
        )
        """
    )

    conn.commit()
    conn.close()
    print("‚úÖ collections_config table initialized")


# Initialize table on module import
init_collections_config_table()


def sanitize_table_name(name: str) -> str:
    """L√†m s·∫°ch t√™n b·∫£ng (ch·ªâ cho ph√©p a-z, 0-9, _)"""
    import re

    clean = name.lower().replace(" ", "_").replace("-", "_")
    clean = re.sub(r"[^a-z0-9_]", "", clean)
    return clean


def sanitize_column_name(name: str) -> str:
    """L√†m s·∫°ch t√™n c·ªôt"""
    import re

    clean = name.lower().replace(" ", "_").replace("-", "_")
    clean = re.sub(r"[^a-z0-9_]", "", clean)
    return clean


def infer_sql_type(value: Any) -> str:
    """T·ª± ƒë·ªông ph√°t hi·ªán ki·ªÉu d·ªØ li·ªáu SQL"""
    if value is None:
        return "TEXT"
    elif isinstance(value, bool):
        return "INTEGER"
    elif isinstance(value, int):
        return "INTEGER"
    elif isinstance(value, float):
        return "REAL"
    else:
        return "TEXT"


def sanitize_sql_value(value):
    """
    Chuy·ªÉn ƒë·ªïi list/dict th√†nh JSON string ƒë·ªÉ l∆∞u v√†o SQLite
    Tr√°nh l·ªói 'type list is not supported'
    """
    if isinstance(value, (list, dict)):
        return json.dumps(value, ensure_ascii=False)
    return value


def generate_table_description(table_name: str, data: Dict[str, Any]) -> str:
    """
    T·ª± ƒë·ªông t·∫°o m√¥ t·∫£ cho b·∫£ng m·ªõi b·∫±ng LLM
    """
    from dotenv import load_dotenv
    import requests

    # Load env
    ENV_PATH = r"D:\HTML\a_Copy\rag\.env"
    try:
        if os.path.exists(ENV_PATH):
            load_dotenv(ENV_PATH, override=True)
    except Exception:
        pass

    GROQ_API_KEY = os.getenv("GROQ_API_KEY")
    GROQ_MODEL = os.getenv("GROQ_MODEL", "glm-4-plus")

    if not GROQ_API_KEY:
        columns = [sanitize_column_name(k) for k in data.keys()]
        return f"B·∫£ng {table_name} ch·ª©a: {', '.join(columns[:5])}"

    columns = list(data.keys())

    sample_values = []
    for k, v in data.items():
        if v and len(str(v)) < 50:
            sample_values.append(f"{k}: {v}")
    sample_str = "; ".join(sample_values[:5])

    prompt = f"""B·∫£ng "{table_name}" ch·ª©a d·ªØ li·ªáu m·∫´u: [{sample_str}]

D·ª±a v√†o t√™n b·∫£ng v√† d·ªØ li·ªáu m·∫´u tr√™n, h√£y vi·∫øt 1 c√¢u m√¥ t·∫£ ng·∫Øn g·ªçn (10-15 t·ª´) v·ªÅ m·ª•c ƒë√≠ch c·ªßa b·∫£ng n√†y.

V√≠ d·ª•:
- B·∫£ng "books" (name: Python Basics; author: John Doe) ‚Üí "Ch·ª©a th√¥ng tin c√°c ƒë·∫ßu s√°ch, t√†i li·ªáu v√† t√°c gi·∫£."
- B·∫£ng "store" (item: Cafe; price: 20k) ‚Üí "Th√¥ng tin th·ª±c ƒë∆°n, b·∫£ng gi√° ƒë·ªì u·ªëng t·∫°i c·ª≠a h√†ng."

Ch·ªâ vi·∫øt m√¥ t·∫£, kh√¥ng th√™m g√¨ kh√°c:"""

    try:
        headers = {
            "Authorization": f"Bearer {GROQ_API_KEY}",
            "Content-Type": "application/json",
        }

        payload = {
            "model": GROQ_MODEL,
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.1,
            "max_tokens": 50,
        }

        resp = requests.post(
            "https://open.bigmodel.cn/api/paas/v4/chat/completions",
            headers=headers,
            json=payload,
            timeout=10,
        )

        if resp.status_code == 200:
            data_resp = resp.json()
            description = data_resp["choices"][0]["message"]["content"].strip()
            return description
        else:
            columns_str = ", ".join(columns[:5])
            return f"B·∫£ng {table_name} ch·ª©a: {columns_str}"

    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói generate description: {e}")
        columns_str = ", ".join(columns[:5])
        return f"B·∫£ng {table_name} ch·ª©a: {columns_str}"


def save_to_collections_config(table_name: str, description: str):
    """
    L∆∞u th√¥ng tin collection v√†o collections_config
    """
    conn = get_conn()
    cur = conn.cursor()
    now = datetime.utcnow().isoformat()

    cur.execute(
        """
        INSERT OR REPLACE INTO collections_config 
        (name, description, enabled, priority, created_at, updated_at)
        VALUES (?, ?, 1, 0, ?, ?)
        """,
        (table_name, description, now, now),
    )

    conn.commit()
    conn.close()
    print(f"  üíæ Saved to collections_config: {table_name}")


def create_table_if_not_exists(table_name: str, data: Dict[str, Any]):
    """
    T·ª± ƒë·ªông t·∫°o b·∫£ng SQLite n·∫øu ch∆∞a t·ªìn t·∫°i.
    N·∫øu b·∫£ng ƒë√£ t·ªìn t·∫°i ‚Üí Ki·ªÉm tra v√† ADD COLUMN m·ªõi n·∫øu thi·∫øu.
    """
    conn = get_conn()
    cur = conn.cursor()

    cur.execute(
        "SELECT name FROM sqlite_master WHERE type='table' AND name=?", (table_name,)
    )
    exists = cur.fetchone()

    expected_columns = {
        "notion_id": "TEXT PRIMARY KEY",
        "last_updated": "TEXT",
        "approved": "INTEGER DEFAULT 1",
    }

    for key, value in data.items():
        col_name = sanitize_column_name(key)
        if col_name not in expected_columns:
            sql_type = infer_sql_type(value)
            expected_columns[col_name] = sql_type

    if not exists:
        print(f"  üÜï Creating new table: {table_name}")

        cols_sql = []
        for col, dtype in expected_columns.items():
            cols_sql.append(f"{col} {dtype}")

        create_sql = f"CREATE TABLE {table_name} ({', '.join(cols_sql)})"
        cur.execute(create_sql)
        conn.commit()

        print(f"  ‚úÖ Table '{table_name}' created successfully!")

        print(f"  ü§ñ Generating description for '{table_name}'...")
        description = generate_table_description(table_name, data)
        save_to_collections_config(table_name, description)

    else:
        cur.execute(f"PRAGMA table_info({table_name})")
        existing_cols = {row[1] for row in cur.fetchall()}

        missing_cols = []
        for col_name, dtype in expected_columns.items():
            if col_name not in existing_cols:
                missing_cols.append((col_name, dtype))

        if missing_cols:
            print(f"  ‚ö†Ô∏è Schema Changed inside '{table_name}'. Migration needed.")
            for col_name, dtype in missing_cols:
                try:
                    alter_sql = f"ALTER TABLE {table_name} ADD COLUMN {col_name} {dtype}"
                    print(f"     ‚ûï Adding column: {col_name} ({dtype})")
                    cur.execute(alter_sql)
                except Exception as e:
                    print(f"     ‚ùå Failed to add column {col_name}: {e}")
            conn.commit()
            print("  ‚úÖ Schema migration completed.")

    conn.close()


def upsert_dynamic_data(
    table_name: str, notion_id: str, data: Dict[str, Any], approved: bool = True
):
    """
    Insert ho·∫∑c Update d·ªØ li·ªáu v√†o b·∫£ng ƒë·ªông (AN TO√ÄN TUY·ªÜT ƒê·ªêI v·ªõi list/dict)
    """
    conn = get_conn()
    cur = conn.cursor()
    now = datetime.utcnow().isoformat()

    columns = ["notion_id"]
    values = [sanitize_sql_value(notion_id)]

    for key, value in data.items():
        col_name = sanitize_column_name(key)
        if col_name == "notion_id":
            continue

        safe_value = sanitize_sql_value(value)

        if isinstance(safe_value, (list, dict)):
            print(
                f"‚ùå [SQLITE BLOCKED] Column: {col_name} | Value: {safe_value} | Type: {type(safe_value)}"
            )
            safe_value = json.dumps(safe_value, ensure_ascii=False)

        columns.append(col_name)
        values.append(
            str(safe_value) if isinstance(safe_value, (list, dict)) else safe_value
        )

    columns.extend(["last_updated", "approved"])
    values.extend([now, 1 if approved else 0])

    placeholders = ", ".join(["?"] * len(columns))
    update_clause_items = []
    for col in columns:
        if col != "notion_id":
            update_clause_items.append(f"{col} = excluded.{col}")
    update_clause = ", ".join(update_clause_items)

    sql = f"""
        INSERT INTO {table_name} ({', '.join(columns)})
        VALUES ({placeholders})
        ON CONFLICT(notion_id) DO UPDATE SET {update_clause}
    """

    try:
        cur.execute(sql, values)
        conn.commit()
    finally:
        conn.close()


def delete_dynamic_data(table_name: str, notion_id: str):
    """X√≥a d·ªØ li·ªáu kh·ªèi b·∫£ng ƒë·ªông"""
    conn = get_conn()
    cur = conn.cursor()
    cur.execute(f"DELETE FROM {table_name} WHERE notion_id = ?", (notion_id,))
    conn.commit()
    conn.close()


# ==========================
#  Notion Parser Helper
# ==========================


def parse_notion_properties(props: Dict[str, Any]) -> Dict[str, Any]:
    """
    Flatten nested Notion properties into simple key-value pairs.
    Handles: Title, RichText, Select, MultiSelect, Date, Number, Checkbox, etc.
    """
    data = {}
    for key, prop in props.items():
        if not isinstance(prop, dict):
            data[key] = prop
            continue

        prop_type = prop.get("type")
        value = None

        try:
            if prop_type == "title":
                value = "".join(
                    [t.get("plain_text", "") for t in prop.get("title", [])]
                )
            elif prop_type == "rich_text":
                value = "".join(
                    [t.get("plain_text", "") for t in prop.get("rich_text", [])]
                )
            elif prop_type == "select":
                select = prop.get("select")
                value = select.get("name") if select else None
            elif prop_type == "multi_select":
                multi = prop.get("multi_select", [])
                value = ", ".join([opt.get("name", "") for opt in multi])
            elif prop_type == "date":
                date = prop.get("date")
                value = date.get("start") if date else None
            elif prop_type == "checkbox":
                value = prop.get("checkbox")
            elif prop_type == "number":
                value = prop.get("number")
            elif prop_type == "email":
                value = prop.get("email")
            elif prop_type == "phone_number":
                value = prop.get("phone_number")
            elif prop_type == "url":
                value = prop.get("url")
            elif prop_type == "status":
                status = prop.get("status")
                value = status.get("name") if status else None
            else:
                if prop_type in prop:
                    value = prop[prop_type]
                    if isinstance(value, dict) and "name" in value:
                        value = value["name"]
        except Exception as e:
            print(f"‚ö†Ô∏è Error parsing property '{key}': {e}")
            value = str(prop)

        data[key] = sanitize_sql_value(value)

    return data


# ==========================
#  API Endpoints
# ==========================


@router.post("/sync")
async def dynamic_sync(request: Request):
    """
    Smart Endpoint: ONLY accept table_name from BODY (no query param anymore)
    """
    try:
        payload = await request.json()

        target_table = payload.get("table_name")
        if not target_table:
            raise HTTPException(
                status_code=422,
                detail="Missing 'table_name' in request body",
            )

        target_table = sanitize_table_name(target_table)

        notion_id = payload.get("notion_id") or payload.get("id")
        if not notion_id:
            raise HTTPException(
                status_code=422,
                detail="Missing 'notion_id' or 'id' in body.",
            )

        # SMART PARSER
        if "data" in payload and isinstance(payload["data"], dict):
            final_data = payload["data"]
            approved = payload.get("approved", True)
        elif "properties" in payload:
            print(
                f"üß† [SMART PARSER] Detected RAW Notion Payload for '{target_table}'"
            )
            final_data = parse_notion_properties(payload["properties"])

            approved = True
            if "Approved" in final_data:
                val = final_data["Approved"]
                if val is not None:
                    approved = bool(val)
        else:
            print("‚ö†Ô∏è [SMART PARSER] Unknown structure. Using flat payload.")
            final_data = {
                k: v
                for k, v in payload.items()
                if k not in ["notion_id", "id", "table_name"]
            }
            approved = True

        # Skip n·∫øu ch∆∞a Approved (tr·ª´ b·∫£ng 'nganh')
        if target_table != "nganh" and not approved:
            print(
                f"‚è≠Ô∏è [DYNAMIC SYNC] Unapproved => delete row in '{target_table}' | ID: {notion_id}"
            )
            try:
                delete_dynamic_data(target_table, notion_id)
            except Exception as e:
                print(f"‚ö†Ô∏è Error deleting unapproved row: {e}")

            return {
                "status": "deleted_unapproved",
                "table_name": target_table,
                "notion_id": notion_id,
                "reason": "not_approved",
            }

        # Sanitize to√†n b·ªô value
        safe_data = {}
        for k, v in final_data.items():
            if isinstance(v, (list, dict)):
                safe_data[k] = json.dumps(v, ensure_ascii=False)
            else:
                safe_data[k] = v
        final_data = safe_data

        print(f"üì• [DYNAMIC SYNC] Table: '{target_table}' | ID: {notion_id}")

        create_table_if_not_exists(target_table, final_data)
        upsert_dynamic_data(target_table, notion_id, final_data, approved)

        print(f"‚úÖ [DYNAMIC SYNC] Success: '{target_table}'")

        try:
            subprocess.Popen(
                ["python", "push_to_qdrant_dynamic.py", target_table],
                cwd=os.path.dirname(os.path.abspath(__file__)),
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
            )
        except Exception as e:
            print(f"‚ö†Ô∏è Qdrant trigger error: {e}")

        try:
            import requests

            requests.post("http://localhost:8000/reload-config", timeout=2)
        except Exception:
            pass

        return {
            "status": "ok",
            "table_name": target_table,
            "notion_id": notion_id,
            "parsed_fields": list(final_data.keys()),
        }

    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå [DYNAMIC SYNC] Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/delete")
@router.delete("/delete")
async def dynamic_delete(payload: DeletePayload):
    """
    X√≥a record kh·ªèi b·∫£ng ƒë·ªông
    """
    try:
        table_name = sanitize_table_name(payload.table_name)

        print(f"üóëÔ∏è  [DYNAMIC DELETE] Deleting from '{table_name}'")
        print(f"   Notion ID: {payload.notion_id}")

        delete_dynamic_data(table_name, payload.notion_id)

        print(f"‚úÖ [DYNAMIC DELETE] Deleted from '{table_name}'")

        return {
            "status": "deleted",
            "table_name": table_name,
            "notion_id": payload.notion_id,
        }

    except Exception as e:
        print(f"‚ùå [DYNAMIC DELETE] Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/tables")
async def list_tables():
    """
    Li·ªát k√™ t·∫•t c·∫£ c√°c b·∫£ng trong SQLite
    """
    try:
        conn = get_conn()
        cur = conn.cursor()
        cur.execute("SELECT name FROM sqlite_master WHERE type='table' ORDER BY name")
        tables = [row[0] for row in cur.fetchall()]
        conn.close()

        return {"status": "ok", "tables": tables, "count": len(tables)}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/schema/{table_name}")
async def get_table_schema(table_name: str):
    """
    Xem schema c·ªßa m·ªôt b·∫£ng
    """
    try:
        table_name = sanitize_table_name(table_name)

        conn = get_conn()
        cur = conn.cursor()
        cur.execute(f"PRAGMA table_info({table_name})")
        columns = cur.fetchall()
        conn.close()

        if not columns:
            raise HTTPException(
                status_code=404, detail=f"Table '{table_name}' not found"
            )

        schema = [
            {
                "cid": col[0],
                "name": col[1],
                "type": col[2],
                "notnull": bool(col[3]),
                "default": col[4],
                "pk": bool(col[5]),
            }
            for col in columns
        ]

        return {"status": "ok", "table_name": table_name, "schema": schema}
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ==========================
#  DEBUG endpoint
# ==========================


@router.post("/debug")
async def debug_dynamic(request: Request):
    """Debug endpoint ƒë·ªÉ xem n8n g·ª≠i g√¨"""
    try:
        body = await request.body()
        headers = dict(request.headers)

        try:
            body_str = body.decode("utf-8")
            json_data = json.loads(body_str)
        except Exception:
            json_data = None

        print("=" * 80)
        print("üîç DEBUG /notion/dynamic/debug")
        print("=" * 80)
        print("\nüìã Headers:")
        for key, value in headers.items():
            print(f"   {key}: {value}")

        print(f"\nüì¶ Raw Body ({len(body)} bytes):")
        print(body.decode("utf-8", errors="replace")[:1000])

        print("\nüîß Parsed JSON:")
        if json_data:
            print(json.dumps(json_data, indent=2, ensure_ascii=False))
        else:
            print("   ‚ùå Kh√¥ng parse ƒë∆∞·ª£c JSON")

        print("=" * 80)

        return {
            "status": "debug_ok",
            "headers": headers,
            "body_length": len(body),
            "json_data": json_data,
        }
    except Exception as e:
        print(f"‚ùå Debug error: {e}")
        return {"status": "error", "message": str(e)}


@router.post("/scan")
async def scan_new_databases():
    """
    AUTO-DISCOVERY: Qu√©t to√†n b·ªô Notion workspace ƒë·ªÉ t√¨m database m·ªõi.
    ƒêi·ªÅu ki·ªán: B·∫°n ph·∫£i "Share" database ƒë√≥ v·ªõi Integration (Con Bot).
    """
    import requests

    ENV_PATH = r"D:\HTML\a_Copy\rag\.env"
    try:
        if os.path.exists(ENV_PATH):
            from dotenv import load_dotenv

            load_dotenv(ENV_PATH, override=True)
    except Exception:
        pass

    NOTION_API_KEY = os.getenv("NOTION_API_KEY")
    NOTION_VERSION = "2022-06-28"

    if not NOTION_API_KEY:
        raise HTTPException(status_code=500, detail="Missing NOTION_API_KEY in .env")

    headers = {
        "Authorization": f"Bearer {NOTION_API_KEY}",
        "Notion-Version": NOTION_VERSION,
        "Content-Type": "application/json",
    }

    print("üîç [AUTO-SCAN] Searching for accessible databases...")
    search_url = "https://api.notion.com/v1/search"
    search_payload = {
        "filter": {"value": "database", "property": "object"},
        "page_size": 100,
    }

    try:
        resp = requests.post(
            search_url, headers=headers, json=search_payload, timeout=15
        )
        if resp.status_code != 200:
            raise Exception(f"Notion Search Error: {resp.text}")

        results = resp.json().get("results", [])
        print(f"‚úÖ Found {len(results)} databases accessible.")

        found_names = []
        for d in results:
            t = "".join([x.get("plain_text", "") for x in d.get("title", [])])
            found_names.append(t if t else d["id"])
        print(f"üìã List: {found_names}")

        synced_tables = []

        for db in results:
            db_id = db["id"]

            raw_title = ""
            if db.get("title"):
                raw_title = "".join(
                    [t.get("plain_text", "") for t in db.get("title", [])]
                )

            if not raw_title:
                raw_title = f"db_{db_id[:4]}"

            table_name = sanitize_table_name(raw_title)
            print(f"   üëâ Checking DB: {raw_title} -> Table: {table_name}")

            query_url = f"https://api.notion.com/v1/databases/{db_id}/query"

            all_rows = []
            has_more = True
            next_cursor = None
            page_count = 0

            print(f"      üîÑ Syncing data from '{table_name}'...")

            while has_more:
                payload = {"page_size": 100}
                if next_cursor:
                    payload["start_cursor"] = next_cursor

                try:
                    q_resp = requests.post(
                        query_url, headers=headers, json=payload, timeout=30
                    )
                    if q_resp.status_code != 200:
                        print(f"      ‚ö†Ô∏è Error fetching page: {q_resp.text}")
                        break

                    data = q_resp.json()
                    rows = data.get("results", [])
                    all_rows.extend(rows)

                    has_more = data.get("has_more", False)
                    next_cursor = data.get("next_cursor")
                    page_count += 1

                    print(f"         - Page {page_count}: fetched {len(rows)} rows.")

                    if len(all_rows) > 1000:
                        print("      ‚ö†Ô∏è Reached 1000 rows limit per scan. Stopping.")
                        break
                except Exception as e:
                    print(f"      ‚ùå Network error: {e}")
                    break

            if not all_rows:
                print("      ‚ö†Ô∏è  Empty Database. Skipping.")
                continue

            for row in all_rows:
                notion_id = row["id"]
                props = row.get("properties", {})

                final_data = parse_notion_properties(props)

                approved = True
                if table_name != "nganh" and "Approved" in final_data:
                    val = final_data["Approved"]
                    if val is not None:
                        approved = bool(val)

                                # N·∫øu kh√¥ng Approved ‚Üí xo√° kh·ªèi SQLite n·∫øu ƒë√£ t·ªìn t·∫°i r·ªìi, r·ªìi b·ªè qua
                if table_name != "nganh" and not approved:
                    print(
                        f"‚è≠Ô∏è [SCAN] Unapproved => delete row | table={table_name} | id={notion_id}"
                    )
                    try:
                        delete_dynamic_data(table_name, notion_id)
                    except Exception as e:
                        print(f"‚ö†Ô∏è Error deleting unapproved row in scan: {e}")
                    continue


                safe_data = {k: sanitize_sql_value(v) for k, v in final_data.items()}

                create_table_if_not_exists(table_name, safe_data)
                upsert_dynamic_data(table_name, notion_id, safe_data, approved=approved)

            print(f"      ‚úÖ Synced {len(all_rows)} items.")

            try:
                subprocess.Popen(
                    ["python", "push_to_qdrant_dynamic.py", table_name],
                    cwd=os.path.dirname(os.path.abspath(__file__)),
                    stdout=subprocess.DEVNULL,
                    stderr=subprocess.DEVNULL,
                )
            except Exception:
                pass

            synced_tables.append(table_name)

        # AUTO-DELETE stale tables
        if len(found_names) > 0:
            try:
                conn = get_conn()
                cur = conn.cursor()

                cur.execute("SELECT name FROM sqlite_master WHERE type='table'")
                verify_rows = cur.fetchall()
                existing_tables = [r[0] for r in verify_rows]

                WHITELIST = {
                    "sqlite_sequence",
                    "conversations",
                    "questions_log",
                    "collections_config",
                    "sync_meta",
                }

                active_set = set(synced_tables)
                stale_tables = []

                for tbl in existing_tables:
                    if tbl not in active_set and tbl not in WHITELIST:
                        stale_tables.append(tbl)

                for bad_table in stale_tables:
                    print(
                        f"   üóëÔ∏è [Auto-Delete] Table '{bad_table}' no longer exists in Notion. Dropping..."
                    )
                    cur.execute(f'DROP TABLE IF EXISTS "{bad_table}"')

                conn.commit()
                conn.close()
            except Exception as e:
                print(f"   ‚ö†Ô∏è [Auto-Delete] Error: {e}")

        return {
            "status": "ok",
            "message": "Auto-Discovery Completed",
            "synced_tables": synced_tables,
            "count": len(synced_tables),
            "accessible_databases": found_names,
        }

    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå Scan Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

def cleanup_deleted_tables_in_sqlite(valid_tables):
    """
    X√≥a c√°c b·∫£ng trong collections_config m√† kh√¥ng c√≤n t·ªìn t·∫°i tr√™n Notion.
    valid_tables: danh s√°ch c√°c b·∫£ng hi·ªán c√≥ (ƒë∆∞·ª£c sync th√†nh c√¥ng).
    """
    try:
        conn = sqlite3.connect("faq.db")
        cur = conn.cursor()

        cur.execute("SELECT name FROM collections_config")
        existing = [row[0] for row in cur.fetchall()]

        to_delete = [t for t in existing if t not in valid_tables]

        if to_delete:
            print("üßπ X√≥a c√°c b·∫£ng kh√¥ng c√≤n trong Notion:")
            for t in to_delete:
                cur.execute("DELETE FROM collections_config WHERE name = ?", (t,))
                print(f"   - ƒê√£ x√≥a: {t}")
            conn.commit()
        else:
            print("‚úî Kh√¥ng c√≥ b·∫£ng n√†o c·∫ßn x√≥a kh·ªèi collections_config.")

        conn.close()
    except Exception as e:
        print(f"‚ö† L·ªói khi x√≥a b·∫£ng kh√¥ng c√≤n trong Notion: {e}")